{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Male and Female photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot iris data\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "folder = '../data/raw/iris_data/LG2200/gender/'\n",
    "onlyfiles = [f for f in listdir(folder+'Female')\n",
    "             if isfile(join(folder+'Female', f))]\n",
    "\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # define filename\n",
    "    filename = folder+'Female/'+onlyfiles[i]\n",
    "    # load image pixels\n",
    "    image = imread(filename, 'tiff')\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot iris data\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "folder = '../data/raw/iris_data/LG2200/gender/'\n",
    "onlyfiles = [f for f in listdir(folder+'Male')\n",
    "             if isfile(join(folder+'Male', f))]\n",
    "\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # define filename\n",
    "    filename = folder+'Male/'+onlyfiles[i]\n",
    "    # load image pixels\n",
    "    image = imread(filename)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "\n",
    "# show the figure\n",
    "fig1 = pyplot.gcf()\n",
    "pyplot.show()\n",
    "pyplot.draw()\n",
    "pyplot.savefig('../data/iris_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset, reshape and save to a new file\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# define location of dataset\n",
    "folder = '../data/raw/train/'\n",
    "\n",
    "photos, labels = list(), list()\n",
    "# enumerate files in the directory\n",
    "for file in listdir(folder):\n",
    "\t# determine class\n",
    "\toutput = 0.0\n",
    "\tif file.startswith('cat'):\n",
    "\t\toutput = 1.0\n",
    "\t# load image\n",
    "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "\t# convert to numpy array\n",
    "\tphoto = img_to_array(photo)\n",
    "\t# store\n",
    "\tphotos.append(photo)\n",
    "\tlabels.append(output)\n",
    "# convert to a numpy arrays\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "# save the reshaped photos\n",
    "save('iris_Male.npy', photos)\n",
    "save('iris_female.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and confirm the shape\n",
    "from numpy import load\n",
    "photos = load('iris_Male.npy')\n",
    "labels = load('iris_female.npy')\n",
    "print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Photos into Standard Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize dataset into a useful structure\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# create directories\n",
    "dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "\n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs:\n",
    "\t# create label subdirectories\n",
    "\tlabeldirs = ['Male/', 'Female/']\n",
    "\tfor labldir in labeldirs:\n",
    "\t\tnewdir = dataset_home + subdir + labldir\n",
    "\t\tmakedirs(newdir, exist_ok=True)\n",
    "        \n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.20\n",
    "# copy training dataset images into subdirectories\n",
    "\n",
    "root_directory = '../data/raw/iris_data/LG2200/gender/'\n",
    "subdirs = ['Male/', 'Female/']\n",
    "for subdir in subdirs:\n",
    "    src_directory = root_directory + subdir\n",
    "\n",
    "    # Let's get the captured irises.\n",
    "    list_files = listdir(src_directory)\n",
    "    # There are some irises that doesn't have identification. So we have to filter them first.\n",
    "    list_files_ok = [sub for sub in list_files if 'd' in sub]\n",
    "    list_users_with_id = [sub.split('d')[1].split('.')[0] for sub in list_files_ok]\n",
    "\n",
    "    # We identify the users by deleting repeated users\n",
    "    list_unique_users = list(set(list_users_with_id))\n",
    "    print(\"Lista de individuos sin repetir imágenes de iris: \", len(list_unique_users))\n",
    "\n",
    "    # Split train - test\n",
    "    random.shuffle(list_unique_users)\n",
    "    len_test = round(val_ratio*len(list_unique_users))\n",
    "    len_train = len(list_unique_users) - len_test\n",
    "    train_users = list_unique_users[0:len_train]\n",
    "    test_users = list_unique_users[len_train:]\n",
    "\n",
    "    train_set = []\n",
    "    for i in train_users:\n",
    "        for str_element in list_files_ok:\n",
    "            if i == str_element.split('d')[1].split('.')[0]:\n",
    "                train_set.append(str_element)\n",
    "\n",
    "    test_set = []\n",
    "    for j in test_users:\n",
    "        for str_element in list_files_ok:\n",
    "            if j == str_element.split('d')[1].split('.')[0]:\n",
    "                test_set.append(str_element)\n",
    "                \n",
    "    # Let's copy the different datasets  \n",
    "    dst_dir = 'train/'\n",
    "    for file in train_set:\n",
    "        src = src_directory + '/' + file\n",
    "        dst = dataset_home + dst_dir + subdir  + file    \n",
    "        copyfile(src, dst)\n",
    "\n",
    "    dst_dir = 'test/'\n",
    "    for file in test_set:\n",
    "        src = src_directory + '/' + file\n",
    "        dst = dataset_home + dst_dir + subdir  + file    \n",
    "        copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small routine to check data leakage \n",
    "var = '42'\n",
    "\n",
    "lista = []\n",
    "for str_element in train_set:\n",
    "    lista.append(var == str_element.split('d')[1].split('.')[0])\n",
    "\n",
    "print('train set')\n",
    "for i in range(len(np.where(lista)[0])):\n",
    "    print(train_set[np.where(lista)[0][i]])\n",
    "    \n",
    "lista = []\n",
    "for str_element in test_set:\n",
    "    lista.append(var == str_element.split('d')[1].split('.')[0])\n",
    "\n",
    "print('test set')\n",
    "for i in range(len(np.where(lista)[0])):\n",
    "    print(test_set[np.where(lista)[0][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize dataset into a useful structure\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# create directories\n",
    "dataset_home = '../data/processed/iris_data/LG2200/gender/train/'\n",
    "dataset_destination = '../data/processed/iris_data/LG2200/'\n",
    "cv_subdirs = ['cv1/', 'cv2/', 'cv3/']\n",
    "\n",
    "\n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs:\n",
    "    # create label subdirectories\n",
    "    for cv_subdir in cv_subdirs:\n",
    "        labeldirs = ['Male/', 'Female/']\n",
    "        for labldir in labeldirs:\n",
    "            newdir = dataset_destination + cv_subdir + subdir + labldir\n",
    "            makedirs(newdir, exist_ok=True)\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.20\n",
    "# copy training dataset images into subdirectories\n",
    "\n",
    "root_directory = '../data/processed/iris_data/LG2200/gender/train/'\n",
    "subdirs = ['Male/', 'Female/']\n",
    "\n",
    "for subdir in subdirs:\n",
    "    src_directory = root_directory + subdir\n",
    "\n",
    "    # Let's get the captured irises.\n",
    "    list_files = listdir(src_directory)\n",
    "    # There are some irises that doesn't have identification. So we have to filter them first.\n",
    "    list_files_ok = [sub for sub in list_files if 'd' in sub]\n",
    "    list_users_with_id = [sub.split('d')[1].split('.')[0] for sub in list_files_ok]\n",
    "\n",
    "    # We identify the users by deleting repeated users\n",
    "    list_unique_users = list(set(list_users_with_id))\n",
    "    print(\"Lista de individuos sin repetir imágenes de iris: \", len(list_unique_users))\n",
    "    \n",
    "    # Let's split the data to perform CV3\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    kf.get_n_splits(list_unique_users)\n",
    "    \n",
    "    # Let's start cv folder count\n",
    "    cv_index = 1\n",
    "    \n",
    "    for train_index, test_index in kf.split(list_unique_users):\n",
    "        X_train, X_test = [list_unique_users[i] for i in train_index], [list_unique_users[i] for i in test_index]\n",
    "\n",
    "        train_users = X_train\n",
    "        test_users = X_test\n",
    "\n",
    "        train_set = []\n",
    "        for i in train_users:\n",
    "            for str_element in list_files_ok:\n",
    "                if i == str_element.split('d')[1].split('.')[0]:\n",
    "                    train_set.append(str_element)\n",
    "\n",
    "        test_set = []\n",
    "        for j in test_users:\n",
    "            for str_element in list_files_ok:\n",
    "                if j == str_element.split('d')[1].split('.')[0]:\n",
    "                    test_set.append(str_element)\n",
    "\n",
    "        cv_subdir = 'cv'+ str(cv_index) + '/'\n",
    "        # Let's copy the different datasets  \n",
    "        dst_dir = 'train/'\n",
    "        for file in train_set:\n",
    "            src = src_directory + '/' + file\n",
    "            dst = dataset_destination + cv_subdir + dst_dir + subdir  + file    \n",
    "            copyfile(src, dst)\n",
    "\n",
    "        dst_dir = 'test/'\n",
    "        for file in test_set:\n",
    "            src = src_directory + '/' + file\n",
    "            dst = dataset_destination + cv_subdir + dst_dir + subdir  + file    \n",
    "            copyfile(src, dst)\n",
    "        \n",
    "        # Increase cv folder count\n",
    "        cv_index = cv_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Transfer Learning: Mobile Networks - Fine - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "import sys\n",
    "from time import time\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    plt.plot(history.history['loss'],\n",
    "                color='blue', label='loss train')\n",
    "    plt.plot(history.history['val_loss'],\n",
    "                color='orange', label='loss test')\n",
    "    plt.plot(history.history['accuracy'],\n",
    "                color='green', label='accuracy train')\n",
    "    plt.plot(history.history['val_accuracy'],\n",
    "                color='red', label='accuracy test')\n",
    "    plt.ylim(bottom = -0.1, top = 1.1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pretty_print_conf_matrix(y_true, y_pred, \n",
    "                             classes,\n",
    "                             normalize=False,\n",
    "                             title='Confusion matrix',\n",
    "                             cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Mostly stolen from: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "    Normalization changed, classification_report stats added below plot\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Configure Confusion Matrix Plot Aesthetics (no text yet) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylabel('True label', fontsize=12)\n",
    "    plt.xlabel('Predicted label', fontsize=12)\n",
    "\n",
    "    # Calculate normalized values (so all cells sum to 1) if desired\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(),2) #(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Place Numbers as Text on Confusion Matrix Plot\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=12)\n",
    "\n",
    "\n",
    "    # Add Precision, Recall, F-1 Score as Captions Below Plot\n",
    "    rpt = classification_report(y_true, y_pred)\n",
    "    rpt = rpt.replace('avg / total', '      avg')\n",
    "    rpt = rpt.replace('support', 'N Obs')\n",
    "\n",
    "    plt.annotate(rpt, \n",
    "                 xy = (0,0), \n",
    "                 xytext = (-50, -140), \n",
    "                 xycoords='axes fraction', textcoords='offset points',\n",
    "                 fontsize=12, ha='right')    \n",
    "\n",
    "    # Plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def print_metrics(model, datagen, test_path):\n",
    "    \n",
    "    test_it = datagen.flow_from_directory(test_path,\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=64,\n",
    "                                          target_size=(240, 320))\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(test_path,\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=1,\n",
    "                                          target_size=(240, 320))    \n",
    "    # predict probabilities for test set\n",
    "    filenames = test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    true_values = []\n",
    "    predictions = []\n",
    "    for i in range(nb_samples):\n",
    "        x_batch, y_batch = test_generator.next()\n",
    "        name = model.predict(x_batch)\n",
    "        name =  (name>0.5).astype(int)[0][0]\n",
    "        true_name = y_batch[0].astype(np.int)\n",
    "        label_map = (test_generator.class_indices)\n",
    "        label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "        prediction = label_map[name]\n",
    "        true_value = label_map[true_name]\n",
    "        true_values.append(true_value)\n",
    "        predictions.append(prediction) \n",
    "    plt.figure()\n",
    "    pretty_print_conf_matrix(true_values, predictions, \n",
    "                             classes= ['Female', 'Male'])\n",
    "\n",
    "\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    k = 0.05\n",
    "    lrate = initial_lrate * exp(-k*epoch)\n",
    "    return lrate\n",
    "\n",
    "def read_pil_image(img_path, height, width):\n",
    "        with open(img_path, 'rb') as f:\n",
    "            return np.array(Image.open(f).convert('RGB').resize((width, height)))\n",
    "\n",
    "def load_all_images(dataset_path, height, width, img_ext='png'):\n",
    "    return np.array([read_pil_image(str(p), height, width) for p in \n",
    "                                    Path(dataset_path).rglob(\"*.\"+img_ext)]) \n",
    "\n",
    "def normalise_features(array):\n",
    "    min_value = -1\n",
    "    max_value = 1\n",
    "    return np.interp(array, (np.amin(array), np.amax(array)),\n",
    "                     (min_value, max_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "#def run_test_harness():\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "dropout = 0.8\n",
    "learning_rate = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:173: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3561 images belonging to 2 classes.\n",
      "Found 1032 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "file = '../data/processed/iris_data/LG2200/gender/train/Male/02463d1896.tiff'\n",
    "width, height = imagesize.get(file)\n",
    "print(width, height)\n",
    "\n",
    "\n",
    "# entry point, run the test harness\n",
    "dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "\n",
    "train_path = dataset_home + 'train/'\n",
    "test_path = dataset_home + 'test/'\n",
    "\n",
    "# prueba = load_all_images(train_path+'Male', height, width, 'tiff')\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "train_datagen.fit(load_all_images(train_path+'Male', height, width, 'tiff'))\n",
    "train_datagen.fit(load_all_images(train_path+'Female', height, width, 'tiff'))\n",
    "# train_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "# train_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "# test_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "# test_datagen.fit(load_all_images(train_path+'Male', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(train_path+'Female', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "\n",
    "# prepare iterators\n",
    "train_it = train_datagen.flow_from_directory(train_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(240, 320))\n",
    "# test_it = test_datagen.flow_from_directory(test_path,\n",
    "#     class_mode='binary', batch_size=batch_size, target_size=(240, 320))    \n",
    "test_it = train_datagen.flow_from_directory(test_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(240, 320)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_it' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3350ae43c277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m history1 = baseModel.fit_generator(train_it, steps_per_epoch=len(train_it), \n\u001b[0m\u001b[0;32m     58\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_it' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "mobilenetModel=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "# for layer in mobilenetModel.layers:\n",
    "#     layer.trainable = False\n",
    "x=mobilenetModel.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "output=Dense(1,activation='sigmoid')(x) #final layer with softmax activation\n",
    "\n",
    "# # define new model\n",
    "baseModel = Model(inputs=mobilenetModel.inputs, outputs=output)\n",
    "\n",
    "# # Check the trainable status of the individual layers\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in baseModel.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 87\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable=False\n",
    "for layer in baseModel.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "for layer in baseModel.layers[fine_tune_at:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "# # Check the trainable status of the individual layers\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in baseModel.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "    \n",
    "# compile model\n",
    "opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "# opt = RMSprop(learning_rate=0.0001, rho=0.99)\n",
    "# opt = Adagrad(learning_rate=0.001)\n",
    "# opt = Adadelta(learning_rate=1.0, rho=0.99)\n",
    "# opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "# opt = Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# opt = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# baseModel.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "baseModel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=5, min_lr=0.01)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# callbacks_list = [ModelCheckpoint(filepath='model.h5', save_best_only=True)]\n",
    "callbacks_list = [tensorboard]\n",
    "# fit model\n",
    "history1 = baseModel.fit_generator(train_it, steps_per_epoch=len(train_it), \n",
    "                                  validation_data=test_it, \n",
    "                                  validation_steps=len(test_it), \n",
    "                                  epochs=epochs, verbose=1,\n",
    "                                  callbacks=callbacks_list)\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = baseModel.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print(train_it.class_indices)\n",
    "#print(baseModel.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history1)\n",
    "#print_metrics(baseModel, test_datagen, test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,853,377\n",
      "Trainable params: 525,313\n",
      "Non-trainable params: 5,328,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x000002477AA60348>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x0000024775723548>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247757C96C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024775581248>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247755814C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247516F0948>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477ADD9AC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247833AA0C8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247833AA7C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E485288>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477ADEB0C8>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000002477E488648>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002478346FFC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E48F288>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783364C08>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024783364C88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783508888>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477ADC69C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002478353CB08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783335608>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783344FC8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002478340F188>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247833FB1C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247833D5908>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000247833D5988>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247834B5BC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247834BAC48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247834BCF48>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024783260B88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783254D48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247832858C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247832D2E88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247832ECF88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783302148>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024783309E88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783569CC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002478358AC08>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000247835AA208>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247835B9F48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247835C3A88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247835C8248>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247835CE548>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247835E0108>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783610C48>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002478362D188>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002478363EDC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002476FF31708>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002476FF31F88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002478321DBC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783228648>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x0000024783234888>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247759EF9C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002475234C048>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024752343E88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024770189608>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477526DB48>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247751EF248>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477ADA30C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002476FF41388>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024751818FC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247700D91C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247700F7B88>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247700E7808>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477AE64CC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247517FC188>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247517FCD48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247518BEA88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247519EE948>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247519EEE08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024751635908>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247515D6048>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002477E93F288>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477EF08708>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477EF08F08>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x0000024751381208>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002477E48AF08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E49FB48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477E4A10C8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002477E47CA88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477ADE73C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477ADE7208>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002477ADE4FC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E607D08>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477E607B08>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002477E60F748>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477AF56508>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477B0F6DC8>: False\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x00000247759F3E48>: True\n",
      "<keras.layers.core.Dense object at 0x0000024783AC6388>: True\n",
      "<keras.layers.core.Dense object at 0x000002477E799288>: True\n",
      "<keras.layers.core.Dense object at 0x000002477E7781C8>: True\n",
      "<keras.layers.core.Dense object at 0x000002477E78FC08>: True\n"
     ]
    }
   ],
   "source": [
    "# Check the trainable status of the individual layers\n",
    "print(\"\\r\\r\\r\\r\")\n",
    "for layer in baseModel.layers:\n",
    "    print(\"{}: {}\".format(layer, layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel.save('Base_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/200\n",
      "112/112 [==============================] - 67s 598ms/step - loss: 0.3642 - accuracy: 0.8450 - val_loss: 0.4700 - val_accuracy: 0.7519\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 61s 542ms/step - loss: 0.3631 - accuracy: 0.8436 - val_loss: 0.3358 - val_accuracy: 0.7287\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 62s 551ms/step - loss: 0.3559 - accuracy: 0.8470 - val_loss: 0.6177 - val_accuracy: 0.7316\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 59s 524ms/step - loss: 0.3528 - accuracy: 0.8489 - val_loss: 0.3805 - val_accuracy: 0.7277\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 59s 525ms/step - loss: 0.3511 - accuracy: 0.8481 - val_loss: 0.3427 - val_accuracy: 0.7345\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.3456 - accuracy: 0.8562 - val_loss: 0.5889 - val_accuracy: 0.7306\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 62s 552ms/step - loss: 0.3409 - accuracy: 0.8568 - val_loss: 0.5061 - val_accuracy: 0.7306\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 62s 557ms/step - loss: 0.3382 - accuracy: 0.8540 - val_loss: 0.4032 - val_accuracy: 0.7306\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 59s 525ms/step - loss: 0.3377 - accuracy: 0.8610 - val_loss: 0.2626 - val_accuracy: 0.7374\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 59s 527ms/step - loss: 0.3333 - accuracy: 0.8616 - val_loss: 0.6344 - val_accuracy: 0.7374\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 64s 572ms/step - loss: 0.3250 - accuracy: 0.8711 - val_loss: 0.2783 - val_accuracy: 0.7432\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 64s 570ms/step - loss: 0.3199 - accuracy: 0.8719 - val_loss: 0.7848 - val_accuracy: 0.7384\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 66s 588ms/step - loss: 0.3207 - accuracy: 0.8635 - val_loss: 0.5822 - val_accuracy: 0.7452\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 63s 562ms/step - loss: 0.3134 - accuracy: 0.8719 - val_loss: 0.5326 - val_accuracy: 0.7442\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 59s 527ms/step - loss: 0.3121 - accuracy: 0.8725 - val_loss: 0.2156 - val_accuracy: 0.7452\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 62s 550ms/step - loss: 0.3136 - accuracy: 0.8748 - val_loss: 0.2808 - val_accuracy: 0.7539\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 54s 482ms/step - loss: 0.3056 - accuracy: 0.8750 - val_loss: 0.6865 - val_accuracy: 0.7490\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 52s 464ms/step - loss: 0.3005 - accuracy: 0.8826 - val_loss: 0.3285 - val_accuracy: 0.7539\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.3012 - accuracy: 0.8745 - val_loss: 0.6495 - val_accuracy: 0.7539\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 56s 503ms/step - loss: 0.2989 - accuracy: 0.8798 - val_loss: 0.5305 - val_accuracy: 0.7539\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 59s 528ms/step - loss: 0.2938 - accuracy: 0.8857 - val_loss: 0.6280 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 57s 511ms/step - loss: 0.2914 - accuracy: 0.8798 - val_loss: 0.4947 - val_accuracy: 0.7568\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 59s 528ms/step - loss: 0.2935 - accuracy: 0.8818 - val_loss: 0.2276 - val_accuracy: 0.7548\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 65s 581ms/step - loss: 0.2889 - accuracy: 0.8854 - val_loss: 0.7810 - val_accuracy: 0.7587\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 62s 556ms/step - loss: 0.2796 - accuracy: 0.8939 - val_loss: 0.8693 - val_accuracy: 0.7636\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 62s 558ms/step - loss: 0.2806 - accuracy: 0.8930 - val_loss: 0.9367 - val_accuracy: 0.7597\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 60s 532ms/step - loss: 0.2770 - accuracy: 0.8939 - val_loss: 0.6734 - val_accuracy: 0.7616\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 59s 525ms/step - loss: 0.2712 - accuracy: 0.8986 - val_loss: 0.8479 - val_accuracy: 0.7684\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 59s 528ms/step - loss: 0.2721 - accuracy: 0.8944 - val_loss: 0.3509 - val_accuracy: 0.7655\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 59s 526ms/step - loss: 0.2737 - accuracy: 0.8953 - val_loss: 0.9020 - val_accuracy: 0.7694\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 60s 538ms/step - loss: 0.2682 - accuracy: 0.8995 - val_loss: 0.3095 - val_accuracy: 0.7694\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 59s 527ms/step - loss: 0.2575 - accuracy: 0.9045 - val_loss: 0.4155 - val_accuracy: 0.7674\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 61s 544ms/step - loss: 0.2525 - accuracy: 0.9093 - val_loss: 0.5181 - val_accuracy: 0.7684\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 64s 567ms/step - loss: 0.2523 - accuracy: 0.9073 - val_loss: 0.3905 - val_accuracy: 0.7645\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 64s 572ms/step - loss: 0.2499 - accuracy: 0.9073 - val_loss: 0.6006 - val_accuracy: 0.7645\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 66s 593ms/step - loss: 0.2487 - accuracy: 0.9093 - val_loss: 0.4322 - val_accuracy: 0.7674\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 68s 610ms/step - loss: 0.2527 - accuracy: 0.9085 - val_loss: 0.5500 - val_accuracy: 0.7694\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 59s 526ms/step - loss: 0.2413 - accuracy: 0.9155 - val_loss: 0.1780 - val_accuracy: 0.7703\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 59s 529ms/step - loss: 0.2385 - accuracy: 0.9149 - val_loss: 0.4085 - val_accuracy: 0.7723\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 60s 536ms/step - loss: 0.2371 - accuracy: 0.9149 - val_loss: 0.2449 - val_accuracy: 0.7703\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.2353 - accuracy: 0.9135 - val_loss: 0.5568 - val_accuracy: 0.7713\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 61s 545ms/step - loss: 0.2246 - accuracy: 0.9253 - val_loss: 0.3709 - val_accuracy: 0.7694\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 63s 559ms/step - loss: 0.2368 - accuracy: 0.9186 - val_loss: 0.8113 - val_accuracy: 0.7703\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 63s 562ms/step - loss: 0.2273 - accuracy: 0.9180 - val_loss: 0.5621 - val_accuracy: 0.7723\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 64s 576ms/step - loss: 0.2305 - accuracy: 0.9138 - val_loss: 0.7778 - val_accuracy: 0.7733\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 61s 546ms/step - loss: 0.2233 - accuracy: 0.9231 - val_loss: 0.5188 - val_accuracy: 0.7733\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 61s 544ms/step - loss: 0.2234 - accuracy: 0.9222 - val_loss: 0.9683 - val_accuracy: 0.7713\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 60s 535ms/step - loss: 0.2206 - accuracy: 0.9239 - val_loss: 0.5296 - val_accuracy: 0.7742\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 61s 540ms/step - loss: 0.2155 - accuracy: 0.9275 - val_loss: 0.2755 - val_accuracy: 0.7733\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 60s 540ms/step - loss: 0.2177 - accuracy: 0.9219 - val_loss: 0.2681 - val_accuracy: 0.7733\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 60s 536ms/step - loss: 0.2111 - accuracy: 0.9275 - val_loss: 0.7163 - val_accuracy: 0.7781\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 64s 570ms/step - loss: 0.2084 - accuracy: 0.9287 - val_loss: 0.3405 - val_accuracy: 0.7771\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 62s 552ms/step - loss: 0.2048 - accuracy: 0.9312 - val_loss: 0.2520 - val_accuracy: 0.7800\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 63s 565ms/step - loss: 0.2061 - accuracy: 0.9320 - val_loss: 0.5144 - val_accuracy: 0.7800\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 61s 542ms/step - loss: 0.2097 - accuracy: 0.9264 - val_loss: 0.5150 - val_accuracy: 0.7810\n",
      "Epoch 56/200\n",
      "112/112 [==============================] - 61s 546ms/step - loss: 0.2063 - accuracy: 0.9278 - val_loss: 0.2882 - val_accuracy: 0.7771\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 61s 547ms/step - loss: 0.2048 - accuracy: 0.9270 - val_loss: 1.2427 - val_accuracy: 0.7810\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 61s 542ms/step - loss: 0.1934 - accuracy: 0.9360 - val_loss: 0.3158 - val_accuracy: 0.7781\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 60s 534ms/step - loss: 0.1942 - accuracy: 0.9385 - val_loss: 0.7456 - val_accuracy: 0.7791\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 61s 540ms/step - loss: 0.1866 - accuracy: 0.9374 - val_loss: 0.4754 - val_accuracy: 0.7800\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 61s 546ms/step - loss: 0.1934 - accuracy: 0.9346 - val_loss: 0.2554 - val_accuracy: 0.7781\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 60s 535ms/step - loss: 0.1884 - accuracy: 0.9374 - val_loss: 0.4810 - val_accuracy: 0.7800\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 58s 521ms/step - loss: 0.1844 - accuracy: 0.9407 - val_loss: 0.1101 - val_accuracy: 0.7791\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 60s 533ms/step - loss: 0.1884 - accuracy: 0.9346 - val_loss: 0.1097 - val_accuracy: 0.7810\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 60s 534ms/step - loss: 0.1939 - accuracy: 0.9326 - val_loss: 0.3617 - val_accuracy: 0.7839\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 60s 539ms/step - loss: 0.1848 - accuracy: 0.9436 - val_loss: 0.7635 - val_accuracy: 0.7800\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 61s 545ms/step - loss: 0.1850 - accuracy: 0.9396 - val_loss: 0.3355 - val_accuracy: 0.7820\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 61s 540ms/step - loss: 0.1825 - accuracy: 0.9436 - val_loss: 0.4148 - val_accuracy: 0.7820\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 60s 533ms/step - loss: 0.1790 - accuracy: 0.9433 - val_loss: 0.3471 - val_accuracy: 0.7820\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 61s 544ms/step - loss: 0.1729 - accuracy: 0.9441 - val_loss: 0.0988 - val_accuracy: 0.7829\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 61s 546ms/step - loss: 0.1669 - accuracy: 0.9492 - val_loss: 0.1181 - val_accuracy: 0.7829\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 62s 557ms/step - loss: 0.1624 - accuracy: 0.9511 - val_loss: 0.9712 - val_accuracy: 0.7839\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 59s 526ms/step - loss: 0.1636 - accuracy: 0.9486 - val_loss: 0.2098 - val_accuracy: 0.7859\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 60s 534ms/step - loss: 0.1722 - accuracy: 0.9455 - val_loss: 0.2261 - val_accuracy: 0.7849\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 60s 538ms/step - loss: 0.1667 - accuracy: 0.9458 - val_loss: 0.6519 - val_accuracy: 0.7859\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 60s 534ms/step - loss: 0.1644 - accuracy: 0.9506 - val_loss: 0.2022 - val_accuracy: 0.7849\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 60s 534ms/step - loss: 0.1601 - accuracy: 0.9553 - val_loss: 1.0241 - val_accuracy: 0.7849\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 60s 535ms/step - loss: 0.1611 - accuracy: 0.9528 - val_loss: 0.4651 - val_accuracy: 0.7868\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 59s 528ms/step - loss: 0.1586 - accuracy: 0.9503 - val_loss: 0.2169 - val_accuracy: 0.7936\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 61s 548ms/step - loss: 0.1518 - accuracy: 0.9531 - val_loss: 0.4082 - val_accuracy: 0.7868\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 59s 523ms/step - loss: 0.1648 - accuracy: 0.9475 - val_loss: 1.0334 - val_accuracy: 0.7878\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 60s 535ms/step - loss: 0.1467 - accuracy: 0.9573 - val_loss: 0.4871 - val_accuracy: 0.7859\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 59s 531ms/step - loss: 0.1488 - accuracy: 0.9584 - val_loss: 0.6869 - val_accuracy: 0.7878\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 59s 522ms/step - loss: 0.1517 - accuracy: 0.9525 - val_loss: 0.8391 - val_accuracy: 0.7868\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 65s 579ms/step - loss: 0.1520 - accuracy: 0.9528 - val_loss: 0.6450 - val_accuracy: 0.7907\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 63s 564ms/step - loss: 0.1481 - accuracy: 0.9587 - val_loss: 0.1703 - val_accuracy: 0.7936\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 60s 540ms/step - loss: 0.1487 - accuracy: 0.9582 - val_loss: 0.3235 - val_accuracy: 0.7888\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.1419 - accuracy: 0.9587 - val_loss: 0.6298 - val_accuracy: 0.7926\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 62s 549ms/step - loss: 0.1407 - accuracy: 0.9629 - val_loss: 0.8861 - val_accuracy: 0.7859\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 53s 474ms/step - loss: 0.1444 - accuracy: 0.9551 - val_loss: 0.9941 - val_accuracy: 0.7917\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 51s 458ms/step - loss: 0.1390 - accuracy: 0.9601 - val_loss: 0.8576 - val_accuracy: 0.7917\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 53s 472ms/step - loss: 0.1385 - accuracy: 0.9601 - val_loss: 0.6035 - val_accuracy: 0.7926\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.1387 - accuracy: 0.9559 - val_loss: 0.2244 - val_accuracy: 0.7878\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 53s 469ms/step - loss: 0.1326 - accuracy: 0.9657 - val_loss: 0.3437 - val_accuracy: 0.7926\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 52s 464ms/step - loss: 0.1259 - accuracy: 0.9714 - val_loss: 0.1870 - val_accuracy: 0.7946\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 53s 471ms/step - loss: 0.1324 - accuracy: 0.9621 - val_loss: 0.0372 - val_accuracy: 0.7955\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 52s 464ms/step - loss: 0.1293 - accuracy: 0.9657 - val_loss: 0.1398 - val_accuracy: 0.7917\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 53s 474ms/step - loss: 0.1311 - accuracy: 0.9660 - val_loss: 0.2349 - val_accuracy: 0.7946\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 51s 459ms/step - loss: 0.1263 - accuracy: 0.9649 - val_loss: 1.2533 - val_accuracy: 0.7965\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.1265 - accuracy: 0.9655 - val_loss: 0.2668 - val_accuracy: 0.7965\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 52s 465ms/step - loss: 0.1223 - accuracy: 0.9702 - val_loss: 0.2004 - val_accuracy: 0.7955\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 51s 458ms/step - loss: 0.1238 - accuracy: 0.9671 - val_loss: 0.3121 - val_accuracy: 0.7984\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.1153 - accuracy: 0.9736 - val_loss: 0.2612 - val_accuracy: 0.7965\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 53s 471ms/step - loss: 0.1190 - accuracy: 0.9680 - val_loss: 0.2765 - val_accuracy: 0.7965\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 0.1146 - accuracy: 0.9728 - val_loss: 1.1640 - val_accuracy: 0.7975\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 53s 469ms/step - loss: 0.1139 - accuracy: 0.9666 - val_loss: 0.1551 - val_accuracy: 0.7994\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 63s 562ms/step - loss: 0.1154 - accuracy: 0.9719 - val_loss: 0.3298 - val_accuracy: 0.8014\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 63s 564ms/step - loss: 0.1174 - accuracy: 0.9711 - val_loss: 0.9546 - val_accuracy: 0.7975\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 63s 561ms/step - loss: 0.1090 - accuracy: 0.9758 - val_loss: 0.1286 - val_accuracy: 0.7984\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 62s 552ms/step - loss: 0.1145 - accuracy: 0.9714 - val_loss: 0.5319 - val_accuracy: 0.8004\n",
      "Epoch 111/200\n",
      "112/112 [==============================] - 60s 536ms/step - loss: 0.1092 - accuracy: 0.9739 - val_loss: 0.4725 - val_accuracy: 0.7994\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 57s 506ms/step - loss: 0.1066 - accuracy: 0.9747 - val_loss: 0.5376 - val_accuracy: 0.8023\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 58s 517ms/step - loss: 0.1052 - accuracy: 0.9773 - val_loss: 0.7780 - val_accuracy: 0.8023\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 62s 551ms/step - loss: 0.1102 - accuracy: 0.9742 - val_loss: 0.5728 - val_accuracy: 0.8014\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 61s 549ms/step - loss: 0.1083 - accuracy: 0.9697 - val_loss: 0.3431 - val_accuracy: 0.8052\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 59s 530ms/step - loss: 0.1069 - accuracy: 0.9733 - val_loss: 0.4293 - val_accuracy: 0.8023\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 59s 529ms/step - loss: 0.1038 - accuracy: 0.9744 - val_loss: 0.2727 - val_accuracy: 0.8043\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 59s 526ms/step - loss: 0.1068 - accuracy: 0.9725 - val_loss: 0.6141 - val_accuracy: 0.8052\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 59s 530ms/step - loss: 0.1062 - accuracy: 0.9744 - val_loss: 0.8172 - val_accuracy: 0.8062\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 59s 528ms/step - loss: 0.0999 - accuracy: 0.9795 - val_loss: 0.1627 - val_accuracy: 0.8062\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 59s 522ms/step - loss: 0.0985 - accuracy: 0.9803 - val_loss: 0.4799 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 59s 530ms/step - loss: 0.1019 - accuracy: 0.9761 - val_loss: 0.1264 - val_accuracy: 0.8062\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 58s 518ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.1568 - val_accuracy: 0.8033\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 55s 495ms/step - loss: 0.0890 - accuracy: 0.9854 - val_loss: 0.1472 - val_accuracy: 0.8023\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 53s 477ms/step - loss: 0.0981 - accuracy: 0.9742 - val_loss: 0.8400 - val_accuracy: 0.8023\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 52s 464ms/step - loss: 0.0972 - accuracy: 0.9812 - val_loss: 0.3743 - val_accuracy: 0.8081\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 53s 470ms/step - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.4371 - val_accuracy: 0.8072\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.0898 - accuracy: 0.9829 - val_loss: 0.0697 - val_accuracy: 0.8091\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 53s 477ms/step - loss: 0.0914 - accuracy: 0.9781 - val_loss: 0.0218 - val_accuracy: 0.8072\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 54s 484ms/step - loss: 0.0931 - accuracy: 0.9778 - val_loss: 0.2763 - val_accuracy: 0.8081\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.0887 - accuracy: 0.9820 - val_loss: 0.3972 - val_accuracy: 0.8081\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 53s 476ms/step - loss: 0.0910 - accuracy: 0.9815 - val_loss: 0.8022 - val_accuracy: 0.8062\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 53s 469ms/step - loss: 0.0856 - accuracy: 0.9803 - val_loss: 0.1807 - val_accuracy: 0.8101\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 53s 469ms/step - loss: 0.0886 - accuracy: 0.9834 - val_loss: 0.4911 - val_accuracy: 0.8014\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 53s 476ms/step - loss: 0.0848 - accuracy: 0.9868 - val_loss: 0.5976 - val_accuracy: 0.8052\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 52s 465ms/step - loss: 0.0838 - accuracy: 0.9817 - val_loss: 0.3612 - val_accuracy: 0.8043\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 52s 466ms/step - loss: 0.0807 - accuracy: 0.9851 - val_loss: 0.4797 - val_accuracy: 0.8081\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.0818 - accuracy: 0.9809 - val_loss: 0.3757 - val_accuracy: 0.8091\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 53s 470ms/step - loss: 0.0796 - accuracy: 0.9846 - val_loss: 1.1100 - val_accuracy: 0.8062\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 0.0848 - accuracy: 0.9815 - val_loss: 0.1684 - val_accuracy: 0.8101\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.0819 - accuracy: 0.9820 - val_loss: 0.3682 - val_accuracy: 0.8101\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 52s 462ms/step - loss: 0.0797 - accuracy: 0.9837 - val_loss: 0.1574 - val_accuracy: 0.8110\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 53s 472ms/step - loss: 0.0738 - accuracy: 0.9893 - val_loss: 0.4975 - val_accuracy: 0.8110\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.0765 - accuracy: 0.9865 - val_loss: 0.3021 - val_accuracy: 0.8110\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 52s 460ms/step - loss: 0.0711 - accuracy: 0.9899 - val_loss: 0.1894 - val_accuracy: 0.8110\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 53s 471ms/step - loss: 0.0730 - accuracy: 0.9874 - val_loss: 0.0189 - val_accuracy: 0.8091\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.0731 - accuracy: 0.9857 - val_loss: 0.5353 - val_accuracy: 0.8101\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.0723 - accuracy: 0.9910 - val_loss: 0.1022 - val_accuracy: 0.8101\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 53s 472ms/step - loss: 0.0760 - accuracy: 0.9846 - val_loss: 0.3253 - val_accuracy: 0.8101\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 0.0750 - accuracy: 0.9860 - val_loss: 0.4214 - val_accuracy: 0.8101\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 53s 471ms/step - loss: 0.0696 - accuracy: 0.9882 - val_loss: 0.2884 - val_accuracy: 0.8110\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 52s 466ms/step - loss: 0.0755 - accuracy: 0.9851 - val_loss: 0.4158 - val_accuracy: 0.8091\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.0721 - accuracy: 0.9885 - val_loss: 0.2630 - val_accuracy: 0.8101\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 52s 468ms/step - loss: 0.0759 - accuracy: 0.9846 - val_loss: 0.4524 - val_accuracy: 0.8091\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 53s 474ms/step - loss: 0.0703 - accuracy: 0.9868 - val_loss: 0.8235 - val_accuracy: 0.8101\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 52s 467ms/step - loss: 0.0687 - accuracy: 0.9879 - val_loss: 0.4433 - val_accuracy: 0.8091\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 52s 465ms/step - loss: 0.0712 - accuracy: 0.9879 - val_loss: 1.4152 - val_accuracy: 0.8091\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 53s 471ms/step - loss: 0.0672 - accuracy: 0.9907 - val_loss: 0.7441 - val_accuracy: 0.8081\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 0.0675 - accuracy: 0.9865 - val_loss: 0.0717 - val_accuracy: 0.8091\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 51s 452ms/step - loss: 0.0610 - accuracy: 0.9913 - val_loss: 0.1524 - val_accuracy: 0.8130\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 51s 459ms/step - loss: 0.0617 - accuracy: 0.9896 - val_loss: 0.7743 - val_accuracy: 0.8120\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 51s 460ms/step - loss: 0.0612 - accuracy: 0.9913 - val_loss: 0.2124 - val_accuracy: 0.8120\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 52s 460ms/step - loss: 0.0634 - accuracy: 0.9913 - val_loss: 0.2759 - val_accuracy: 0.8110\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 51s 454ms/step - loss: 0.0662 - accuracy: 0.9885 - val_loss: 0.6320 - val_accuracy: 0.8140\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 53s 473ms/step - loss: 0.0559 - accuracy: 0.9944 - val_loss: 0.8038 - val_accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "112/112 [==============================] - 51s 453ms/step - loss: 0.0633 - accuracy: 0.9874 - val_loss: 0.0863 - val_accuracy: 0.8120\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 51s 455ms/step - loss: 0.0588 - accuracy: 0.9919 - val_loss: 0.1765 - val_accuracy: 0.8120\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 53s 474ms/step - loss: 0.0556 - accuracy: 0.9938 - val_loss: 0.6024 - val_accuracy: 0.8120\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 59s 524ms/step - loss: 0.0656 - accuracy: 0.9888 - val_loss: 0.0438 - val_accuracy: 0.8149\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 60s 540ms/step - loss: 0.0646 - accuracy: 0.9868 - val_loss: 0.5144 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 57s 506ms/step - loss: 0.0628 - accuracy: 0.9910 - val_loss: 0.1729 - val_accuracy: 0.8110\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 59s 528ms/step - loss: 0.0544 - accuracy: 0.9944 - val_loss: 0.2756 - val_accuracy: 0.8110\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 58s 521ms/step - loss: 0.0553 - accuracy: 0.9927 - val_loss: 0.4652 - val_accuracy: 0.8130\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.0546 - accuracy: 0.9921 - val_loss: 0.1077 - val_accuracy: 0.8140\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 58s 518ms/step - loss: 0.0548 - accuracy: 0.9927 - val_loss: 0.1239 - val_accuracy: 0.8140\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 57s 509ms/step - loss: 0.0530 - accuracy: 0.9938 - val_loss: 0.1518 - val_accuracy: 0.8140\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 57s 509ms/step - loss: 0.0519 - accuracy: 0.9927 - val_loss: 0.1532 - val_accuracy: 0.8149\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 59s 523ms/step - loss: 0.0580 - accuracy: 0.9902 - val_loss: 0.4048 - val_accuracy: 0.8178\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 62s 557ms/step - loss: 0.0583 - accuracy: 0.9902 - val_loss: 0.1002 - val_accuracy: 0.8159\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 61s 549ms/step - loss: 0.0565 - accuracy: 0.9910 - val_loss: 0.2199 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 60s 533ms/step - loss: 0.0531 - accuracy: 0.9935 - val_loss: 0.6915 - val_accuracy: 0.8169\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 58s 515ms/step - loss: 0.0523 - accuracy: 0.9941 - val_loss: 0.3225 - val_accuracy: 0.8169\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 57s 513ms/step - loss: 0.0505 - accuracy: 0.9949 - val_loss: 0.1293 - val_accuracy: 0.8169\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 61s 543ms/step - loss: 0.0533 - accuracy: 0.9916 - val_loss: 0.6177 - val_accuracy: 0.8120\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 59s 530ms/step - loss: 0.0509 - accuracy: 0.9941 - val_loss: 0.2850 - val_accuracy: 0.8149\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - 60s 535ms/step - loss: 0.0508 - accuracy: 0.9938 - val_loss: 0.1652 - val_accuracy: 0.8120\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.0474 - accuracy: 0.9958 - val_loss: 0.0318 - val_accuracy: 0.8120\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 61s 545ms/step - loss: 0.0440 - accuracy: 0.9969 - val_loss: 0.0835 - val_accuracy: 0.8169\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 61s 543ms/step - loss: 0.0562 - accuracy: 0.9902 - val_loss: 0.1569 - val_accuracy: 0.8140\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 61s 547ms/step - loss: 0.0447 - accuracy: 0.9966 - val_loss: 0.8794 - val_accuracy: 0.8140\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.0456 - accuracy: 0.9952 - val_loss: 0.3539 - val_accuracy: 0.8159\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 58s 518ms/step - loss: 0.0463 - accuracy: 0.9924 - val_loss: 0.9921 - val_accuracy: 0.8149\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 56s 496ms/step - loss: 0.0454 - accuracy: 0.9955 - val_loss: 0.1374 - val_accuracy: 0.8159\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 57s 512ms/step - loss: 0.0506 - accuracy: 0.9919 - val_loss: 0.0453 - val_accuracy: 0.8217\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 54s 485ms/step - loss: 0.0434 - accuracy: 0.9961 - val_loss: 0.2871 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 56s 503ms/step - loss: 0.0534 - accuracy: 0.9893 - val_loss: 0.4250 - val_accuracy: 0.8207\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 56s 497ms/step - loss: 0.0443 - accuracy: 0.9955 - val_loss: 0.1569 - val_accuracy: 0.8169\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 61s 541ms/step - loss: 0.0408 - accuracy: 0.9969 - val_loss: 0.0619 - val_accuracy: 0.8159\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 54s 486ms/step - loss: 0.0558 - accuracy: 0.9890 - val_loss: 0.8893 - val_accuracy: 0.8236\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 59s 527ms/step - loss: 0.0439 - accuracy: 0.9930 - val_loss: 0.4757 - val_accuracy: 0.8178\n",
      "{'Female': 0, 'Male': 1}\n",
      "> 81.783\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Duplicate Model\n",
    "# model= clone_model(baseModel)\n",
    "model_with_last_20_layers = load_model('Base_Model.h5')\n",
    "\n",
    "# # loop over the layers in the model and show which ones are trainable\n",
    "# # or not\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in model_with_last_20_layers.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 20\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in model_with_last_20_layers.layers:\n",
    "    layer.trainable=False\n",
    "for layer in model_with_last_20_layers.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "for layer in model_with_last_20_layers.layers[fine_tune_at:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "\n",
    "# # loop over the layers in the model and show which ones are trainable\n",
    "# # or not\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in model_with_last_20_layers.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# compile model\n",
    "#opt = SGD(lr=1.0e-6, momentum=0.9)\n",
    "opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "model_with_last_20_layers.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=5, min_lr=0.001)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# callbacks_list = [ModelCheckpoint(filepath='model.h5', save_best_only=True)]\n",
    "callbacks_list = [tensorboard]\n",
    "# fit model\n",
    "history_awith_last_20_layers = model_with_last_20_layers.fit_generator(train_it, steps_per_epoch=len(train_it), \n",
    "                                                                      validation_data=test_it, \n",
    "                                                                      validation_steps=len(test_it), \n",
    "                                                                      epochs=epochs, verbose=1, \n",
    "                                                                      callbacks=callbacks_list)\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = model_with_last_20_layers.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print(train_it.class_indices)\n",
    "#print(model.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history_awith_last_20_layers)\n",
    "#print_metrics(model, test_datagen, test_path)\n",
    "    \n",
    "    \n",
    "# entry point, run the test harness\n",
    "# dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "#run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_last_20_layers.save('Base_Model_fine_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n",
      "Found 4630 images belonging to 2 classes.\n",
      "> 74.428\n"
     ]
    }
   ],
   "source": [
    "test_path = '../data/raw/iris_data/LG4000/gender/'\n",
    "\n",
    "# Duplicate Model\n",
    "# model= clone_model(baseModel)\n",
    "model = load_model('Base_Model_fine_tuned.h5')\n",
    "\n",
    "\n",
    "# entry point, run the test harness\n",
    "file = '../data/processed/iris_data/LG2200/gender/train/Male/02463d1896.tiff'\n",
    "width, height = imagesize.get(file)\n",
    "print(width, height)\n",
    "\n",
    "\n",
    "# prueba = load_all_images(train_path+'Male', height, width, 'tiff')\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "train_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "train_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "# prepare iterators\n",
    "test_it = train_datagen.flow_from_directory(test_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(240, 320)) \n",
    "\n",
    "\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "#print(model.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 224x224 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "import sys\n",
    "from time import time\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    plt.plot(history.history['loss'],\n",
    "                color='blue', label='loss train')\n",
    "    plt.plot(history.history['val_loss'],\n",
    "                color='orange', label='loss test')\n",
    "    plt.plot(history.history['accuracy'],\n",
    "                color='green', label='accuracy train')\n",
    "    plt.plot(history.history['val_accuracy'],\n",
    "                color='red', label='accuracy test')\n",
    "    plt.ylim(bottom = -0.1, top = 1.1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pretty_print_conf_matrix(y_true, y_pred, \n",
    "                             classes,\n",
    "                             normalize=False,\n",
    "                             title='Confusion matrix',\n",
    "                             cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Mostly stolen from: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "    Normalization changed, classification_report stats added below plot\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Configure Confusion Matrix Plot Aesthetics (no text yet) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylabel('True label', fontsize=12)\n",
    "    plt.xlabel('Predicted label', fontsize=12)\n",
    "\n",
    "    # Calculate normalized values (so all cells sum to 1) if desired\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(),2) #(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Place Numbers as Text on Confusion Matrix Plot\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=12)\n",
    "\n",
    "\n",
    "    # Add Precision, Recall, F-1 Score as Captions Below Plot\n",
    "    rpt = classification_report(y_true, y_pred)\n",
    "    rpt = rpt.replace('avg / total', '      avg')\n",
    "    rpt = rpt.replace('support', 'N Obs')\n",
    "\n",
    "    plt.annotate(rpt, \n",
    "                 xy = (0,0), \n",
    "                 xytext = (-50, -140), \n",
    "                 xycoords='axes fraction', textcoords='offset points',\n",
    "                 fontsize=12, ha='right')    \n",
    "\n",
    "    # Plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def print_metrics(model, datagen, test_path):\n",
    "    \n",
    "    test_it = datagen.flow_from_directory(test_path,\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=64,\n",
    "                                          target_size=(240, 320))\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(test_path,\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=1,\n",
    "                                          target_size=(240, 320))    \n",
    "    # predict probabilities for test set\n",
    "    filenames = test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    true_values = []\n",
    "    predictions = []\n",
    "    for i in range(nb_samples):\n",
    "        x_batch, y_batch = test_generator.next()\n",
    "        name = model.predict(x_batch)\n",
    "        name =  (name>0.5).astype(int)[0][0]\n",
    "        true_name = y_batch[0].astype(np.int)\n",
    "        label_map = (test_generator.class_indices)\n",
    "        label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "        prediction = label_map[name]\n",
    "        true_value = label_map[true_name]\n",
    "        true_values.append(true_value)\n",
    "        predictions.append(prediction) \n",
    "    plt.figure()\n",
    "    pretty_print_conf_matrix(true_values, predictions, \n",
    "                             classes= ['Female', 'Male'])\n",
    "\n",
    "\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    k = 0.05\n",
    "    lrate = initial_lrate * exp(-k*epoch)\n",
    "    return lrate\n",
    "\n",
    "def read_pil_image(img_path, height, width):\n",
    "        with open(img_path, 'rb') as f:\n",
    "            return np.array(Image.open(f).convert('RGB').resize((width, height)))\n",
    "\n",
    "def load_all_images(dataset_path, height, width, img_ext='png'):\n",
    "    return np.array([read_pil_image(str(p), height, width) for p in \n",
    "                                    Path(dataset_path).rglob(\"*.\"+img_ext)]) \n",
    "\n",
    "def normalise_features(array):\n",
    "    min_value = -1\n",
    "    max_value = 1\n",
    "    return np.interp(array, (np.amin(array), np.amax(array)),\n",
    "                     (min_value, max_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "#def run_test_harness():\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "dropout = 0.8\n",
    "learning_rate = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:173: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3561 images belonging to 2 classes.\n",
      "Found 1032 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "file = '../data/processed/iris_data/LG2200/gender/train/Male/02463d1896.tiff'\n",
    "width, height = imagesize.get(file)\n",
    "print(width, height)\n",
    "\n",
    "\n",
    "# entry point, run the test harness\n",
    "dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "\n",
    "train_path = dataset_home + 'train/'\n",
    "test_path = dataset_home + 'test/'\n",
    "\n",
    "# prueba = load_all_images(train_path+'Male', height, width, 'tiff')\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "train_datagen.fit(load_all_images(train_path+'Male', height, width, 'tiff'))\n",
    "train_datagen.fit(load_all_images(train_path+'Female', height, width, 'tiff'))\n",
    "# train_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "# train_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "# test_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "# test_datagen.fit(load_all_images(train_path+'Male', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(train_path+'Female', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "\n",
    "# prepare iterators\n",
    "train_it = train_datagen.flow_from_directory(train_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(224, 224))\n",
    "# test_it = test_datagen.flow_from_directory(test_path,\n",
    "#     class_mode='binary', batch_size=batch_size, target_size=(240, 320))    \n",
    "test_it = train_datagen.flow_from_directory(test_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/200\n",
      "112/112 [==============================] - 44s 392ms/step - loss: 0.6998 - accuracy: 0.5074 - val_loss: 0.6359 - val_accuracy: 0.5068\n",
      "WARNING:tensorflow:From D:\\vhcg77\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.6914 - accuracy: 0.5352 - val_loss: 0.8573 - val_accuracy: 0.5068\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.6855 - accuracy: 0.5484 - val_loss: 0.6152 - val_accuracy: 0.4932\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.6818 - accuracy: 0.5538 - val_loss: 0.8506 - val_accuracy: 0.5048\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.6774 - accuracy: 0.5715 - val_loss: 0.7588 - val_accuracy: 0.5087\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.6742 - accuracy: 0.5844 - val_loss: 0.6613 - val_accuracy: 0.5165\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.6693 - accuracy: 0.5993 - val_loss: 0.7853 - val_accuracy: 0.5203\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.6674 - accuracy: 0.6057 - val_loss: 0.7047 - val_accuracy: 0.5271\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.6620 - accuracy: 0.6116 - val_loss: 0.7429 - val_accuracy: 0.5339\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.6570 - accuracy: 0.6349 - val_loss: 0.7627 - val_accuracy: 0.5359\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.6561 - accuracy: 0.6358 - val_loss: 0.6143 - val_accuracy: 0.5397\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.6509 - accuracy: 0.6479 - val_loss: 0.6713 - val_accuracy: 0.5446\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.6482 - accuracy: 0.6498 - val_loss: 0.6460 - val_accuracy: 0.5494\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.6446 - accuracy: 0.6689 - val_loss: 0.6304 - val_accuracy: 0.5543\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.6416 - accuracy: 0.6740 - val_loss: 0.6487 - val_accuracy: 0.5610\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.6388 - accuracy: 0.6799 - val_loss: 0.6947 - val_accuracy: 0.5620\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.6360 - accuracy: 0.6821 - val_loss: 0.6463 - val_accuracy: 0.5678\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.6322 - accuracy: 0.6818 - val_loss: 0.7337 - val_accuracy: 0.5698\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.6291 - accuracy: 0.6869 - val_loss: 0.6482 - val_accuracy: 0.5707\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 50s 442ms/step - loss: 0.6257 - accuracy: 0.6939 - val_loss: 0.5971 - val_accuracy: 0.5775\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.6226 - accuracy: 0.6981 - val_loss: 0.7054 - val_accuracy: 0.5775\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.6210 - accuracy: 0.7004 - val_loss: 0.6747 - val_accuracy: 0.5785\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.6164 - accuracy: 0.7049 - val_loss: 0.7754 - val_accuracy: 0.5833\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 42s 371ms/step - loss: 0.6156 - accuracy: 0.7040 - val_loss: 0.6927 - val_accuracy: 0.5853\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 42s 372ms/step - loss: 0.6108 - accuracy: 0.7094 - val_loss: 0.6505 - val_accuracy: 0.5901\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.6078 - accuracy: 0.7167 - val_loss: 0.6202 - val_accuracy: 0.5862\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.6069 - accuracy: 0.7167 - val_loss: 0.6247 - val_accuracy: 0.5911\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.6024 - accuracy: 0.7237 - val_loss: 0.6109 - val_accuracy: 0.5911\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.6012 - accuracy: 0.7209 - val_loss: 0.6305 - val_accuracy: 0.5979\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5946 - accuracy: 0.7332 - val_loss: 0.6329 - val_accuracy: 0.6027\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.5926 - accuracy: 0.7313 - val_loss: 0.8468 - val_accuracy: 0.6017\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.5897 - accuracy: 0.7377 - val_loss: 0.6041 - val_accuracy: 0.6076\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.5873 - accuracy: 0.7391 - val_loss: 0.6725 - val_accuracy: 0.6095\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.5835 - accuracy: 0.7366 - val_loss: 0.6338 - val_accuracy: 0.6124\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.5840 - accuracy: 0.7372 - val_loss: 0.6057 - val_accuracy: 0.6114\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.5794 - accuracy: 0.7459 - val_loss: 0.7010 - val_accuracy: 0.6124\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.5761 - accuracy: 0.7520 - val_loss: 0.7253 - val_accuracy: 0.6163\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.5745 - accuracy: 0.7456 - val_loss: 0.6581 - val_accuracy: 0.6182\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.5730 - accuracy: 0.7400 - val_loss: 0.6934 - val_accuracy: 0.6163\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.5690 - accuracy: 0.7509 - val_loss: 0.6117 - val_accuracy: 0.6202\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.5695 - accuracy: 0.7425 - val_loss: 0.6813 - val_accuracy: 0.6211\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5663 - accuracy: 0.7470 - val_loss: 0.6014 - val_accuracy: 0.6221\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5611 - accuracy: 0.7593 - val_loss: 0.6666 - val_accuracy: 0.6250\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5593 - accuracy: 0.7543 - val_loss: 0.5669 - val_accuracy: 0.6250\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.5563 - accuracy: 0.7518 - val_loss: 0.5772 - val_accuracy: 0.6289\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.5561 - accuracy: 0.7473 - val_loss: 0.6267 - val_accuracy: 0.6298\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 37s 326ms/step - loss: 0.5523 - accuracy: 0.7543 - val_loss: 0.6578 - val_accuracy: 0.6308\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.5496 - accuracy: 0.7591 - val_loss: 0.6753 - val_accuracy: 0.6318\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.5476 - accuracy: 0.7630 - val_loss: 0.5851 - val_accuracy: 0.6337\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5465 - accuracy: 0.7641 - val_loss: 0.6506 - val_accuracy: 0.6347\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.5434 - accuracy: 0.7633 - val_loss: 0.6806 - val_accuracy: 0.6386\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5424 - accuracy: 0.7621 - val_loss: 0.7181 - val_accuracy: 0.6386\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5415 - accuracy: 0.7700 - val_loss: 0.7162 - val_accuracy: 0.6405\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.5370 - accuracy: 0.7706 - val_loss: 0.6077 - val_accuracy: 0.6434\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.5344 - accuracy: 0.7672 - val_loss: 0.5991 - val_accuracy: 0.6453\n",
      "Epoch 56/200\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.5326 - accuracy: 0.7647 - val_loss: 0.6291 - val_accuracy: 0.6434\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5299 - accuracy: 0.7720 - val_loss: 0.7649 - val_accuracy: 0.6463\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.5299 - accuracy: 0.7723 - val_loss: 0.6032 - val_accuracy: 0.6376\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 37s 326ms/step - loss: 0.5248 - accuracy: 0.7723 - val_loss: 0.6291 - val_accuracy: 0.6492\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.5240 - accuracy: 0.7737 - val_loss: 0.6801 - val_accuracy: 0.6550\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.5237 - accuracy: 0.7680 - val_loss: 0.5358 - val_accuracy: 0.6541\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.5211 - accuracy: 0.7810 - val_loss: 0.7273 - val_accuracy: 0.6579\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5186 - accuracy: 0.7751 - val_loss: 0.6329 - val_accuracy: 0.6609\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.5159 - accuracy: 0.7770 - val_loss: 0.6899 - val_accuracy: 0.6550\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.5155 - accuracy: 0.7793 - val_loss: 0.7642 - val_accuracy: 0.6579\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.5158 - accuracy: 0.7711 - val_loss: 0.5044 - val_accuracy: 0.6570\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 47s 424ms/step - loss: 0.5099 - accuracy: 0.7818 - val_loss: 0.4929 - val_accuracy: 0.6579\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.5105 - accuracy: 0.7784 - val_loss: 0.7999 - val_accuracy: 0.6628\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.5065 - accuracy: 0.7798 - val_loss: 0.5813 - val_accuracy: 0.6628\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.5068 - accuracy: 0.7815 - val_loss: 0.6672 - val_accuracy: 0.6705\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.5071 - accuracy: 0.7725 - val_loss: 0.6013 - val_accuracy: 0.6696\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5048 - accuracy: 0.7804 - val_loss: 0.6538 - val_accuracy: 0.6754\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5034 - accuracy: 0.7824 - val_loss: 0.5253 - val_accuracy: 0.6686\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.4962 - accuracy: 0.7947 - val_loss: 0.7463 - val_accuracy: 0.6715\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.4919 - accuracy: 0.7883 - val_loss: 0.4972 - val_accuracy: 0.6744\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4962 - accuracy: 0.7832 - val_loss: 0.5694 - val_accuracy: 0.6744\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4974 - accuracy: 0.7857 - val_loss: 0.4677 - val_accuracy: 0.6754\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4939 - accuracy: 0.7852 - val_loss: 0.5673 - val_accuracy: 0.6783\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4922 - accuracy: 0.7891 - val_loss: 0.4983 - val_accuracy: 0.6725\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4884 - accuracy: 0.7885 - val_loss: 0.5751 - val_accuracy: 0.6773\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.4884 - accuracy: 0.7857 - val_loss: 0.5800 - val_accuracy: 0.6783\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.4886 - accuracy: 0.7869 - val_loss: 0.4683 - val_accuracy: 0.6793\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4856 - accuracy: 0.7846 - val_loss: 0.4731 - val_accuracy: 0.6793\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4856 - accuracy: 0.7855 - val_loss: 0.5706 - val_accuracy: 0.6851\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4824 - accuracy: 0.7902 - val_loss: 0.5635 - val_accuracy: 0.6793\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4812 - accuracy: 0.7877 - val_loss: 0.5347 - val_accuracy: 0.6831\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.4829 - accuracy: 0.7891 - val_loss: 0.5626 - val_accuracy: 0.6783\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4804 - accuracy: 0.7950 - val_loss: 0.5736 - val_accuracy: 0.6841\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4747 - accuracy: 0.7936 - val_loss: 0.5813 - val_accuracy: 0.6841\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4751 - accuracy: 0.7958 - val_loss: 0.6912 - val_accuracy: 0.6860\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4738 - accuracy: 0.7928 - val_loss: 0.7134 - val_accuracy: 0.6851\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4712 - accuracy: 0.8031 - val_loss: 0.4585 - val_accuracy: 0.6880\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 31s 272ms/step - loss: 0.4691 - accuracy: 0.7970 - val_loss: 0.4077 - val_accuracy: 0.6802\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4692 - accuracy: 0.7933 - val_loss: 0.5938 - val_accuracy: 0.6928\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4684 - accuracy: 0.7942 - val_loss: 0.5932 - val_accuracy: 0.6919\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4646 - accuracy: 0.7919 - val_loss: 0.4707 - val_accuracy: 0.6909\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 39s 348ms/step - loss: 0.4667 - accuracy: 0.7947 - val_loss: 0.5247 - val_accuracy: 0.6938\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.4663 - accuracy: 0.7930 - val_loss: 0.7581 - val_accuracy: 0.6957\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4669 - accuracy: 0.7933 - val_loss: 0.5773 - val_accuracy: 0.6928\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4595 - accuracy: 0.7987 - val_loss: 0.5704 - val_accuracy: 0.6890\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.4575 - accuracy: 0.7942 - val_loss: 0.7395 - val_accuracy: 0.6919\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4601 - accuracy: 0.7956 - val_loss: 0.5417 - val_accuracy: 0.6890\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4580 - accuracy: 0.8026 - val_loss: 0.5763 - val_accuracy: 0.6928\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4551 - accuracy: 0.8001 - val_loss: 0.4191 - val_accuracy: 0.6948\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4544 - accuracy: 0.7961 - val_loss: 0.6907 - val_accuracy: 0.6938\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4567 - accuracy: 0.7981 - val_loss: 0.6313 - val_accuracy: 0.6957\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.4549 - accuracy: 0.8029 - val_loss: 0.6587 - val_accuracy: 0.6928\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.4535 - accuracy: 0.7978 - val_loss: 0.6363 - val_accuracy: 0.6909\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4520 - accuracy: 0.7992 - val_loss: 0.4636 - val_accuracy: 0.6938\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.4507 - accuracy: 0.8020 - val_loss: 0.3455 - val_accuracy: 0.6928\n",
      "Epoch 111/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.4478 - accuracy: 0.8006 - val_loss: 0.5784 - val_accuracy: 0.6967\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4444 - accuracy: 0.8012 - val_loss: 0.3122 - val_accuracy: 0.6977\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.4471 - accuracy: 0.8045 - val_loss: 0.4201 - val_accuracy: 0.6977\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.4461 - accuracy: 0.7995 - val_loss: 0.4620 - val_accuracy: 0.6948\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4462 - accuracy: 0.8037 - val_loss: 0.5923 - val_accuracy: 0.6967\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4467 - accuracy: 0.8079 - val_loss: 0.6074 - val_accuracy: 0.6967\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4395 - accuracy: 0.8082 - val_loss: 0.6333 - val_accuracy: 0.6986\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4426 - accuracy: 0.8043 - val_loss: 0.4581 - val_accuracy: 0.6986\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4392 - accuracy: 0.8119 - val_loss: 0.4922 - val_accuracy: 0.6986\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.4365 - accuracy: 0.8023 - val_loss: 0.4346 - val_accuracy: 0.6977\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4420 - accuracy: 0.8043 - val_loss: 0.5674 - val_accuracy: 0.6986\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.7321 - val_accuracy: 0.6957\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4340 - accuracy: 0.8062 - val_loss: 0.6701 - val_accuracy: 0.6996\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4395 - accuracy: 0.8065 - val_loss: 0.7140 - val_accuracy: 0.7006\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4320 - accuracy: 0.8147 - val_loss: 0.5770 - val_accuracy: 0.7006\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4345 - accuracy: 0.8051 - val_loss: 0.6161 - val_accuracy: 0.7016\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4306 - accuracy: 0.8085 - val_loss: 0.6210 - val_accuracy: 0.6967\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.4295 - accuracy: 0.8068 - val_loss: 0.4375 - val_accuracy: 0.7006\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4276 - accuracy: 0.8079 - val_loss: 0.7579 - val_accuracy: 0.7064\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.4271 - accuracy: 0.8124 - val_loss: 0.3814 - val_accuracy: 0.7045\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.4272 - accuracy: 0.8119 - val_loss: 0.5592 - val_accuracy: 0.7035\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.4254 - accuracy: 0.8082 - val_loss: 0.5758 - val_accuracy: 0.7045\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.4233 - accuracy: 0.8152 - val_loss: 0.5086 - val_accuracy: 0.7064\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.4263 - accuracy: 0.8155 - val_loss: 0.5419 - val_accuracy: 0.7054\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4207 - accuracy: 0.8076 - val_loss: 0.7488 - val_accuracy: 0.7025\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4220 - accuracy: 0.8147 - val_loss: 0.5546 - val_accuracy: 0.7054\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 46s 413ms/step - loss: 0.4247 - accuracy: 0.8133 - val_loss: 0.5674 - val_accuracy: 0.7093\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 44s 395ms/step - loss: 0.4250 - accuracy: 0.8124 - val_loss: 0.3424 - val_accuracy: 0.7122\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 43s 387ms/step - loss: 0.4176 - accuracy: 0.8147 - val_loss: 0.4836 - val_accuracy: 0.7006\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 42s 376ms/step - loss: 0.4241 - accuracy: 0.8090 - val_loss: 0.5077 - val_accuracy: 0.7083\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 41s 370ms/step - loss: 0.4200 - accuracy: 0.8147 - val_loss: 0.7078 - val_accuracy: 0.7112\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 42s 379ms/step - loss: 0.4162 - accuracy: 0.8234 - val_loss: 0.4797 - val_accuracy: 0.7006\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.4189 - accuracy: 0.8116 - val_loss: 0.4910 - val_accuracy: 0.7054\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.3970 - val_accuracy: 0.7064\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.4153 - accuracy: 0.8161 - val_loss: 0.4450 - val_accuracy: 0.7112\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.4127 - accuracy: 0.8200 - val_loss: 0.5883 - val_accuracy: 0.7122\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.4144 - accuracy: 0.8141 - val_loss: 0.5292 - val_accuracy: 0.7112\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 42s 372ms/step - loss: 0.4115 - accuracy: 0.8200 - val_loss: 0.7830 - val_accuracy: 0.7035\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 42s 373ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.6186 - val_accuracy: 0.7035\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 42s 379ms/step - loss: 0.4131 - accuracy: 0.8161 - val_loss: 0.3890 - val_accuracy: 0.7016\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 42s 378ms/step - loss: 0.4167 - accuracy: 0.8127 - val_loss: 0.7820 - val_accuracy: 0.7064\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 42s 372ms/step - loss: 0.4116 - accuracy: 0.8206 - val_loss: 0.6662 - val_accuracy: 0.7054\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 44s 395ms/step - loss: 0.4115 - accuracy: 0.8138 - val_loss: 0.7253 - val_accuracy: 0.7035\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 42s 375ms/step - loss: 0.4080 - accuracy: 0.8141 - val_loss: 0.6241 - val_accuracy: 0.7006\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 46s 410ms/step - loss: 0.4072 - accuracy: 0.8203 - val_loss: 0.5897 - val_accuracy: 0.7074\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 44s 394ms/step - loss: 0.4024 - accuracy: 0.8239 - val_loss: 0.5361 - val_accuracy: 0.7006\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 44s 393ms/step - loss: 0.4083 - accuracy: 0.8175 - val_loss: 0.4659 - val_accuracy: 0.7083\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 42s 371ms/step - loss: 0.4010 - accuracy: 0.8273 - val_loss: 0.5496 - val_accuracy: 0.7074\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 42s 372ms/step - loss: 0.4041 - accuracy: 0.8265 - val_loss: 0.5917 - val_accuracy: 0.7093\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 40s 359ms/step - loss: 0.4068 - accuracy: 0.8242 - val_loss: 0.4173 - val_accuracy: 0.7093\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 42s 377ms/step - loss: 0.4030 - accuracy: 0.8236 - val_loss: 0.6638 - val_accuracy: 0.7054\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 43s 388ms/step - loss: 0.4032 - accuracy: 0.8208 - val_loss: 0.4796 - val_accuracy: 0.7064\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 42s 373ms/step - loss: 0.4005 - accuracy: 0.8222 - val_loss: 0.5471 - val_accuracy: 0.7064\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 44s 389ms/step - loss: 0.3971 - accuracy: 0.8231 - val_loss: 0.4511 - val_accuracy: 0.7064\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 42s 371ms/step - loss: 0.3978 - accuracy: 0.8245 - val_loss: 0.3595 - val_accuracy: 0.7045\n",
      "Epoch 166/200\n",
      "112/112 [==============================] - 42s 377ms/step - loss: 0.4058 - accuracy: 0.8166 - val_loss: 0.6137 - val_accuracy: 0.6957\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.3973 - accuracy: 0.8228 - val_loss: 0.5856 - val_accuracy: 0.7045\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 42s 374ms/step - loss: 0.3969 - accuracy: 0.8250 - val_loss: 0.8663 - val_accuracy: 0.7093\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.3969 - accuracy: 0.8228 - val_loss: 0.6561 - val_accuracy: 0.7035\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.3927 - accuracy: 0.8265 - val_loss: 0.4867 - val_accuracy: 0.7083\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 42s 373ms/step - loss: 0.3978 - accuracy: 0.8287 - val_loss: 0.4589 - val_accuracy: 0.7016\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 42s 375ms/step - loss: 0.3934 - accuracy: 0.8234 - val_loss: 0.6782 - val_accuracy: 0.7122\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 44s 395ms/step - loss: 0.3940 - accuracy: 0.8186 - val_loss: 0.4737 - val_accuracy: 0.7074\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.3990 - accuracy: 0.8203 - val_loss: 0.5370 - val_accuracy: 0.6948\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 44s 396ms/step - loss: 0.3899 - accuracy: 0.8290 - val_loss: 0.5291 - val_accuracy: 0.6986\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 43s 380ms/step - loss: 0.3932 - accuracy: 0.8307 - val_loss: 0.6115 - val_accuracy: 0.6938\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 44s 392ms/step - loss: 0.3893 - accuracy: 0.8298 - val_loss: 0.5619 - val_accuracy: 0.6909\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 43s 382ms/step - loss: 0.3910 - accuracy: 0.8259 - val_loss: 0.5595 - val_accuracy: 0.6977\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 42s 375ms/step - loss: 0.3872 - accuracy: 0.8287 - val_loss: 0.6611 - val_accuracy: 0.6977\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 42s 374ms/step - loss: 0.3860 - accuracy: 0.8301 - val_loss: 0.5502 - val_accuracy: 0.6938\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 43s 387ms/step - loss: 0.3938 - accuracy: 0.8340 - val_loss: 0.3993 - val_accuracy: 0.7054\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 43s 380ms/step - loss: 0.3848 - accuracy: 0.8312 - val_loss: 0.6291 - val_accuracy: 0.7103\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 45s 401ms/step - loss: 0.3871 - accuracy: 0.8307 - val_loss: 0.4249 - val_accuracy: 0.7093\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 47s 415ms/step - loss: 0.3883 - accuracy: 0.8259 - val_loss: 0.7183 - val_accuracy: 0.7054\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 45s 400ms/step - loss: 0.3862 - accuracy: 0.8340 - val_loss: 0.4048 - val_accuracy: 0.6919\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - 42s 379ms/step - loss: 0.3847 - accuracy: 0.8287 - val_loss: 0.4754 - val_accuracy: 0.6977\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 42s 371ms/step - loss: 0.3825 - accuracy: 0.8293 - val_loss: 0.6410 - val_accuracy: 0.6967\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 41s 364ms/step - loss: 0.3861 - accuracy: 0.8250 - val_loss: 0.6577 - val_accuracy: 0.6899\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.3770 - accuracy: 0.8335 - val_loss: 0.5535 - val_accuracy: 0.7006\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 40s 362ms/step - loss: 0.3838 - accuracy: 0.8338 - val_loss: 0.6941 - val_accuracy: 0.6977\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 42s 376ms/step - loss: 0.3802 - accuracy: 0.8321 - val_loss: 0.7289 - val_accuracy: 0.6977\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 41s 367ms/step - loss: 0.3806 - accuracy: 0.8354 - val_loss: 0.3098 - val_accuracy: 0.6919\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.3826 - accuracy: 0.8346 - val_loss: 0.4930 - val_accuracy: 0.7074\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.3794 - accuracy: 0.8354 - val_loss: 0.7481 - val_accuracy: 0.6919\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.3768 - accuracy: 0.8371 - val_loss: 0.6272 - val_accuracy: 0.6909\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.3834 - accuracy: 0.8338 - val_loss: 0.5124 - val_accuracy: 0.6909\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.3839 - accuracy: 0.8368 - val_loss: 0.6015 - val_accuracy: 0.6957\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.3774 - accuracy: 0.8360 - val_loss: 0.7667 - val_accuracy: 0.6938\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.3745 - accuracy: 0.8357 - val_loss: 0.8783 - val_accuracy: 0.6938\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.3754 - accuracy: 0.8354 - val_loss: 0.3621 - val_accuracy: 0.6977\n",
      "{'Female': 0, 'Male': 1}\n",
      "> 69.767\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Model\n",
    "mobilenetModel=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "# for layer in mobilenetModel.layers:\n",
    "#     layer.trainable = False\n",
    "x=mobilenetModel.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "output=Dense(1,activation='sigmoid')(x) #final layer with softmax activation\n",
    "\n",
    "# # define new model\n",
    "baseModel = Model(inputs=mobilenetModel.inputs, outputs=output)\n",
    "\n",
    "# # Check the trainable status of the individual layers\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in baseModel.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 87\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable=False\n",
    "for layer in baseModel.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "for layer in baseModel.layers[fine_tune_at:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "# # Check the trainable status of the individual layers\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in baseModel.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "    \n",
    "# compile model\n",
    "# opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "# opt = RMSprop(learning_rate=0.0001, rho=0.99)\n",
    "# opt = Adagrad(learning_rate=0.001)\n",
    "# opt = Adadelta(learning_rate=1.0, rho=0.99)\n",
    "# opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "opt = Adamax(learning_rate=0.0034, beta_1=0.9, beta_2=0.999)\n",
    "# opt = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# baseModel.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "baseModel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=5, min_lr=0.01)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# callbacks_list = [ModelCheckpoint(filepath='model.h5', save_best_only=True)]\n",
    "callbacks_list = [tensorboard]\n",
    "# fit model\n",
    "history1 = baseModel.fit_generator(train_it, steps_per_epoch=len(train_it), \n",
    "                                  validation_data=test_it, \n",
    "                                  validation_steps=len(test_it), \n",
    "                                  epochs=epochs, verbose=1,\n",
    "                                  callbacks=callbacks_list)\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = baseModel.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print(train_it.class_indices)\n",
    "#print(baseModel.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history1)\n",
    "#print_metrics(baseModel, test_datagen, test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,853,377\n",
      "Trainable params: 2,624,513\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x000002477AA60348>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x0000024775723548>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247757C96C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024775581248>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247755814C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247516F0948>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477ADD9AC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247833AA0C8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247833AA7C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E485288>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477ADEB0C8>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000002477E488648>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002478346FFC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E48F288>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783364C08>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024783364C88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783508888>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477ADC69C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002478353CB08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783335608>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783344FC8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002478340F188>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247833FB1C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247833D5908>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000247833D5988>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247834B5BC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247834BAC48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247834BCF48>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024783260B88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783254D48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247832858C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247832D2E88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247832ECF88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783302148>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024783309E88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024783569CC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002478358AC08>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000247835AA208>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247835B9F48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247835C3A88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247835C8248>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247835CE548>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247835E0108>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783610C48>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002478362D188>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002478363EDC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002476FF31708>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002476FF31F88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002478321DBC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000024783228648>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x0000024783234888>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247759EF9C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002475234C048>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024752343E88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024770189608>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477526DB48>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247751EF248>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477ADA30C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002476FF41388>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000024751818FC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247700D91C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247700F7B88>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247700E7808>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477AE64CC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247517FC188>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000247517FCD48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000247518BEA88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247519EE948>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000247519EEE08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000024751635908>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000247515D6048>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002477E93F288>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477EF08708>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477EF08F08>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x0000024751381208>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002477E48AF08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E49FB48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477E4A10C8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002477E47CA88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477ADE73C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477ADE7208>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000002477ADE4FC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477E607D08>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477E607B08>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002477E60F748>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002477AF56508>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000002477B0F6DC8>: False\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x00000247759F3E48>: True\n",
      "<keras.layers.core.Dense object at 0x0000024783AC6388>: True\n",
      "<keras.layers.core.Dense object at 0x000002477E799288>: True\n",
      "<keras.layers.core.Dense object at 0x000002477E7781C8>: True\n",
      "<keras.layers.core.Dense object at 0x000002477E78FC08>: True\n"
     ]
    }
   ],
   "source": [
    "# Check the trainable status of the individual layers\n",
    "print(\"\\r\\r\\r\\r\")\n",
    "for layer in baseModel.layers:\n",
    "    print(\"{}: {}\".format(layer, layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel.save('Base_Model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "112/112 [==============================] - 42s 377ms/step - loss: 0.3736 - accuracy: 0.8343 - val_loss: 0.7036 - val_accuracy: 0.7287\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.3625 - accuracy: 0.8425 - val_loss: 0.2671 - val_accuracy: 0.7432\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.3651 - accuracy: 0.8441 - val_loss: 0.3628 - val_accuracy: 0.7510\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.3636 - accuracy: 0.8366 - val_loss: 0.5305 - val_accuracy: 0.7539\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.3601 - accuracy: 0.8461 - val_loss: 0.5083 - val_accuracy: 0.7548\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.3460 - accuracy: 0.8526 - val_loss: 0.5661 - val_accuracy: 0.7539\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.3505 - accuracy: 0.8517 - val_loss: 0.2554 - val_accuracy: 0.7568\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.3449 - accuracy: 0.8573 - val_loss: 0.3637 - val_accuracy: 0.7597\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.3415 - accuracy: 0.8616 - val_loss: 0.3757 - val_accuracy: 0.7548\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.3360 - accuracy: 0.8621 - val_loss: 0.5381 - val_accuracy: 0.7578\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.3299 - accuracy: 0.8638 - val_loss: 1.0129 - val_accuracy: 0.7578\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.3261 - accuracy: 0.8646 - val_loss: 0.4685 - val_accuracy: 0.7587\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.3202 - accuracy: 0.8719 - val_loss: 0.4119 - val_accuracy: 0.7587\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.3207 - accuracy: 0.8691 - val_loss: 0.4784 - val_accuracy: 0.7607\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 41s 363ms/step - loss: 0.3187 - accuracy: 0.8677 - val_loss: 0.4472 - val_accuracy: 0.7597\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 44s 393ms/step - loss: 0.3092 - accuracy: 0.8722 - val_loss: 0.3334 - val_accuracy: 0.7636\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 43s 381ms/step - loss: 0.3095 - accuracy: 0.8689 - val_loss: 0.2363 - val_accuracy: 0.7626\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 44s 391ms/step - loss: 0.3080 - accuracy: 0.8736 - val_loss: 0.3919 - val_accuracy: 0.7645\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 43s 387ms/step - loss: 0.3029 - accuracy: 0.8815 - val_loss: 0.4187 - val_accuracy: 0.7645\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 44s 388ms/step - loss: 0.3016 - accuracy: 0.8770 - val_loss: 0.5469 - val_accuracy: 0.7645\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.2953 - accuracy: 0.8790 - val_loss: 1.0244 - val_accuracy: 0.7655\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.2893 - accuracy: 0.8888 - val_loss: 0.4187 - val_accuracy: 0.7684\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.2883 - accuracy: 0.8826 - val_loss: 0.4286 - val_accuracy: 0.7674\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.2799 - accuracy: 0.8975 - val_loss: 0.2933 - val_accuracy: 0.7694\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.2803 - accuracy: 0.8947 - val_loss: 0.6914 - val_accuracy: 0.7684\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.2805 - accuracy: 0.8910 - val_loss: 0.3782 - val_accuracy: 0.7713\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.2791 - accuracy: 0.8880 - val_loss: 0.4275 - val_accuracy: 0.7752\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.2748 - accuracy: 0.8941 - val_loss: 0.6504 - val_accuracy: 0.7733\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.2684 - accuracy: 0.8983 - val_loss: 0.6676 - val_accuracy: 0.7723\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.2698 - accuracy: 0.8997 - val_loss: 0.1491 - val_accuracy: 0.7694\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.2613 - accuracy: 0.9026 - val_loss: 0.6158 - val_accuracy: 0.7771\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.2596 - accuracy: 0.9034 - val_loss: 0.4439 - val_accuracy: 0.7791\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.2544 - accuracy: 0.9087 - val_loss: 0.4673 - val_accuracy: 0.7752\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.2513 - accuracy: 0.9028 - val_loss: 0.6295 - val_accuracy: 0.7762\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.2499 - accuracy: 0.9082 - val_loss: 0.3966 - val_accuracy: 0.7791\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.2543 - accuracy: 0.9028 - val_loss: 0.8436 - val_accuracy: 0.7771\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.2413 - accuracy: 0.9129 - val_loss: 0.7554 - val_accuracy: 0.7781\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.2439 - accuracy: 0.9079 - val_loss: 0.6920 - val_accuracy: 0.7781\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.2420 - accuracy: 0.9138 - val_loss: 0.3065 - val_accuracy: 0.7781\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.2357 - accuracy: 0.9188 - val_loss: 0.6565 - val_accuracy: 0.7800\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.2410 - accuracy: 0.9107 - val_loss: 0.1387 - val_accuracy: 0.7820\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.2334 - accuracy: 0.9163 - val_loss: 0.5120 - val_accuracy: 0.7810\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.2338 - accuracy: 0.9174 - val_loss: 0.4172 - val_accuracy: 0.7820\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.2273 - accuracy: 0.9222 - val_loss: 0.5320 - val_accuracy: 0.7771\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 32s 281ms/step - loss: 0.2240 - accuracy: 0.9186 - val_loss: 0.4642 - val_accuracy: 0.7820\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.2233 - accuracy: 0.9202 - val_loss: 0.2413 - val_accuracy: 0.7820\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.2202 - accuracy: 0.9217 - val_loss: 0.5923 - val_accuracy: 0.7859\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.2154 - accuracy: 0.9326 - val_loss: 0.3496 - val_accuracy: 0.7839\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.2149 - accuracy: 0.9202 - val_loss: 0.5553 - val_accuracy: 0.7907\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.2117 - accuracy: 0.9295 - val_loss: 0.5401 - val_accuracy: 0.7897\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.2076 - accuracy: 0.9323 - val_loss: 0.1766 - val_accuracy: 0.7897\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.2055 - accuracy: 0.9301 - val_loss: 0.5964 - val_accuracy: 0.7907\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.2038 - accuracy: 0.9337 - val_loss: 0.5940 - val_accuracy: 0.7926\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.2110 - accuracy: 0.9273 - val_loss: 0.5655 - val_accuracy: 0.7917\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.2005 - accuracy: 0.9354 - val_loss: 0.2899 - val_accuracy: 0.7926\n",
      "Epoch 56/200\n",
      "112/112 [==============================] - 39s 349ms/step - loss: 0.1927 - accuracy: 0.9354 - val_loss: 0.9327 - val_accuracy: 0.7907\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.1948 - accuracy: 0.9315 - val_loss: 0.7251 - val_accuracy: 0.7907\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 43s 388ms/step - loss: 0.1939 - accuracy: 0.9374 - val_loss: 0.6534 - val_accuracy: 0.7907\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 40s 360ms/step - loss: 0.1905 - accuracy: 0.9368 - val_loss: 0.7658 - val_accuracy: 0.7926\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1878 - accuracy: 0.9433 - val_loss: 0.2598 - val_accuracy: 0.7926\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.1886 - accuracy: 0.9388 - val_loss: 0.6056 - val_accuracy: 0.7936\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1878 - accuracy: 0.9430 - val_loss: 0.3622 - val_accuracy: 0.7936\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1770 - accuracy: 0.9466 - val_loss: 0.9536 - val_accuracy: 0.7936\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.1809 - accuracy: 0.9419 - val_loss: 0.5135 - val_accuracy: 0.7936\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1857 - accuracy: 0.9407 - val_loss: 0.6320 - val_accuracy: 0.7936\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.1759 - accuracy: 0.9478 - val_loss: 0.2862 - val_accuracy: 0.7907\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.1756 - accuracy: 0.9469 - val_loss: 0.2877 - val_accuracy: 0.7936\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1716 - accuracy: 0.9461 - val_loss: 0.4890 - val_accuracy: 0.7955\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.1694 - accuracy: 0.9489 - val_loss: 0.3580 - val_accuracy: 0.7926\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.1685 - accuracy: 0.9495 - val_loss: 0.5926 - val_accuracy: 0.7936\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.1682 - accuracy: 0.9509 - val_loss: 0.2448 - val_accuracy: 0.7936\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.1664 - accuracy: 0.9475 - val_loss: 0.0901 - val_accuracy: 0.7888\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 42s 373ms/step - loss: 0.1630 - accuracy: 0.9542 - val_loss: 0.6568 - val_accuracy: 0.7965\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.1607 - accuracy: 0.9556 - val_loss: 0.3038 - val_accuracy: 0.7936\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 43s 380ms/step - loss: 0.1606 - accuracy: 0.9506 - val_loss: 0.3654 - val_accuracy: 0.7926\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 39s 349ms/step - loss: 0.1557 - accuracy: 0.9525 - val_loss: 0.3917 - val_accuracy: 0.7917\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.1463 - accuracy: 0.9607 - val_loss: 0.1830 - val_accuracy: 0.7917\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1528 - accuracy: 0.9553 - val_loss: 0.7317 - val_accuracy: 0.8033\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.1493 - accuracy: 0.9598 - val_loss: 0.4095 - val_accuracy: 0.7965\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.1503 - accuracy: 0.9587 - val_loss: 0.2512 - val_accuracy: 0.8023\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.1450 - accuracy: 0.9590 - val_loss: 0.3327 - val_accuracy: 0.7994\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1432 - accuracy: 0.9635 - val_loss: 0.4348 - val_accuracy: 0.7965\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.1367 - accuracy: 0.9666 - val_loss: 0.5263 - val_accuracy: 0.8043\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1387 - accuracy: 0.9610 - val_loss: 0.1719 - val_accuracy: 0.8023\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1445 - accuracy: 0.9576 - val_loss: 0.3498 - val_accuracy: 0.8014\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1385 - accuracy: 0.9584 - val_loss: 0.2769 - val_accuracy: 0.8023\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1408 - accuracy: 0.9582 - val_loss: 0.5264 - val_accuracy: 0.8004\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.1363 - accuracy: 0.9638 - val_loss: 0.4920 - val_accuracy: 0.8052\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1348 - accuracy: 0.9618 - val_loss: 0.2377 - val_accuracy: 0.8014\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1373 - accuracy: 0.9604 - val_loss: 0.2630 - val_accuracy: 0.8023\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1271 - accuracy: 0.9694 - val_loss: 0.7469 - val_accuracy: 0.8023\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.1321 - accuracy: 0.9669 - val_loss: 0.1372 - val_accuracy: 0.8014\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.1254 - accuracy: 0.9691 - val_loss: 0.2862 - val_accuracy: 0.8033\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.1266 - accuracy: 0.9677 - val_loss: 0.3460 - val_accuracy: 0.8023\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 39s 348ms/step - loss: 0.1240 - accuracy: 0.9700 - val_loss: 0.3769 - val_accuracy: 0.7994\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1162 - accuracy: 0.9761 - val_loss: 0.7967 - val_accuracy: 0.8033\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.1201 - accuracy: 0.9714 - val_loss: 0.9336 - val_accuracy: 0.8014\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.1165 - accuracy: 0.9742 - val_loss: 0.2854 - val_accuracy: 0.8004\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.1211 - accuracy: 0.9683 - val_loss: 0.6898 - val_accuracy: 0.8043\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 39s 350ms/step - loss: 0.1185 - accuracy: 0.9761 - val_loss: 0.4910 - val_accuracy: 0.8052\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1094 - accuracy: 0.9778 - val_loss: 0.3412 - val_accuracy: 0.8072\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.1132 - accuracy: 0.9705 - val_loss: 0.5632 - val_accuracy: 0.8014\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1122 - accuracy: 0.9744 - val_loss: 0.3514 - val_accuracy: 0.8033\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1131 - accuracy: 0.9747 - val_loss: 0.3307 - val_accuracy: 0.8033\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.1026 - accuracy: 0.9809 - val_loss: 0.5375 - val_accuracy: 0.8072\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1060 - accuracy: 0.9756 - val_loss: 0.2440 - val_accuracy: 0.8091\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.1133 - accuracy: 0.9705 - val_loss: 0.7658 - val_accuracy: 0.8052\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1039 - accuracy: 0.9784 - val_loss: 1.2380 - val_accuracy: 0.8052\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1094 - accuracy: 0.9758 - val_loss: 0.6614 - val_accuracy: 0.8023\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.1050 - accuracy: 0.9756 - val_loss: 0.4124 - val_accuracy: 0.8043\n",
      "Epoch 111/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1002 - accuracy: 0.9798 - val_loss: 0.3384 - val_accuracy: 0.8052\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1005 - accuracy: 0.9798 - val_loss: 0.3998 - val_accuracy: 0.8052\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.0989 - accuracy: 0.9789 - val_loss: 0.3438 - val_accuracy: 0.8062\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.0982 - accuracy: 0.9795 - val_loss: 0.5915 - val_accuracy: 0.8052\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1024 - accuracy: 0.9747 - val_loss: 0.4329 - val_accuracy: 0.8072\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.0979 - accuracy: 0.9775 - val_loss: 0.4007 - val_accuracy: 0.8072\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 39s 351ms/step - loss: 0.0962 - accuracy: 0.9803 - val_loss: 0.3574 - val_accuracy: 0.8072\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.0940 - accuracy: 0.9806 - val_loss: 0.3089 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.0874 - accuracy: 0.9854 - val_loss: 0.3212 - val_accuracy: 0.8081\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.0883 - accuracy: 0.9837 - val_loss: 0.1018 - val_accuracy: 0.8043\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.0909 - accuracy: 0.9815 - val_loss: 0.3950 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.0872 - accuracy: 0.9829 - val_loss: 0.1437 - val_accuracy: 0.8091\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.0883 - accuracy: 0.9837 - val_loss: 0.3819 - val_accuracy: 0.8091\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 39s 348ms/step - loss: 0.0869 - accuracy: 0.9840 - val_loss: 0.1018 - val_accuracy: 0.8033\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 41s 365ms/step - loss: 0.0918 - accuracy: 0.9798 - val_loss: 0.5691 - val_accuracy: 0.8072\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 40s 359ms/step - loss: 0.0837 - accuracy: 0.9834 - val_loss: 0.3020 - val_accuracy: 0.8033\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.0823 - accuracy: 0.9848 - val_loss: 0.4981 - val_accuracy: 0.8091\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0855 - accuracy: 0.9837 - val_loss: 0.6296 - val_accuracy: 0.8091\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 42s 377ms/step - loss: 0.0795 - accuracy: 0.9885 - val_loss: 0.1443 - val_accuracy: 0.8081\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0796 - accuracy: 0.9882 - val_loss: 0.2447 - val_accuracy: 0.8081\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 41s 363ms/step - loss: 0.0801 - accuracy: 0.9868 - val_loss: 0.5514 - val_accuracy: 0.8110\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 40s 354ms/step - loss: 0.0851 - accuracy: 0.9832 - val_loss: 0.4389 - val_accuracy: 0.8101\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.0754 - accuracy: 0.9879 - val_loss: 0.6002 - val_accuracy: 0.8110\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 43s 386ms/step - loss: 0.0738 - accuracy: 0.9890 - val_loss: 0.1222 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 42s 374ms/step - loss: 0.0780 - accuracy: 0.9854 - val_loss: 0.3178 - val_accuracy: 0.8130\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0729 - accuracy: 0.9885 - val_loss: 1.1329 - val_accuracy: 0.8052\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.0796 - accuracy: 0.9846 - val_loss: 0.2690 - val_accuracy: 0.8130\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 39s 351ms/step - loss: 0.0776 - accuracy: 0.9834 - val_loss: 0.5667 - val_accuracy: 0.8033\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0712 - accuracy: 0.9890 - val_loss: 0.7363 - val_accuracy: 0.8043\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.0724 - accuracy: 0.9879 - val_loss: 0.0963 - val_accuracy: 0.8081\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 45s 398ms/step - loss: 0.0683 - accuracy: 0.9907 - val_loss: 0.5483 - val_accuracy: 0.8140\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 48s 432ms/step - loss: 0.0672 - accuracy: 0.9902 - val_loss: 0.2822 - val_accuracy: 0.8130\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 43s 388ms/step - loss: 0.0698 - accuracy: 0.9890 - val_loss: 0.1463 - val_accuracy: 0.8120\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 40s 356ms/step - loss: 0.0689 - accuracy: 0.9882 - val_loss: 1.0548 - val_accuracy: 0.8110\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.0672 - accuracy: 0.9888 - val_loss: 0.2710 - val_accuracy: 0.8140\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0622 - accuracy: 0.9913 - val_loss: 0.2894 - val_accuracy: 0.8052\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.0709 - accuracy: 0.9907 - val_loss: 0.7138 - val_accuracy: 0.8110\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0651 - accuracy: 0.9910 - val_loss: 1.6487 - val_accuracy: 0.8091\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0629 - accuracy: 0.9888 - val_loss: 0.3689 - val_accuracy: 0.8130\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0670 - accuracy: 0.9899 - val_loss: 0.4611 - val_accuracy: 0.8140\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0656 - accuracy: 0.9893 - val_loss: 0.2178 - val_accuracy: 0.8091\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.0627 - accuracy: 0.9927 - val_loss: 0.4291 - val_accuracy: 0.8081\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.0669 - accuracy: 0.9899 - val_loss: 0.5142 - val_accuracy: 0.8091\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0656 - accuracy: 0.9893 - val_loss: 0.3262 - val_accuracy: 0.8052\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.0569 - accuracy: 0.9947 - val_loss: 0.3828 - val_accuracy: 0.8140\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 40s 354ms/step - loss: 0.0584 - accuracy: 0.9927 - val_loss: 0.2687 - val_accuracy: 0.8120\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.0629 - accuracy: 0.9890 - val_loss: 0.4693 - val_accuracy: 0.8149\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.0618 - accuracy: 0.9890 - val_loss: 0.2596 - val_accuracy: 0.8091\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.0568 - accuracy: 0.9938 - val_loss: 0.1980 - val_accuracy: 0.8149\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.0571 - accuracy: 0.9899 - val_loss: 0.5353 - val_accuracy: 0.8140\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.0610 - accuracy: 0.9905 - val_loss: 0.3095 - val_accuracy: 0.8110\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.0533 - accuracy: 0.9933 - val_loss: 0.7093 - val_accuracy: 0.8101\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.0557 - accuracy: 0.9924 - val_loss: 0.6226 - val_accuracy: 0.8081\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.0590 - accuracy: 0.9896 - val_loss: 0.4830 - val_accuracy: 0.8149\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.0508 - accuracy: 0.9961 - val_loss: 0.2198 - val_accuracy: 0.8130\n",
      "Epoch 166/200\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.0530 - accuracy: 0.9913 - val_loss: 0.2464 - val_accuracy: 0.8159\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0520 - accuracy: 0.9944 - val_loss: 0.2224 - val_accuracy: 0.8149\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0521 - accuracy: 0.9933 - val_loss: 0.2677 - val_accuracy: 0.8159\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0568 - accuracy: 0.9885 - val_loss: 0.6932 - val_accuracy: 0.8101\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.0533 - accuracy: 0.9952 - val_loss: 0.3631 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0494 - accuracy: 0.9963 - val_loss: 0.5685 - val_accuracy: 0.8130\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.0544 - accuracy: 0.9935 - val_loss: 0.4008 - val_accuracy: 0.8101\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.0534 - accuracy: 0.9924 - val_loss: 0.7678 - val_accuracy: 0.8149\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0517 - accuracy: 0.9935 - val_loss: 0.6376 - val_accuracy: 0.8120\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 32s 281ms/step - loss: 0.0469 - accuracy: 0.9944 - val_loss: 0.6604 - val_accuracy: 0.8130\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0483 - accuracy: 0.9938 - val_loss: 0.7673 - val_accuracy: 0.8149\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.0478 - accuracy: 0.9949 - val_loss: 0.4159 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.0494 - accuracy: 0.9941 - val_loss: 0.1891 - val_accuracy: 0.8110\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0460 - accuracy: 0.9952 - val_loss: 0.2110 - val_accuracy: 0.8120\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.0471 - accuracy: 0.9935 - val_loss: 0.2619 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0461 - accuracy: 0.9963 - val_loss: 0.3584 - val_accuracy: 0.8159\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.0417 - accuracy: 0.9966 - val_loss: 0.8708 - val_accuracy: 0.8140\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.0444 - accuracy: 0.9966 - val_loss: 0.1453 - val_accuracy: 0.8120\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.0442 - accuracy: 0.9952 - val_loss: 0.0580 - val_accuracy: 0.8140\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0453 - accuracy: 0.9941 - val_loss: 0.0913 - val_accuracy: 0.8072\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.0421 - accuracy: 0.9952 - val_loss: 0.2476 - val_accuracy: 0.8149\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.0461 - accuracy: 0.9952 - val_loss: 0.5245 - val_accuracy: 0.8140\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.0418 - accuracy: 0.9952 - val_loss: 0.2965 - val_accuracy: 0.8130\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0432 - accuracy: 0.9955 - val_loss: 0.4554 - val_accuracy: 0.8130\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0458 - accuracy: 0.9944 - val_loss: 0.1735 - val_accuracy: 0.8130\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.0391 - accuracy: 0.9966 - val_loss: 0.1954 - val_accuracy: 0.8130\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.0428 - accuracy: 0.9966 - val_loss: 0.3924 - val_accuracy: 0.8130\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.0414 - accuracy: 0.9966 - val_loss: 0.4824 - val_accuracy: 0.8130\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0418 - accuracy: 0.9966 - val_loss: 0.1003 - val_accuracy: 0.8149\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.0411 - accuracy: 0.9963 - val_loss: 0.1709 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.0393 - accuracy: 0.9961 - val_loss: 0.3857 - val_accuracy: 0.8120\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.0406 - accuracy: 0.9952 - val_loss: 0.8304 - val_accuracy: 0.8140\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.0380 - accuracy: 0.9966 - val_loss: 0.3250 - val_accuracy: 0.8140\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0392 - accuracy: 0.9955 - val_loss: 0.5078 - val_accuracy: 0.8120\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.0394 - accuracy: 0.9966 - val_loss: 0.5492 - val_accuracy: 0.8120\n",
      "{'Female': 0, 'Male': 1}\n",
      "> 81.202\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Duplicate Model\n",
    "# model= clone_model(baseModel)\n",
    "model_with_last_20_layers = load_model('Base_Model_2.h5')\n",
    "\n",
    "# # loop over the layers in the model and show which ones are trainable\n",
    "# # or not\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in model_with_last_20_layers.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 20\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in model_with_last_20_layers.layers:\n",
    "    layer.trainable=False\n",
    "for layer in model_with_last_20_layers.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "for layer in model_with_last_20_layers.layers[fine_tune_at:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "\n",
    "# # loop over the layers in the model and show which ones are trainable\n",
    "# # or not\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in model_with_last_20_layers.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# compile model\n",
    "#opt = SGD(lr=1.0e-6, momentum=0.9)\n",
    "opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "model_with_last_20_layers.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=5, min_lr=0.001)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# callbacks_list = [ModelCheckpoint(filepath='model.h5', save_best_only=True)]\n",
    "callbacks_list = [tensorboard]\n",
    "# fit model\n",
    "history_awith_last_20_layers = model_with_last_20_layers.fit_generator(train_it, steps_per_epoch=len(train_it), \n",
    "                                                                      validation_data=test_it, \n",
    "                                                                      validation_steps=len(test_it), \n",
    "                                                                      epochs=epochs, verbose=1, \n",
    "                                                                      callbacks=callbacks_list)\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = model_with_last_20_layers.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print(train_it.class_indices)\n",
    "#print(model.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history_awith_last_20_layers)\n",
    "#print_metrics(model, test_datagen, test_path)\n",
    "    \n",
    "    \n",
    "# entry point, run the test harness\n",
    "# dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "#run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_last_20_layers.save('Base_Model_fine_tuned_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n",
      "Found 4630 images belonging to 2 classes.\n",
      "> 74.039\n"
     ]
    }
   ],
   "source": [
    "test_path = '../data/raw/iris_data/LG4000/gender/'\n",
    "\n",
    "# Duplicate Model\n",
    "# model= clone_model(baseModel)\n",
    "model = load_model('Base_Model_fine_tuned_2.h5')\n",
    "\n",
    "\n",
    "# entry point, run the test harness\n",
    "file = '../data/processed/iris_data/LG2200/gender/train/Male/02463d1896.tiff'\n",
    "width, height = imagesize.get(file)\n",
    "print(width, height)\n",
    "\n",
    "\n",
    "# prueba = load_all_images(train_path+'Male', height, width, 'tiff')\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "train_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "train_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "# prepare iterators\n",
    "test_it = train_datagen.flow_from_directory(test_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(240, 320)) \n",
    "\n",
    "\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "#print(model.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing neck bottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "# baseline model for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    plt.plot(history.history['loss'],\n",
    "                color='blue', label='loss train')\n",
    "    plt.plot(history.history['val_loss'],\n",
    "                color='orange', label='loss test')\n",
    "    plt.plot(history.history['accuracy'],\n",
    "                color='green', label='accuracy train')\n",
    "    plt.plot(history.history['val_accuracy'],\n",
    "                color='red', label='accuracy test')\n",
    "    plt.ylim(bottom = -0.1, top = 1.1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pretty_print_conf_matrix(y_true, y_pred, \n",
    "                             classes,\n",
    "                             normalize=False,\n",
    "                             title='Confusion matrix',\n",
    "                             cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Mostly stolen from: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "    Normalization changed, classification_report stats added below plot\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Configure Confusion Matrix Plot Aesthetics (no text yet) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylabel('True label', fontsize=12)\n",
    "    plt.xlabel('Predicted label', fontsize=12)\n",
    "\n",
    "    # Calculate normalized values (so all cells sum to 1) if desired\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(),2) #(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Place Numbers as Text on Confusion Matrix Plot\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=12)\n",
    "\n",
    "\n",
    "    # Add Precision, Recall, F-1 Score as Captions Below Plot\n",
    "    rpt = classification_report(y_true, y_pred)\n",
    "    rpt = rpt.replace('avg / total', '      avg')\n",
    "    rpt = rpt.replace('support', 'N Obs')\n",
    "\n",
    "    plt.annotate(rpt, \n",
    "                 xy = (0,0), \n",
    "                 xytext = (-50, -140), \n",
    "                 xycoords='axes fraction', textcoords='offset points',\n",
    "                 fontsize=12, ha='right')    \n",
    "\n",
    "    # Plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def print_metrics(model, datagen, test_path):\n",
    "    \n",
    "    test_it = datagen.flow_from_directory(test_path,\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=64,\n",
    "                                          target_size=(240, 320))\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(test_path,\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size=1,\n",
    "                                          target_size=(240, 320))    \n",
    "    # predict probabilities for test set\n",
    "    filenames = test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    true_values = []\n",
    "    predictions = []\n",
    "    for i in range(nb_samples):\n",
    "        x_batch, y_batch = test_generator.next()\n",
    "        name = model.predict(x_batch)\n",
    "        name =  (name>0.5).astype(int)[0][0]\n",
    "        true_name = y_batch[0].astype(np.int)\n",
    "        label_map = (test_generator.class_indices)\n",
    "        label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "        prediction = label_map[name]\n",
    "        true_value = label_map[true_name]\n",
    "        true_values.append(true_value)\n",
    "        predictions.append(prediction) \n",
    "    plt.figure()\n",
    "    pretty_print_conf_matrix(true_values, predictions, \n",
    "                             classes= ['Female', 'Male'])\n",
    "\n",
    "\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    k = 0.05\n",
    "    lrate = initial_lrate * exp(-k*epoch)\n",
    "    return lrate\n",
    "\n",
    "def read_pil_image(img_path, height, width):\n",
    "        with open(img_path, 'rb') as f:\n",
    "            return np.array(Image.open(f).convert('RGB').resize((width, height)))\n",
    "\n",
    "def load_all_images(dataset_path, height, width, img_ext='png'):\n",
    "    return np.array([read_pil_image(str(p), height, width) for p in \n",
    "                                    Path(dataset_path).rglob(\"*.\"+img_ext)]) \n",
    "\n",
    "def normalise_features(array):\n",
    "    min_value = -1\n",
    "    max_value = 1\n",
    "    return np.interp(array, (np.amin(array), np.amax(array)),\n",
    "                     (min_value, max_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "#def run_test_harness():\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "dropout = 0.8\n",
    "learning_rate = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:173: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n",
      "  warnings.warn('Using \".tiff\" files with multiple bands '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3561 images belonging to 2 classes.\n",
      "Found 1032 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "file = '../data/processed/iris_data/LG2200/gender/train/Male/02463d1896.tiff'\n",
    "width, height = imagesize.get(file)\n",
    "print(width, height)\n",
    "\n",
    "\n",
    "# entry point, run the test harness\n",
    "dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "\n",
    "train_path = dataset_home + 'train/'\n",
    "test_path = dataset_home + 'test/'\n",
    "\n",
    "# prueba = load_all_images(train_path+'Male', height, width, 'tiff')\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "train_datagen.fit(load_all_images(train_path+'Male', height, width, 'tiff'))\n",
    "train_datagen.fit(load_all_images(train_path+'Female', height, width, 'tiff'))\n",
    "# train_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "# train_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "# test_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "# test_datagen.fit(load_all_images(train_path+'Male', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(train_path+'Female', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "# test_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "\n",
    "# prepare iterators\n",
    "train_it = train_datagen.flow_from_directory(train_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(224, 224))\n",
    "# test_it = test_datagen.flow_from_directory(test_path,\n",
    "#     class_mode='binary', batch_size=batch_size, target_size=(240, 320))    \n",
    "test_it = train_datagen.flow_from_directory(test_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_applications\\mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/200\n",
      "56/56 [==============================] - 40s 714ms/step - loss: 4.0855 - accuracy: 0.5313 - val_loss: 1.0566 - val_accuracy: 0.4952\n",
      "WARNING:tensorflow:From D:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 30s 528ms/step - loss: 0.6566 - accuracy: 0.6428 - val_loss: 0.4597 - val_accuracy: 0.6153\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.5839 - accuracy: 0.6905 - val_loss: 0.7027 - val_accuracy: 0.7151\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 29s 523ms/step - loss: 0.5032 - accuracy: 0.7509 - val_loss: 0.5312 - val_accuracy: 0.7171\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 31s 554ms/step - loss: 0.4887 - accuracy: 0.7582 - val_loss: 0.4694 - val_accuracy: 0.7287\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 31s 553ms/step - loss: 0.4677 - accuracy: 0.7765 - val_loss: 0.4812 - val_accuracy: 0.6686\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 30s 534ms/step - loss: 0.5091 - accuracy: 0.7565 - val_loss: 0.7223 - val_accuracy: 0.6318\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 29s 510ms/step - loss: 0.4528 - accuracy: 0.7753 - val_loss: 0.7441 - val_accuracy: 0.6153\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 29s 511ms/step - loss: 0.4520 - accuracy: 0.7883 - val_loss: 0.6574 - val_accuracy: 0.6570\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 29s 512ms/step - loss: 0.4471 - accuracy: 0.7815 - val_loss: 0.4738 - val_accuracy: 0.7316\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 29s 511ms/step - loss: 0.4909 - accuracy: 0.7638 - val_loss: 0.5229 - val_accuracy: 0.6415\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 30s 534ms/step - loss: 0.4203 - accuracy: 0.8074 - val_loss: 0.7157 - val_accuracy: 0.7384\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 30s 540ms/step - loss: 0.4495 - accuracy: 0.7905 - val_loss: 1.7958 - val_accuracy: 0.5048\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 31s 545ms/step - loss: 0.4605 - accuracy: 0.7796 - val_loss: 0.7115 - val_accuracy: 0.7006\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 28s 508ms/step - loss: 0.3772 - accuracy: 0.8256 - val_loss: 0.2834 - val_accuracy: 0.6793\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 28s 501ms/step - loss: 0.4465 - accuracy: 0.7967 - val_loss: 0.5725 - val_accuracy: 0.6919\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 27s 488ms/step - loss: 0.3800 - accuracy: 0.8290 - val_loss: 0.4903 - val_accuracy: 0.7355\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 28s 494ms/step - loss: 0.3714 - accuracy: 0.8304 - val_loss: 0.3859 - val_accuracy: 0.7093\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 28s 500ms/step - loss: 0.4201 - accuracy: 0.8090 - val_loss: 0.7245 - val_accuracy: 0.7132\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 28s 495ms/step - loss: 0.3485 - accuracy: 0.8416 - val_loss: 1.0225 - val_accuracy: 0.6793\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 28s 498ms/step - loss: 0.3470 - accuracy: 0.8450 - val_loss: 0.3643 - val_accuracy: 0.6473\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 27s 489ms/step - loss: 0.3908 - accuracy: 0.8234 - val_loss: 0.9097 - val_accuracy: 0.6260\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - 27s 482ms/step - loss: 0.3440 - accuracy: 0.8472 - val_loss: 0.2771 - val_accuracy: 0.7306\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 28s 496ms/step - loss: 0.3869 - accuracy: 0.8267 - val_loss: 1.2019 - val_accuracy: 0.7035\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 31s 549ms/step - loss: 0.4377 - accuracy: 0.7891 - val_loss: 0.4426 - val_accuracy: 0.6812\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 32s 573ms/step - loss: 0.3685 - accuracy: 0.8287 - val_loss: 0.7994 - val_accuracy: 0.7345\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 28s 503ms/step - loss: 0.3475 - accuracy: 0.8436 - val_loss: 0.6125 - val_accuracy: 0.7297\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 29s 526ms/step - loss: 0.3933 - accuracy: 0.8130 - val_loss: 1.1265 - val_accuracy: 0.6008\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 31s 558ms/step - loss: 0.3482 - accuracy: 0.8481 - val_loss: 0.5696 - val_accuracy: 0.6938\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 32s 563ms/step - loss: 0.3856 - accuracy: 0.8208 - val_loss: 0.7317 - val_accuracy: 0.7335\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 33s 590ms/step - loss: 0.3113 - accuracy: 0.8624 - val_loss: 0.7166 - val_accuracy: 0.7132\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 39s 691ms/step - loss: 0.3043 - accuracy: 0.8624 - val_loss: 0.3607 - val_accuracy: 0.7103\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 37s 664ms/step - loss: 0.3222 - accuracy: 0.8582 - val_loss: 0.9539 - val_accuracy: 0.6434\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 34s 603ms/step - loss: 0.4007 - accuracy: 0.8138 - val_loss: 0.5672 - val_accuracy: 0.6851\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 34s 608ms/step - loss: 0.3238 - accuracy: 0.8596 - val_loss: 0.3264 - val_accuracy: 0.7141\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 32s 575ms/step - loss: 0.3257 - accuracy: 0.8506 - val_loss: 0.5318 - val_accuracy: 0.7151\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 32s 565ms/step - loss: 0.3094 - accuracy: 0.8565 - val_loss: 0.4635 - val_accuracy: 0.7306\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 30s 544ms/step - loss: 0.3170 - accuracy: 0.8573 - val_loss: 1.3956 - val_accuracy: 0.5911\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 30s 544ms/step - loss: 0.3545 - accuracy: 0.8467 - val_loss: 0.5218 - val_accuracy: 0.7258\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 31s 547ms/step - loss: 0.3012 - accuracy: 0.8652 - val_loss: 0.2713 - val_accuracy: 0.7209\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 27s 490ms/step - loss: 0.2839 - accuracy: 0.8753 - val_loss: 0.4936 - val_accuracy: 0.7297\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 29s 523ms/step - loss: 0.3175 - accuracy: 0.8602 - val_loss: 0.5197 - val_accuracy: 0.7248\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 30s 540ms/step - loss: 0.2958 - accuracy: 0.8689 - val_loss: 0.8800 - val_accuracy: 0.7122\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 34s 603ms/step - loss: 0.3304 - accuracy: 0.8495 - val_loss: 1.0065 - val_accuracy: 0.7016\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 31s 546ms/step - loss: 0.3025 - accuracy: 0.8691 - val_loss: 0.6524 - val_accuracy: 0.7277\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 30s 536ms/step - loss: 0.3093 - accuracy: 0.8722 - val_loss: 0.7146 - val_accuracy: 0.7151\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 30s 529ms/step - loss: 0.3004 - accuracy: 0.8717 - val_loss: 1.1055 - val_accuracy: 0.6541\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 30s 528ms/step - loss: 0.3285 - accuracy: 0.8571 - val_loss: 0.2935 - val_accuracy: 0.7093\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 30s 537ms/step - loss: 0.3224 - accuracy: 0.8596 - val_loss: 0.9497 - val_accuracy: 0.7200\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 30s 543ms/step - loss: 0.2755 - accuracy: 0.8826 - val_loss: 1.3911 - val_accuracy: 0.7122\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 30s 535ms/step - loss: 0.3004 - accuracy: 0.8719 - val_loss: 0.6336 - val_accuracy: 0.6860\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 31s 549ms/step - loss: 0.2885 - accuracy: 0.8781 - val_loss: 0.4030 - val_accuracy: 0.7219\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 30s 537ms/step - loss: 0.2710 - accuracy: 0.8815 - val_loss: 0.7986 - val_accuracy: 0.7267\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 31s 546ms/step - loss: 0.2631 - accuracy: 0.8865 - val_loss: 0.6205 - val_accuracy: 0.7180\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 32s 572ms/step - loss: 0.2811 - accuracy: 0.8742 - val_loss: 0.3877 - val_accuracy: 0.7258\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 31s 560ms/step - loss: 0.2965 - accuracy: 0.8644 - val_loss: 0.5430 - val_accuracy: 0.7112\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 31s 559ms/step - loss: 0.2974 - accuracy: 0.8621 - val_loss: 1.0238 - val_accuracy: 0.7122\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 31s 562ms/step - loss: 0.2734 - accuracy: 0.8801 - val_loss: 0.5710 - val_accuracy: 0.7238\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 32s 569ms/step - loss: 0.3230 - accuracy: 0.8517 - val_loss: 0.6922 - val_accuracy: 0.7025\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 31s 557ms/step - loss: 0.2621 - accuracy: 0.8891 - val_loss: 0.2720 - val_accuracy: 0.6831\n",
      "Epoch 61/200\n",
      "56/56 [==============================] - 31s 560ms/step - loss: 0.2734 - accuracy: 0.8829 - val_loss: 1.1697 - val_accuracy: 0.7306\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 31s 556ms/step - loss: 0.2584 - accuracy: 0.8882 - val_loss: 0.6245 - val_accuracy: 0.7219\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 31s 559ms/step - loss: 0.2599 - accuracy: 0.8874 - val_loss: 0.7196 - val_accuracy: 0.6967\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 32s 563ms/step - loss: 0.2797 - accuracy: 0.8776 - val_loss: 0.5914 - val_accuracy: 0.6851\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 32s 568ms/step - loss: 0.2640 - accuracy: 0.8874 - val_loss: 0.4516 - val_accuracy: 0.7238\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 30s 537ms/step - loss: 0.2837 - accuracy: 0.8736 - val_loss: 0.9207 - val_accuracy: 0.6463\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 31s 545ms/step - loss: 0.2826 - accuracy: 0.8776 - val_loss: 0.3234 - val_accuracy: 0.7112\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 30s 529ms/step - loss: 0.2927 - accuracy: 0.8739 - val_loss: 0.5517 - val_accuracy: 0.7258\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 31s 545ms/step - loss: 0.2327 - accuracy: 0.9003 - val_loss: 0.4094 - val_accuracy: 0.6996\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 31s 547ms/step - loss: 0.2418 - accuracy: 0.9003 - val_loss: 0.5457 - val_accuracy: 0.7025\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 31s 560ms/step - loss: 0.2204 - accuracy: 0.9054 - val_loss: 0.4429 - val_accuracy: 0.6957\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 31s 549ms/step - loss: 0.2568 - accuracy: 0.8908 - val_loss: 0.8971 - val_accuracy: 0.6948\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 32s 572ms/step - loss: 0.2276 - accuracy: 0.9045 - val_loss: 0.4008 - val_accuracy: 0.7297\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 30s 539ms/step - loss: 0.2161 - accuracy: 0.9085 - val_loss: 0.6744 - val_accuracy: 0.7393\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 30s 539ms/step - loss: 0.2423 - accuracy: 0.8955 - val_loss: 1.0027 - val_accuracy: 0.6473\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 32s 580ms/step - loss: 0.2642 - accuracy: 0.8832 - val_loss: 0.9584 - val_accuracy: 0.7316\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 30s 540ms/step - loss: 0.2293 - accuracy: 0.9023 - val_loss: 0.5673 - val_accuracy: 0.7229\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 29s 514ms/step - loss: 0.2579 - accuracy: 0.8894 - val_loss: 0.5860 - val_accuracy: 0.6822\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 33s 586ms/step - loss: 0.2445 - accuracy: 0.8916 - val_loss: 0.1176 - val_accuracy: 0.7384\n",
      "Epoch 80/200\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.1939 - accuracy: 0.9128"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-93692bdb0b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                                   callbacks=callbacks_list)\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[0mtest_it\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\vhcg77\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "mobilenetModel=MobileNet(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         pooling='max') #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "# for layer in mobilenetModel.layers:\n",
    "#     layer.trainable = False\n",
    "x=mobilenetModel.output\n",
    "#x=MaxPooling2D()\n",
    "#x=GlobalAveragePooling2D()(x)\n",
    "#x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "#x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "#x=Dense(256,activation='relu')(x) #dense layer 3\n",
    "x=Dense(64,activation='relu')(x) #dense layer 3\n",
    "output=Dense(1,activation='sigmoid')(x) #final layer with softmax activation\n",
    "\n",
    "# # define new model\n",
    "baseModel = Model(inputs=mobilenetModel.inputs, outputs=output)\n",
    "\n",
    "# # Check the trainable status of the individual layers\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in baseModel.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 87\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable=False\n",
    "for layer in baseModel.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "for layer in baseModel.layers[fine_tune_at:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "# # Check the trainable status of the individual layers\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in baseModel.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "    \n",
    "# compile model\n",
    "# opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "# opt = RMSprop(learning_rate=0.0001, rho=0.99)\n",
    "# opt = Adagrad(learning_rate=learning_rate)\n",
    "# opt = Adadelta(learning_rate=1.0, rho=0.99)\n",
    "# opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "opt = Adamax(learning_rate=0.0034, beta_1=0.9, beta_2=0.999)\n",
    "# opt = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# baseModel.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "baseModel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=5, min_lr=0.01)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# callbacks_list = [ModelCheckpoint(filepath='model.h5', save_best_only=True)]\n",
    "callbacks_list = [tensorboard]\n",
    "# fit model\n",
    "history1 = baseModel.fit_generator(train_it, steps_per_epoch=len(train_it), \n",
    "                                  validation_data=test_it, \n",
    "                                  validation_steps=len(test_it), \n",
    "                                  epochs=epochs, verbose=1,\n",
    "                                  callbacks=callbacks_list)\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = baseModel.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print(train_it.class_indices)\n",
    "#print(baseModel.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history1)\n",
    "#print_metrics(baseModel, test_datagen, test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,786,561\n",
      "Trainable params: 557,697\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001D5910FBB88>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D5910FAC08>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5910FA608>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D590FAD988>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D590FB7E08>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D591266748>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D591105448>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D590FA4288>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5912A4088>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D591146188>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D590FA2788>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D590F92F48>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D590F8D108>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D59112C708>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D59129B6C8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D59120D108>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D590FDC308>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D590F8FFC8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D59128DA88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D590FC24C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5912EBF48>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5C4AE1188>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5C4AF1108>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5C4B01A48>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D5C4B10448>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5C4B24D88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5C4B41508>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5C4B3E348>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5C4B48848>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5C4B77108>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5C4B87C08>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5C4B97448>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5C4BB90C8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5C4BC8848>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5C4BE1C48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5C4BF2348>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5C4C0C608>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D5F923BEC8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5F924C648>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5F9259488>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5F9262FC8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5F927FB88>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5F9290788>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5F92A5648>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5F92C1F08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5F92CCD88>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5F92E5148>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5F9300508>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5F930E788>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5F932A948>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5F9344A48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5F934F348>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5F9364488>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5FB31C348>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5FB33D688>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5FB348AC8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5FB35CD08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5FB36AC48>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5FB389CC8>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5FB3B19C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5FB3BF148>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5FB3D3A08>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5FB3E44C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5FB407148>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5FB418A88>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D5FB434BC8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5FB429648>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D5FB458548>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D5FB476A08>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D5FB481188>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D601516308>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D60152F088>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D601541608>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D60155D988>: False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D60157AA88>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D60158C788>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D601599508>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D60159B708>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D6015B74C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D6015B2108>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D6015E59C8>: False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D6016099C8>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D601600CC8>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D60161F508>: False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D601655F48>: False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D601659108>: False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D601669EC8>: False\n",
      "<keras.layers.pooling.GlobalMaxPooling2D object at 0x000001D601686748>: True\n",
      "<keras.layers.core.Dense object at 0x000001D590FBA188>: True\n",
      "<keras.layers.core.Dense object at 0x000001D590FBA408>: True\n",
      "<keras.layers.core.Dense object at 0x000001D6016C52C8>: True\n"
     ]
    }
   ],
   "source": [
    "# Check the trainable status of the individual layers\n",
    "print(\"\\r\\r\\r\\r\")\n",
    "for layer in baseModel.layers:\n",
    "    print(\"{}: {}\".format(layer, layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel.save('Base_Model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "112/112 [==============================] - 42s 377ms/step - loss: 0.3736 - accuracy: 0.8343 - val_loss: 0.7036 - val_accuracy: 0.7287\n",
      "Epoch 2/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.3625 - accuracy: 0.8425 - val_loss: 0.2671 - val_accuracy: 0.7432\n",
      "Epoch 3/200\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.3651 - accuracy: 0.8441 - val_loss: 0.3628 - val_accuracy: 0.7510\n",
      "Epoch 4/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.3636 - accuracy: 0.8366 - val_loss: 0.5305 - val_accuracy: 0.7539\n",
      "Epoch 5/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.3601 - accuracy: 0.8461 - val_loss: 0.5083 - val_accuracy: 0.7548\n",
      "Epoch 6/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.3460 - accuracy: 0.8526 - val_loss: 0.5661 - val_accuracy: 0.7539\n",
      "Epoch 7/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.3505 - accuracy: 0.8517 - val_loss: 0.2554 - val_accuracy: 0.7568\n",
      "Epoch 8/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.3449 - accuracy: 0.8573 - val_loss: 0.3637 - val_accuracy: 0.7597\n",
      "Epoch 9/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.3415 - accuracy: 0.8616 - val_loss: 0.3757 - val_accuracy: 0.7548\n",
      "Epoch 10/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.3360 - accuracy: 0.8621 - val_loss: 0.5381 - val_accuracy: 0.7578\n",
      "Epoch 11/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.3299 - accuracy: 0.8638 - val_loss: 1.0129 - val_accuracy: 0.7578\n",
      "Epoch 12/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.3261 - accuracy: 0.8646 - val_loss: 0.4685 - val_accuracy: 0.7587\n",
      "Epoch 13/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.3202 - accuracy: 0.8719 - val_loss: 0.4119 - val_accuracy: 0.7587\n",
      "Epoch 14/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.3207 - accuracy: 0.8691 - val_loss: 0.4784 - val_accuracy: 0.7607\n",
      "Epoch 15/200\n",
      "112/112 [==============================] - 41s 363ms/step - loss: 0.3187 - accuracy: 0.8677 - val_loss: 0.4472 - val_accuracy: 0.7597\n",
      "Epoch 16/200\n",
      "112/112 [==============================] - 44s 393ms/step - loss: 0.3092 - accuracy: 0.8722 - val_loss: 0.3334 - val_accuracy: 0.7636\n",
      "Epoch 17/200\n",
      "112/112 [==============================] - 43s 381ms/step - loss: 0.3095 - accuracy: 0.8689 - val_loss: 0.2363 - val_accuracy: 0.7626\n",
      "Epoch 18/200\n",
      "112/112 [==============================] - 44s 391ms/step - loss: 0.3080 - accuracy: 0.8736 - val_loss: 0.3919 - val_accuracy: 0.7645\n",
      "Epoch 19/200\n",
      "112/112 [==============================] - 43s 387ms/step - loss: 0.3029 - accuracy: 0.8815 - val_loss: 0.4187 - val_accuracy: 0.7645\n",
      "Epoch 20/200\n",
      "112/112 [==============================] - 44s 388ms/step - loss: 0.3016 - accuracy: 0.8770 - val_loss: 0.5469 - val_accuracy: 0.7645\n",
      "Epoch 21/200\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.2953 - accuracy: 0.8790 - val_loss: 1.0244 - val_accuracy: 0.7655\n",
      "Epoch 22/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.2893 - accuracy: 0.8888 - val_loss: 0.4187 - val_accuracy: 0.7684\n",
      "Epoch 23/200\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.2883 - accuracy: 0.8826 - val_loss: 0.4286 - val_accuracy: 0.7674\n",
      "Epoch 24/200\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.2799 - accuracy: 0.8975 - val_loss: 0.2933 - val_accuracy: 0.7694\n",
      "Epoch 25/200\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.2803 - accuracy: 0.8947 - val_loss: 0.6914 - val_accuracy: 0.7684\n",
      "Epoch 26/200\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.2805 - accuracy: 0.8910 - val_loss: 0.3782 - val_accuracy: 0.7713\n",
      "Epoch 27/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.2791 - accuracy: 0.8880 - val_loss: 0.4275 - val_accuracy: 0.7752\n",
      "Epoch 28/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.2748 - accuracy: 0.8941 - val_loss: 0.6504 - val_accuracy: 0.7733\n",
      "Epoch 29/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.2684 - accuracy: 0.8983 - val_loss: 0.6676 - val_accuracy: 0.7723\n",
      "Epoch 30/200\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.2698 - accuracy: 0.8997 - val_loss: 0.1491 - val_accuracy: 0.7694\n",
      "Epoch 31/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.2613 - accuracy: 0.9026 - val_loss: 0.6158 - val_accuracy: 0.7771\n",
      "Epoch 32/200\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.2596 - accuracy: 0.9034 - val_loss: 0.4439 - val_accuracy: 0.7791\n",
      "Epoch 33/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.2544 - accuracy: 0.9087 - val_loss: 0.4673 - val_accuracy: 0.7752\n",
      "Epoch 34/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.2513 - accuracy: 0.9028 - val_loss: 0.6295 - val_accuracy: 0.7762\n",
      "Epoch 35/200\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.2499 - accuracy: 0.9082 - val_loss: 0.3966 - val_accuracy: 0.7791\n",
      "Epoch 36/200\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.2543 - accuracy: 0.9028 - val_loss: 0.8436 - val_accuracy: 0.7771\n",
      "Epoch 37/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.2413 - accuracy: 0.9129 - val_loss: 0.7554 - val_accuracy: 0.7781\n",
      "Epoch 38/200\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.2439 - accuracy: 0.9079 - val_loss: 0.6920 - val_accuracy: 0.7781\n",
      "Epoch 39/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.2420 - accuracy: 0.9138 - val_loss: 0.3065 - val_accuracy: 0.7781\n",
      "Epoch 40/200\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.2357 - accuracy: 0.9188 - val_loss: 0.6565 - val_accuracy: 0.7800\n",
      "Epoch 41/200\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.2410 - accuracy: 0.9107 - val_loss: 0.1387 - val_accuracy: 0.7820\n",
      "Epoch 42/200\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.2334 - accuracy: 0.9163 - val_loss: 0.5120 - val_accuracy: 0.7810\n",
      "Epoch 43/200\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.2338 - accuracy: 0.9174 - val_loss: 0.4172 - val_accuracy: 0.7820\n",
      "Epoch 44/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.2273 - accuracy: 0.9222 - val_loss: 0.5320 - val_accuracy: 0.7771\n",
      "Epoch 45/200\n",
      "112/112 [==============================] - 32s 281ms/step - loss: 0.2240 - accuracy: 0.9186 - val_loss: 0.4642 - val_accuracy: 0.7820\n",
      "Epoch 46/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.2233 - accuracy: 0.9202 - val_loss: 0.2413 - val_accuracy: 0.7820\n",
      "Epoch 47/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.2202 - accuracy: 0.9217 - val_loss: 0.5923 - val_accuracy: 0.7859\n",
      "Epoch 48/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.2154 - accuracy: 0.9326 - val_loss: 0.3496 - val_accuracy: 0.7839\n",
      "Epoch 49/200\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.2149 - accuracy: 0.9202 - val_loss: 0.5553 - val_accuracy: 0.7907\n",
      "Epoch 50/200\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.2117 - accuracy: 0.9295 - val_loss: 0.5401 - val_accuracy: 0.7897\n",
      "Epoch 51/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.2076 - accuracy: 0.9323 - val_loss: 0.1766 - val_accuracy: 0.7897\n",
      "Epoch 52/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.2055 - accuracy: 0.9301 - val_loss: 0.5964 - val_accuracy: 0.7907\n",
      "Epoch 53/200\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.2038 - accuracy: 0.9337 - val_loss: 0.5940 - val_accuracy: 0.7926\n",
      "Epoch 54/200\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.2110 - accuracy: 0.9273 - val_loss: 0.5655 - val_accuracy: 0.7917\n",
      "Epoch 55/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.2005 - accuracy: 0.9354 - val_loss: 0.2899 - val_accuracy: 0.7926\n",
      "Epoch 56/200\n",
      "112/112 [==============================] - 39s 349ms/step - loss: 0.1927 - accuracy: 0.9354 - val_loss: 0.9327 - val_accuracy: 0.7907\n",
      "Epoch 57/200\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.1948 - accuracy: 0.9315 - val_loss: 0.7251 - val_accuracy: 0.7907\n",
      "Epoch 58/200\n",
      "112/112 [==============================] - 43s 388ms/step - loss: 0.1939 - accuracy: 0.9374 - val_loss: 0.6534 - val_accuracy: 0.7907\n",
      "Epoch 59/200\n",
      "112/112 [==============================] - 40s 360ms/step - loss: 0.1905 - accuracy: 0.9368 - val_loss: 0.7658 - val_accuracy: 0.7926\n",
      "Epoch 60/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1878 - accuracy: 0.9433 - val_loss: 0.2598 - val_accuracy: 0.7926\n",
      "Epoch 61/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.1886 - accuracy: 0.9388 - val_loss: 0.6056 - val_accuracy: 0.7936\n",
      "Epoch 62/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1878 - accuracy: 0.9430 - val_loss: 0.3622 - val_accuracy: 0.7936\n",
      "Epoch 63/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1770 - accuracy: 0.9466 - val_loss: 0.9536 - val_accuracy: 0.7936\n",
      "Epoch 64/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.1809 - accuracy: 0.9419 - val_loss: 0.5135 - val_accuracy: 0.7936\n",
      "Epoch 65/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1857 - accuracy: 0.9407 - val_loss: 0.6320 - val_accuracy: 0.7936\n",
      "Epoch 66/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.1759 - accuracy: 0.9478 - val_loss: 0.2862 - val_accuracy: 0.7907\n",
      "Epoch 67/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.1756 - accuracy: 0.9469 - val_loss: 0.2877 - val_accuracy: 0.7936\n",
      "Epoch 68/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1716 - accuracy: 0.9461 - val_loss: 0.4890 - val_accuracy: 0.7955\n",
      "Epoch 69/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.1694 - accuracy: 0.9489 - val_loss: 0.3580 - val_accuracy: 0.7926\n",
      "Epoch 70/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.1685 - accuracy: 0.9495 - val_loss: 0.5926 - val_accuracy: 0.7936\n",
      "Epoch 71/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.1682 - accuracy: 0.9509 - val_loss: 0.2448 - val_accuracy: 0.7936\n",
      "Epoch 72/200\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.1664 - accuracy: 0.9475 - val_loss: 0.0901 - val_accuracy: 0.7888\n",
      "Epoch 73/200\n",
      "112/112 [==============================] - 42s 373ms/step - loss: 0.1630 - accuracy: 0.9542 - val_loss: 0.6568 - val_accuracy: 0.7965\n",
      "Epoch 74/200\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.1607 - accuracy: 0.9556 - val_loss: 0.3038 - val_accuracy: 0.7936\n",
      "Epoch 75/200\n",
      "112/112 [==============================] - 43s 380ms/step - loss: 0.1606 - accuracy: 0.9506 - val_loss: 0.3654 - val_accuracy: 0.7926\n",
      "Epoch 76/200\n",
      "112/112 [==============================] - 39s 349ms/step - loss: 0.1557 - accuracy: 0.9525 - val_loss: 0.3917 - val_accuracy: 0.7917\n",
      "Epoch 77/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.1463 - accuracy: 0.9607 - val_loss: 0.1830 - val_accuracy: 0.7917\n",
      "Epoch 78/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1528 - accuracy: 0.9553 - val_loss: 0.7317 - val_accuracy: 0.8033\n",
      "Epoch 79/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.1493 - accuracy: 0.9598 - val_loss: 0.4095 - val_accuracy: 0.7965\n",
      "Epoch 80/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.1503 - accuracy: 0.9587 - val_loss: 0.2512 - val_accuracy: 0.8023\n",
      "Epoch 81/200\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.1450 - accuracy: 0.9590 - val_loss: 0.3327 - val_accuracy: 0.7994\n",
      "Epoch 82/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1432 - accuracy: 0.9635 - val_loss: 0.4348 - val_accuracy: 0.7965\n",
      "Epoch 83/200\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.1367 - accuracy: 0.9666 - val_loss: 0.5263 - val_accuracy: 0.8043\n",
      "Epoch 84/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1387 - accuracy: 0.9610 - val_loss: 0.1719 - val_accuracy: 0.8023\n",
      "Epoch 85/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1445 - accuracy: 0.9576 - val_loss: 0.3498 - val_accuracy: 0.8014\n",
      "Epoch 86/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1385 - accuracy: 0.9584 - val_loss: 0.2769 - val_accuracy: 0.8023\n",
      "Epoch 87/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1408 - accuracy: 0.9582 - val_loss: 0.5264 - val_accuracy: 0.8004\n",
      "Epoch 88/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.1363 - accuracy: 0.9638 - val_loss: 0.4920 - val_accuracy: 0.8052\n",
      "Epoch 89/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1348 - accuracy: 0.9618 - val_loss: 0.2377 - val_accuracy: 0.8014\n",
      "Epoch 90/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1373 - accuracy: 0.9604 - val_loss: 0.2630 - val_accuracy: 0.8023\n",
      "Epoch 91/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1271 - accuracy: 0.9694 - val_loss: 0.7469 - val_accuracy: 0.8023\n",
      "Epoch 92/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.1321 - accuracy: 0.9669 - val_loss: 0.1372 - val_accuracy: 0.8014\n",
      "Epoch 93/200\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.1254 - accuracy: 0.9691 - val_loss: 0.2862 - val_accuracy: 0.8033\n",
      "Epoch 94/200\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.1266 - accuracy: 0.9677 - val_loss: 0.3460 - val_accuracy: 0.8023\n",
      "Epoch 95/200\n",
      "112/112 [==============================] - 39s 348ms/step - loss: 0.1240 - accuracy: 0.9700 - val_loss: 0.3769 - val_accuracy: 0.7994\n",
      "Epoch 96/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1162 - accuracy: 0.9761 - val_loss: 0.7967 - val_accuracy: 0.8033\n",
      "Epoch 97/200\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.1201 - accuracy: 0.9714 - val_loss: 0.9336 - val_accuracy: 0.8014\n",
      "Epoch 98/200\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.1165 - accuracy: 0.9742 - val_loss: 0.2854 - val_accuracy: 0.8004\n",
      "Epoch 99/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.1211 - accuracy: 0.9683 - val_loss: 0.6898 - val_accuracy: 0.8043\n",
      "Epoch 100/200\n",
      "112/112 [==============================] - 39s 350ms/step - loss: 0.1185 - accuracy: 0.9761 - val_loss: 0.4910 - val_accuracy: 0.8052\n",
      "Epoch 101/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1094 - accuracy: 0.9778 - val_loss: 0.3412 - val_accuracy: 0.8072\n",
      "Epoch 102/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.1132 - accuracy: 0.9705 - val_loss: 0.5632 - val_accuracy: 0.8014\n",
      "Epoch 103/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1122 - accuracy: 0.9744 - val_loss: 0.3514 - val_accuracy: 0.8033\n",
      "Epoch 104/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1131 - accuracy: 0.9747 - val_loss: 0.3307 - val_accuracy: 0.8033\n",
      "Epoch 105/200\n",
      "112/112 [==============================] - 40s 353ms/step - loss: 0.1026 - accuracy: 0.9809 - val_loss: 0.5375 - val_accuracy: 0.8072\n",
      "Epoch 106/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1060 - accuracy: 0.9756 - val_loss: 0.2440 - val_accuracy: 0.8091\n",
      "Epoch 107/200\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.1133 - accuracy: 0.9705 - val_loss: 0.7658 - val_accuracy: 0.8052\n",
      "Epoch 108/200\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.1039 - accuracy: 0.9784 - val_loss: 1.2380 - val_accuracy: 0.8052\n",
      "Epoch 109/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.1094 - accuracy: 0.9758 - val_loss: 0.6614 - val_accuracy: 0.8023\n",
      "Epoch 110/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.1050 - accuracy: 0.9756 - val_loss: 0.4124 - val_accuracy: 0.8043\n",
      "Epoch 111/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1002 - accuracy: 0.9798 - val_loss: 0.3384 - val_accuracy: 0.8052\n",
      "Epoch 112/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.1005 - accuracy: 0.9798 - val_loss: 0.3998 - val_accuracy: 0.8052\n",
      "Epoch 113/200\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.0989 - accuracy: 0.9789 - val_loss: 0.3438 - val_accuracy: 0.8062\n",
      "Epoch 114/200\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.0982 - accuracy: 0.9795 - val_loss: 0.5915 - val_accuracy: 0.8052\n",
      "Epoch 115/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.1024 - accuracy: 0.9747 - val_loss: 0.4329 - val_accuracy: 0.8072\n",
      "Epoch 116/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.0979 - accuracy: 0.9775 - val_loss: 0.4007 - val_accuracy: 0.8072\n",
      "Epoch 117/200\n",
      "112/112 [==============================] - 39s 351ms/step - loss: 0.0962 - accuracy: 0.9803 - val_loss: 0.3574 - val_accuracy: 0.8072\n",
      "Epoch 118/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.0940 - accuracy: 0.9806 - val_loss: 0.3089 - val_accuracy: 0.8062\n",
      "Epoch 119/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.0874 - accuracy: 0.9854 - val_loss: 0.3212 - val_accuracy: 0.8081\n",
      "Epoch 120/200\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.0883 - accuracy: 0.9837 - val_loss: 0.1018 - val_accuracy: 0.8043\n",
      "Epoch 121/200\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.0909 - accuracy: 0.9815 - val_loss: 0.3950 - val_accuracy: 0.8062\n",
      "Epoch 122/200\n",
      "112/112 [==============================] - 38s 341ms/step - loss: 0.0872 - accuracy: 0.9829 - val_loss: 0.1437 - val_accuracy: 0.8091\n",
      "Epoch 123/200\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.0883 - accuracy: 0.9837 - val_loss: 0.3819 - val_accuracy: 0.8091\n",
      "Epoch 124/200\n",
      "112/112 [==============================] - 39s 348ms/step - loss: 0.0869 - accuracy: 0.9840 - val_loss: 0.1018 - val_accuracy: 0.8033\n",
      "Epoch 125/200\n",
      "112/112 [==============================] - 41s 365ms/step - loss: 0.0918 - accuracy: 0.9798 - val_loss: 0.5691 - val_accuracy: 0.8072\n",
      "Epoch 126/200\n",
      "112/112 [==============================] - 40s 359ms/step - loss: 0.0837 - accuracy: 0.9834 - val_loss: 0.3020 - val_accuracy: 0.8033\n",
      "Epoch 127/200\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.0823 - accuracy: 0.9848 - val_loss: 0.4981 - val_accuracy: 0.8091\n",
      "Epoch 128/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0855 - accuracy: 0.9837 - val_loss: 0.6296 - val_accuracy: 0.8091\n",
      "Epoch 129/200\n",
      "112/112 [==============================] - 42s 377ms/step - loss: 0.0795 - accuracy: 0.9885 - val_loss: 0.1443 - val_accuracy: 0.8081\n",
      "Epoch 130/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0796 - accuracy: 0.9882 - val_loss: 0.2447 - val_accuracy: 0.8081\n",
      "Epoch 131/200\n",
      "112/112 [==============================] - 41s 363ms/step - loss: 0.0801 - accuracy: 0.9868 - val_loss: 0.5514 - val_accuracy: 0.8110\n",
      "Epoch 132/200\n",
      "112/112 [==============================] - 40s 354ms/step - loss: 0.0851 - accuracy: 0.9832 - val_loss: 0.4389 - val_accuracy: 0.8101\n",
      "Epoch 133/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.0754 - accuracy: 0.9879 - val_loss: 0.6002 - val_accuracy: 0.8110\n",
      "Epoch 134/200\n",
      "112/112 [==============================] - 43s 386ms/step - loss: 0.0738 - accuracy: 0.9890 - val_loss: 0.1222 - val_accuracy: 0.8062\n",
      "Epoch 135/200\n",
      "112/112 [==============================] - 42s 374ms/step - loss: 0.0780 - accuracy: 0.9854 - val_loss: 0.3178 - val_accuracy: 0.8130\n",
      "Epoch 136/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0729 - accuracy: 0.9885 - val_loss: 1.1329 - val_accuracy: 0.8052\n",
      "Epoch 137/200\n",
      "112/112 [==============================] - 41s 369ms/step - loss: 0.0796 - accuracy: 0.9846 - val_loss: 0.2690 - val_accuracy: 0.8130\n",
      "Epoch 138/200\n",
      "112/112 [==============================] - 39s 351ms/step - loss: 0.0776 - accuracy: 0.9834 - val_loss: 0.5667 - val_accuracy: 0.8033\n",
      "Epoch 139/200\n",
      "112/112 [==============================] - 41s 362ms/step - loss: 0.0712 - accuracy: 0.9890 - val_loss: 0.7363 - val_accuracy: 0.8043\n",
      "Epoch 140/200\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.0724 - accuracy: 0.9879 - val_loss: 0.0963 - val_accuracy: 0.8081\n",
      "Epoch 141/200\n",
      "112/112 [==============================] - 45s 398ms/step - loss: 0.0683 - accuracy: 0.9907 - val_loss: 0.5483 - val_accuracy: 0.8140\n",
      "Epoch 142/200\n",
      "112/112 [==============================] - 48s 432ms/step - loss: 0.0672 - accuracy: 0.9902 - val_loss: 0.2822 - val_accuracy: 0.8130\n",
      "Epoch 143/200\n",
      "112/112 [==============================] - 43s 388ms/step - loss: 0.0698 - accuracy: 0.9890 - val_loss: 0.1463 - val_accuracy: 0.8120\n",
      "Epoch 144/200\n",
      "112/112 [==============================] - 40s 356ms/step - loss: 0.0689 - accuracy: 0.9882 - val_loss: 1.0548 - val_accuracy: 0.8110\n",
      "Epoch 145/200\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.0672 - accuracy: 0.9888 - val_loss: 0.2710 - val_accuracy: 0.8140\n",
      "Epoch 146/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0622 - accuracy: 0.9913 - val_loss: 0.2894 - val_accuracy: 0.8052\n",
      "Epoch 147/200\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.0709 - accuracy: 0.9907 - val_loss: 0.7138 - val_accuracy: 0.8110\n",
      "Epoch 148/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0651 - accuracy: 0.9910 - val_loss: 1.6487 - val_accuracy: 0.8091\n",
      "Epoch 149/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0629 - accuracy: 0.9888 - val_loss: 0.3689 - val_accuracy: 0.8130\n",
      "Epoch 150/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0670 - accuracy: 0.9899 - val_loss: 0.4611 - val_accuracy: 0.8140\n",
      "Epoch 151/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0656 - accuracy: 0.9893 - val_loss: 0.2178 - val_accuracy: 0.8091\n",
      "Epoch 152/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.0627 - accuracy: 0.9927 - val_loss: 0.4291 - val_accuracy: 0.8081\n",
      "Epoch 153/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.0669 - accuracy: 0.9899 - val_loss: 0.5142 - val_accuracy: 0.8091\n",
      "Epoch 154/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0656 - accuracy: 0.9893 - val_loss: 0.3262 - val_accuracy: 0.8052\n",
      "Epoch 155/200\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.0569 - accuracy: 0.9947 - val_loss: 0.3828 - val_accuracy: 0.8140\n",
      "Epoch 156/200\n",
      "112/112 [==============================] - 40s 354ms/step - loss: 0.0584 - accuracy: 0.9927 - val_loss: 0.2687 - val_accuracy: 0.8120\n",
      "Epoch 157/200\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.0629 - accuracy: 0.9890 - val_loss: 0.4693 - val_accuracy: 0.8149\n",
      "Epoch 158/200\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.0618 - accuracy: 0.9890 - val_loss: 0.2596 - val_accuracy: 0.8091\n",
      "Epoch 159/200\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.0568 - accuracy: 0.9938 - val_loss: 0.1980 - val_accuracy: 0.8149\n",
      "Epoch 160/200\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.0571 - accuracy: 0.9899 - val_loss: 0.5353 - val_accuracy: 0.8140\n",
      "Epoch 161/200\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.0610 - accuracy: 0.9905 - val_loss: 0.3095 - val_accuracy: 0.8110\n",
      "Epoch 162/200\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.0533 - accuracy: 0.9933 - val_loss: 0.7093 - val_accuracy: 0.8101\n",
      "Epoch 163/200\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.0557 - accuracy: 0.9924 - val_loss: 0.6226 - val_accuracy: 0.8081\n",
      "Epoch 164/200\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.0590 - accuracy: 0.9896 - val_loss: 0.4830 - val_accuracy: 0.8149\n",
      "Epoch 165/200\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.0508 - accuracy: 0.9961 - val_loss: 0.2198 - val_accuracy: 0.8130\n",
      "Epoch 166/200\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.0530 - accuracy: 0.9913 - val_loss: 0.2464 - val_accuracy: 0.8159\n",
      "Epoch 167/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0520 - accuracy: 0.9944 - val_loss: 0.2224 - val_accuracy: 0.8149\n",
      "Epoch 168/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0521 - accuracy: 0.9933 - val_loss: 0.2677 - val_accuracy: 0.8159\n",
      "Epoch 169/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0568 - accuracy: 0.9885 - val_loss: 0.6932 - val_accuracy: 0.8101\n",
      "Epoch 170/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.0533 - accuracy: 0.9952 - val_loss: 0.3631 - val_accuracy: 0.8140\n",
      "Epoch 171/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0494 - accuracy: 0.9963 - val_loss: 0.5685 - val_accuracy: 0.8130\n",
      "Epoch 172/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.0544 - accuracy: 0.9935 - val_loss: 0.4008 - val_accuracy: 0.8101\n",
      "Epoch 173/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.0534 - accuracy: 0.9924 - val_loss: 0.7678 - val_accuracy: 0.8149\n",
      "Epoch 174/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0517 - accuracy: 0.9935 - val_loss: 0.6376 - val_accuracy: 0.8120\n",
      "Epoch 175/200\n",
      "112/112 [==============================] - 32s 281ms/step - loss: 0.0469 - accuracy: 0.9944 - val_loss: 0.6604 - val_accuracy: 0.8130\n",
      "Epoch 176/200\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0483 - accuracy: 0.9938 - val_loss: 0.7673 - val_accuracy: 0.8149\n",
      "Epoch 177/200\n",
      "112/112 [==============================] - 31s 280ms/step - loss: 0.0478 - accuracy: 0.9949 - val_loss: 0.4159 - val_accuracy: 0.8140\n",
      "Epoch 178/200\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.0494 - accuracy: 0.9941 - val_loss: 0.1891 - val_accuracy: 0.8110\n",
      "Epoch 179/200\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.0460 - accuracy: 0.9952 - val_loss: 0.2110 - val_accuracy: 0.8120\n",
      "Epoch 180/200\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.0471 - accuracy: 0.9935 - val_loss: 0.2619 - val_accuracy: 0.8140\n",
      "Epoch 181/200\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.0461 - accuracy: 0.9963 - val_loss: 0.3584 - val_accuracy: 0.8159\n",
      "Epoch 182/200\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.0417 - accuracy: 0.9966 - val_loss: 0.8708 - val_accuracy: 0.8140\n",
      "Epoch 183/200\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.0444 - accuracy: 0.9966 - val_loss: 0.1453 - val_accuracy: 0.8120\n",
      "Epoch 184/200\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.0442 - accuracy: 0.9952 - val_loss: 0.0580 - val_accuracy: 0.8140\n",
      "Epoch 185/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0453 - accuracy: 0.9941 - val_loss: 0.0913 - val_accuracy: 0.8072\n",
      "Epoch 186/200\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.0421 - accuracy: 0.9952 - val_loss: 0.2476 - val_accuracy: 0.8149\n",
      "Epoch 187/200\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.0461 - accuracy: 0.9952 - val_loss: 0.5245 - val_accuracy: 0.8140\n",
      "Epoch 188/200\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.0418 - accuracy: 0.9952 - val_loss: 0.2965 - val_accuracy: 0.8130\n",
      "Epoch 189/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0432 - accuracy: 0.9955 - val_loss: 0.4554 - val_accuracy: 0.8130\n",
      "Epoch 190/200\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.0458 - accuracy: 0.9944 - val_loss: 0.1735 - val_accuracy: 0.8130\n",
      "Epoch 191/200\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.0391 - accuracy: 0.9966 - val_loss: 0.1954 - val_accuracy: 0.8130\n",
      "Epoch 192/200\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.0428 - accuracy: 0.9966 - val_loss: 0.3924 - val_accuracy: 0.8130\n",
      "Epoch 193/200\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.0414 - accuracy: 0.9966 - val_loss: 0.4824 - val_accuracy: 0.8130\n",
      "Epoch 194/200\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.0418 - accuracy: 0.9966 - val_loss: 0.1003 - val_accuracy: 0.8149\n",
      "Epoch 195/200\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.0411 - accuracy: 0.9963 - val_loss: 0.1709 - val_accuracy: 0.8140\n",
      "Epoch 196/200\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.0393 - accuracy: 0.9961 - val_loss: 0.3857 - val_accuracy: 0.8120\n",
      "Epoch 197/200\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.0406 - accuracy: 0.9952 - val_loss: 0.8304 - val_accuracy: 0.8140\n",
      "Epoch 198/200\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.0380 - accuracy: 0.9966 - val_loss: 0.3250 - val_accuracy: 0.8140\n",
      "Epoch 199/200\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.0392 - accuracy: 0.9955 - val_loss: 0.5078 - val_accuracy: 0.8120\n",
      "Epoch 200/200\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.0394 - accuracy: 0.9966 - val_loss: 0.5492 - val_accuracy: 0.8120\n",
      "{'Female': 0, 'Male': 1}\n",
      "> 81.202\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5hU1f3GP3dmtjd26SwgWNAosEgRRUVQQYlix2iiBvNTo1iiJpbYg4kmkhgbhhijSYzGjooNRQUbHUEEkV6WDrtsLzNz7++Pc8+dM3fu9NllF+Z9nn125s4t57b3vOc93/M9mmEYpJFGGmmk0f7h2t8FSCONNNJIIzVIE3oaaaSRxgGCNKGnkUYaaRwgSBN6GmmkkcYBgjShp5FGGmkcIPDsrwN36tTJ6NOnz/46fBppJA+9CfZ9Jz4X/gg8ufu3PNFQuQw8eVBweOL7aNoNdZtBc0FGEeQfmrrypRETFi9evMcwjM5Ov+03Qu/Tpw+LFi3aX4dPI43kUf0DvHuU+HzGf6Dj0P1bnmh4vQQ6DofRHyS+jzV/g4WTILMIuo2Bk15JXfnSiAmapm0K91vackkjjUSh+wKfDV/49doKDF38JbsPAM2T/L7SSDnShJ5GGonC8AY+6+2B0P3iL9l9ALg8QJrQ2xrShJ5GGokiSKEnSZStAcNP0iQcpNDTo8zbGtKEnkYaiUJXFHq7sVySVegKoacVeptDmtDTSCNRqCTebiyXZBW6YrmkPfQ2hzShp5FGomh3Cj1OD93fBN5q28K05dKWkSb0NNJIFEGE3sY9dMMAjPhU9bf3wSen2vZjbp/uFG2TSBN6GmkkCqMdhS1KIo6n4mncAQ3bbfsxt0+HLbZJpAk9jTQShd6OwhYlEcdDwk5x60GdomnLpa0hTehppJEo2pNCJwGF7uS5W4TuTiv0Nog0oaeRRqJoVx66LF+8Ct1O6H5AE7lc0oTe5pAm9Hiw+Q3Y/Nr+LkUabQXtKWzRslziqXic4tZ1oc41F+lO0baH/Zacq11i9RPiAe89YX+XJI22gPYUtmh1isaj0B3i1g1dkLnmSocttkFEVeiapj2nadouTdO+C/O7pmnaE5qmrdU07VtN0wanvpgpxOqpULsxsW11H+htvGmdRuuhXRF6Ago9nOWiuQCNtEJve4jFcvkXcGaE38cBR5h/1wB/S75YLQRfHSy6ATYnmPJT97Z9rzSN1kOQ5dLGn4uEolzCdIpKyyXtobc5RCV0wzA+ByoirHIu8B9DYB7QQdO07qkqYEohFVWifqfha/tKLI3WQ7tS6IlEuTgpdB1BGy7SYYttD6nw0EuBLcr3cnPZdvuKmqZdg1Dx9O7dOwWHjhPyBUz05dO9oGmpK08a7RvtKWwx0Th0u60iLZcYFfr6yvXsa9zHwK4D8bgCdNPsb8an+8jNCMzy5PV78bg8aOY7tnjbYj7b+BnXDLkGDY2Vu1fSq6gX3fO7o2kaX2z6gs82fkZFQwVjDh3D6L6jyc3IpcnXRHl1Odtrt5OXkUezv5kt1VsozCrErbnZUr2F3kW9cWkuZvwwg70Ne/HpPny6j2753ejXsR/9Ovaj0dfI1uqteHUvft2P3/Dj1/0U5xRTnF3M3PK5lFeX43a58bg8uDU3bs38bC7rnNsZl+ZidcVqirKKKMoqYmPVRs487EwuHXBp7PciRqSC0J0YzrHqNgzjGeAZgKFDh7Z+9S5fumQUejowKA2JNjCwqMnXxJqKNWR7sulZ2JNsTzYAhmGwtWYrGyo30K9jP7pqfvb6IcfvRVKoX/czf+t8irOL2bhvI7PWz6Igq4Du+d3pUdCD7tUV5Dbq7Fz/KbM2fMIPe3+gqGYlem0DOZXfMzIvG9eKV9lVt4vcjFxmrpvJvPJ5nN73dI4rPY61FWt5bP5j+HQfBZkFXFF2BeMOH8eW6i1MnjOZqqYqJpZNpFNuJxZtX8TH6z7Gpbk4ouMRnNDzBP619F94dS9//PKP1HvrafA1AHBc6XGc0PMEHp//OBoaWZ4sHp//OABFWUVUNVXFfP2y3Fl0ze9KhisDl+ZiW8026rx1MW2b6c7kkKJD0A0dn+6zCF9+9vq91DTXANA9vzvVTdXUe+vpWdiTgV0GxlzGeJAKQi8HeinfewLbUrDf1CMlCt2duvKk0b6RgnzoNU01TF04lXpvPSf1Ponjex5PbkYu5dXlrK9cz+663QCMO2Ic+Zn5fLn5S5buWEptcy35mfk8OvdRNlWJGclcmouBXQdy+cDLeW/Ne3y64VMAMlwZHNvlaBbtgEL3Dq7++HbKupYxdeFU5pbPtcqS5c6i2d+MYddjL5yGW3NzeMnh1NaV4/L72Feznb/5/bD2J9ZqJTklnNjrRF5b+RrPLX0OgImDJjLm0DF8uPZD/rHkH0xdOBWA4aXD6dexH88seQaf7qNvh75MGjaJTHcmC7Yu4Nklz/LjI37MLcffwtSFU+mS14Wxh41lQ+UGHp33KI/Pf5yJgyby5LgnyXRn8sn6T/hmxzdsq9lG17yu9C7qTbf8bjT4GnBrbnoX9aa6qRqf7qNnYU/WV66n3lvPmMPGkJ+ZH7iNhsG2mm2sqVhDjieHnoU9yXRn4nYJ9e12udlbv5eddTvp36V/UAvDCY2+Rrx+LwVZBRiGgU/3keHOSOhZiQWaEUPokaZpfYB3DcPo7/DbWcANwI+B4cAThmEcF22fQ4cONVp9TtHa9fDOYfCj38CxU+Lf/q1DwJUB56xNfdnSaDPYUbuD6qZq+nXsF7R85tqZTPl6CtcPu57zjjoPbfn9bF36IOu9cPzQe8kom8y6inVMWzSNfY37yPJk0TWvK83+ZgqzCvnl0F+S6c5k5tqZTF81nfLqcpbvWs6uul24NBe6oePSXLg0Fz6b4i/OLqYkp4R1leuClpd1LeOW429B0zTWVqzlvTXvsWT7EjrmdOS2EbcxsOtAPlz7IV9u/IQzvStY5c9ierUg7ZKcEh469SHyM/MpzinmtL6n4dJc7KzbybaabWz/6v+or/yOjqPfZVivERTnFMOC66D8TXzFg1lWsYnMk16hS14XaptrKS0sJduTjdfvZXf9bgzDoLSw1Crr7rrdrK9cT5Yni7KuZWiaRpOvybIoVDT5msjyZDnen7rmOr7d+S3H9zzesmcOJmiattgwDMcJbKMSuqZp/wNGAZ2AncD9QAaAYRjTNHFFn0JEwtQDVxqGEZWp9wuhy0l9j7wZhvw1/u2nlwpCP3djyouWRuth9sbZXPfedYzoOYKfDfwZX23+ipGHjOTwksM59+VzWbx9MQD3nHwPJ/Q6gVdWvMLuut18sPYDsj3ZNPoaObvf2VxZlMlVi9+kUod8Tyad80vZXLUZt8tNp9xONHgbqGysREPDwKBTbieafE3UNNdQnF3Mjzr/iC55XbjzxDs5uvPRzCufx1dbvqLZ38xhxYdxaPGhdMnrQkVDBY/Oe5R9jfu4evDVnNr3VAqzCtles50+HfoEkaFhGKzcvZLSwlI6ZHcInHT1anj3SMjqRO34DWyo3EDPwp6CpMNh1ijYNQd+0gBuYeUw/xrYOgNKhojEXeMWt8AdSiMSIhF6VMvFMIyIzr0haoTrEyxb60KqnqQsl7SHvj+wrWYbxdnF5GTkxLT+3xb+jYXbFnLKIaewcvdKdtfvpm+HvizduZTp30+nZ2FPXvj2BcsaACzCnTJmCt/t+o7ff/F7a3m3/G7cPPxmJo+ezD+W/IP7PruPd711HJah8WRXF/OzB1BZ8CMuLriYXw3/Fd0LRKBXs78Zj8vD4m2LeejLh+iY05EJR0/g1L6nhjS9xxw2hjGHjXE8n5MPOTlk2WElh4Us0zSNY7ocE7oDJcolPzOfAV0HRL+IjpEx6kjRdJRLW8PBNVLUSEHYop720FONfY37KMoqCmk+G4bBG9+/wV/m/oV55fM4pOgQ/jH+HyGkN698Hk8teIreRb0Z0n0IG/Zt4LaPbyPLncXzS58nw5VBSU4JO+t20quwFzcNv4nfn/p7dtbu5Jsd33BCzxN4+MuH+WDtB7z6s1cZ0mMIhmFwUu+TyHJncUn/S4LI99YTbmXC0RP41/sXc5XxHd3dfn7W71Q49pGQc8t0ZwIwrHQY038yvQWuXoxINA5d/S+3jyPKJY3WxcFF6OlO0f0Kv+5nXeU6irKK6JrfFYBXvnuFy6Zfxom9TmTsYWN5Yv4TuDQXXfO7UtFQweaqzRzZ8Uh+N+p3vLj8Rcb+dyyDuw+mX8d+7KnfA8CnGz6lILOAOm+d5T2P7zeeVye8yuq9qzm0+FDyM/Opa64jNyPXqjjyS/ItlfvUj58KKqumaVw1+Kqw59KrqBf3Hj4ENq8Bf3Pbz+WSULZFh23SI0XbNA4yQk/ScjF8B/dI0R2fwPp/w4j/RFzN6/dS2VjJhsoNbKvZxui+o5nxwwyuf/96appryHJncfPxN1PvrWfqwqmUdS1j2c5lzNk0hzGHjqFXYS921e/i8JLDmTxqMpcNvAy3y81tI27j+aXP89w3z7Fo2yI65XbC6/cyaegk/nDaH8h0Z/Ltzm/ZWr2VcUeMI9uTzcCugfCwvMy81F4Pwyvygrv0AzMO3aoElG3SI0XbNA4uQk/WctG9oLVcyFFbhl/38+aSp1m7/k2uKfsLHfM6U9FQwY0f3Mi2mm30KOhB17yufLPjGz7f9Dm68rJnubNo8jcx8pCRXDnoSj5a9xF/+upPZLmzuOjoi3junOdo8DWwo3YH/buEBFJZyMnIYdKwSUwaNinsOseVHieGtbUGdJ/oJDf87YjQ48yHbt8mPVK0TePgIvRkFLphOOe2OEDx1qq3mPTeJEb3Hc3xpcfz+PzHrZC5R57qx7jDx7Fg6wK2VG9haI+hzCufZ0Vd3DbiNnoW9qRXYS86ZHfg1RWv0i2/G3eedCcZ7gwmDprII2MeoXNuZys0LS8zj065nfbnKccP3VTomqftPxdWBRvvSFGcLRdNSyv0NoiDjNCTUOhGknZNK0LGMzuhvLqc/Mx8OmR34J0f3uGT9Z+Q6c7kkv6XsHHfRu785E68fi+bqjZxZMcjmf79dF5a/hLDegzjkcOO4fBd7/Bg7ijmlc/D7XLz2c8/Y0SvERHLc0qfU0KW9SzsmZJzTQr+ZmiugJxuiW1vSIXua/seeqoUuoxyIW25tEUcXISeDClb6r5tK7GHv3iYJxY8wVe/+IrcjFwmz5nM9FXTyfZkc0jRIXy+6XNKckq4bOBlPD7/cfIycvH66vnz3D8DMKjbIPp36c8VHa7g7pPvprKxkm012zi227FoS26FKnjt/OcgM0L8cnvBmqnw3e/hor2JbR+k0NsLoSei0O0euisdtthGcXARelIKXUbI+IX9sp9HqDX7m6lrrgsaGDJz7Uzu/vRuDAyumH4F1U3VrN67mvFHjsev+/lh7w/cdfJdzFg9g8fnPy4iQUbdQvOsU/lnp5/jKj6WScMmBYXodcvvRrd8U8FauXC8HBCo3SgUuiSpeGF4hULX20GUixMpR0WUKJe0Qm9zOLgIPRUKHQI9/S0MwzB4feXreHUvPx3wU/y6n1V7VrFw20J+N+d3bK7azPh+4/G4PCzbuYx1FesY0HUA1w65lknvTyLDlcH7P3uf0w89PWi/d518FzPXzuSsfmeRuXc+2W645ajToO/lUQpkvtgHCqF794n/FknFCdkp6moPHrpDLHms24Rsm45yaas4uAg9mTj0kNzXqSf02uZaXlj2AhcdfRFVTVVc9c5VzNk0B4CFWxfyyYZPWL5rOQADuw7kV8N/xUvLX6Igq4CyrmVcMfAKrhp8Fd3yu1HZWMmgboNCyBwgNyOX8390vnku5svqq49ewGTDPtsavGZWPknM8aI9Wi7W5xhefcdOUTPKJW25tEkcnISeTKeo9dk5cVDU3Ziq+60f3uL+U+6nuqma/y3/H9cNu45bZt7Cu6vf5e5P76bZ30yGO4NpZ03jyy1f8tj8x+hR0INnzn6Gsm5lDOk+BLfLzaNnPOp4nLtOviu+8/LFkDL0QLNcmhWFnghkp2i7IHTd+XPEbRx89zjzoafRuji4CD0py0VV6PERwK66XbzzwzvM2TSH1XtXs2DrAjQ0pn8/nSZ/E7qh89j8x9ANnXtOvodF2xfh0lz8/ey/07OwJ1cNvooLjrqAUX1GRU6mlAjk1Gn+GBT6gWa5JEvolkJ3twMP3a7QY9kmQi6X9EjRNomDi9CTUegOkxnUNNVw68xbObrz0Uw4ZkJQKN7W6q386as/8eqKV9lZtxOAHgU96NOhD4+OfZQLj76QX3/0a7rldeOXQ3/JQ188JEZGjp4ccmi3yx2wSFINy3KJQaHrB5hCtzz0JEYOu7Pbn4ceKxGHs1wshZ62XNoaDi5CN5IIPVRe+vrmGnKzSnj4y4d59ptnAfjNx7/hx0f8mGsGX8Pu+t3c+MGNNPubufBHFzK0x1BO7XuqCP1TomNem/Ca9fmlC19K7JyShWW5xKLQ5fU7QAg9ZQq9vVkusSp0p05R2YHsIq3Q2x4OLkJPQafo/2rg8r8exk8H/JRXV7zKZQMv496R9/Lvpf/muaXP8e7qdwE4te+pPDv+WfoW901V6VsGxkFquRg6eKvNz0kQuoxyaVeWS6xEHCmXSzpssS3i4CL0OD10r9/LrTNvxaf7+PXRZ7K8FibuhN6Fpbzw7QvkeHJ4+LSH6VnYkz+c9gceGPUA765+l9rmWn464Kchs7C0SRysnaLeGqwojWTSKbukh97Gr0kqPXSZyyVN6G0OBxeh2zx0OVuTtEEMw6DR10hORg7VTdVc+salvL/mfTwuD9MWTwOgXwbM/dnbrKivwat7g3zzDHdGy3ndLYV4OkX1A0ihS/8ckrRcZJRLY2rK1WJIJsrFVhm4POmwxTaKg4zQAwr9i01fcPHrF5Obkcs5/c7hqE5H8cK3L/D1lq85te+pfLvzW/bU7+HvZ/+dsYeN5fUFUzhq49OMyoX87HxO7jxo/55LqhBPp+iBpNCbU0DoathiW7dc9BQpdGtQ0gFkueyYBev+CSf+b3+XJGkcFIS+vnI9W6q2sGnTIr7ZDZt3beXdZafTp0MfDi0+lKcXPU2zv5lu+d244bgbeH/N+/Tv0p9HxjzC0B5i6r7flE2APU+LHbb1iIZ4cLB2igYRehLplF0eM8qljRN6Ih66Yxz6AThSdOcc2PQyjHix3U8xeUAT+vKdy7n707uZsXqGtSxHgz6ZzVx09MU8Oe5JSnJK8Ok+Nu7bSGlBKTkZOTwx7onQnakvbFtXY/HgYO0UlaNEITmFrmUIgmvrhE4iUS4HyUhRNfotTehtCx+s+YCvtnxFvbeeJxc8SUFmAZNHTWZErxH0KH+Rfluex53bGc5/0drG4/JweMnhkXecxMCiNo1E4tDbPHnFgFRYLlKht4t86AnEoR8sybl0JfEe7XsCm3ZP6IZhoGkaPt3H7R/fzl/n/dX67dL+l/LkuCfpmNtRLKicYQ5wSzY51wFAaBKJWC4HhEJXCD3hGaxMhd7ewhb1WBV6hHzo2gEUh57M+JQ2hnZJ6Lqh88DsB/jfd/9jZ+1Onhj3BPPL5zNt8TRuGHYDU8ZOodnfTGFWoW3DZGYsamGFvuTXkNUJjvlt6vcdCXo8naIHkOWSkk5RVaG3dUJXyTfekaJh8qEfKCNF28lcB7Gg3RG6X/dz9YyreX7p85xx2Bl0zevKlW9fCcDtI27nT2P+BEC2Jzt042TmFNVb2EPfMQsyClqf0OPx0A+kof8ps1wyDq5cLqrlklbobQ7tjtCf++Y5nl/6PA+c8gD3nXIfXt3LLR/egsfl4eHTH468cTIKvaU9dN0LDdtTv99osGwUc5IGV4RH4kCKcgnqFE1iYJHWTvOhx7PNgZ4P3Rqf0gL3sGYdVK2Anuekft8OaHeE/otjf0GXvC6ce9S5AGS6M5l61tTYNk5m6H9I+twUQ/dCww5afTYk9WX114OrMPq6B4JCT3ZgkaGLv/ZoucRyvoaBFcUSbqTogRjlkmqseVrEuE/YF33dFKDdxei4XW6LzOOGpUZTMcFFimF4BaH6alK/74jHVR7iaB2jB1KnaLKWi3yGXO0kbDFehR7Oc9cPwHzoLemh+xtF67eV0O4UelKwiMhQRrzFCNVmaImmmSxbww7IiKCSU35chYiidYweaB56RpGwXpKZY1ZmW2wrHrqug8vssDQM8bm6Gj5fCXmAF/jkS7iwTPwmsXMnTJsGubnQqxf07AF7gX3AotfghiFw6KGmh+4GvwGL/bDRtDmvvRaKHXL1v/surFoFhx8OM2dC587wm9/AU0/B/PlwyCFwxhkwZgxkZoptdu2Cu+6C7GwoLIS33xbn0qED7NgBp58O990H06fD3r1w2GEwbhwsXAj/+Q+ccAIcdRSsXw/z5kFlpTjO2LEwdChs3gwLFsBXX8GiRZBXBYcAng+gSofaWrjuOvHbX/4CJSXQuzd07w6eMJRpGGK/33wjytyvHwwZAp8thZVNMP9WOPJIGDhQ7KNbN3GdU4yYCF3TtDOBxxHzrj1rGMYfbb8XAf8Fepv7/LNhGM+nuKzJI4iUfeDOjH3blg5blPts2A6F/VK//7DHtVkusax7IBC6dx9kdRSEHqReDVi9GnbvhhNPDLa/6usFuXz5JRTmQk8izyna1ATbt4sXXNME4VRXB34vLoacHFiyBPr0gR//GCoqxDE+/hiam2HYMEGAmzaJ4w8YAM8+Cx98IPbZpYsgyaYmsey776BrV6irE7/fcgu8/DL88AOcAmwHVt8Et5fDn/4EPh/8739w662wZ0+Yi/UavD4PbrsN7t0EObvEeW8DMGfG+vOf4bzzxDnt3Ak/+pGoHG65JbCb3FxxDlOmQGOjIL1PP4UnnwS3G0pLYfBgWLxYkLrHAw0NMGoUFBVBVZUgxH/+E/7xj+AiulyiMisqEucr0amTIE95HBWlpXDccfD9bHgPeOeqwG/PPw9r1kBBgSjbjh1hro2tDEcdJa79Sy8FooCygDl/F+cucccd8Mc/Ou4mGUQldE3T3MBUYAxQDizUNO0dwzBWKqtdD6w0DGO8pmmdgR80TXvRMIzWa2vEghBSjofQW6FTFKAxhgcnlVArp1gtl5boFJ07F2bPhl//GrZsEeptzBhBVtXVcPPN4oU+/nhBfs3N4vuAAfDee/DiizB+PIwcKUjU74e8PLH9t98KsurVS6i7ggJ4bhsUd4TuQJd18Ld7heLbtEkoNBAEe/rpsHy5ON6HHwpFmJ8vXk4dyLgNuuTDgAb43/mwYgVs3Qper/iLBx07iv2DKGtenijT00+LfRqGUIqbNwu1nJ0Nn38uzk3ThDK9/XZRGeXnw7p18LvfiWtw4TB4Y6F440cdB488IiqYNWugvFyoyTlzBMlt2QIb18D0C8QrMvK3MOlvcNNN0C8TSjtBkwcu3gcP1gglfPfdokKpqBDH++9/A9fw73+HDRvEMb76Ch5+GK6/Hi68UFzXjz8W93/jRnHf8/PhrbcEedfXiwrR/qy8/TZMmCDu/4oV8OaboiK75hpxrJ07hSrv3Vtcm+ZmmDUL1q4V13bw4MBvc86B9TOg5ytwyCCxvyuuEMd/7z1RKTQ3i0pGj2AzFReLZwvEs7lsGex5FBrehkuqYOMmUbEahmhVtABiUejHAWsNw1gPoGnay8C5gEroBlCgibSF+UAF0EbaoAqS8cFbo1MUWj/SJchDT8JyMQzxspSUCGKyw+sVL9Qxx4gXScW2bXDOOYKYXn1VKOT6eqGMTj9dvJzffQc9e4oX1wmjRgnl9re/hf7mconmekWFaMqDaGv6t4rPD98gXuzTT4fTThMkUVUF99wD778vFF52Npx0klCcJ50EqxbAAyOg5HRYsQY+roJDvhWkdfbZYv2cHOjRQ1RITU1CDXbpErhee/eK38rK4OuvBXkcc4ywBgYPFmV680149FG48kpxDm++KdTdddfF1nk+f7643hXPQ8+FUAxc8wjc/6KwHYYOhalTRZmlBVNUBEf2AdmYGN5PVBwLFkDRfdDrdMjtDcvvh9wcQXwzZgQfd/ly+OQTYcVkZ4t7B6KSHjMmsF5mJpx1lvhzgp3MQVRcJ5wQ+H7sseJP4sgjxZ+KzExRuThB9wkVPXyQaB336ycqzfx8yMgIbC/PIRYUFQlx8eVU2AzgFyTeQkQuEQuhlwJblO/lwHDbOk8B7yAaYQXATwwjtMdE07RrgGsAettf6tZAMvlY2ptCX7JEKLXu3cWLunevUGPz5onmbpcugigbvoOOQDaw70PI3SyavJs2CZW7Y4cgQoD6XaLqzngaMl8WL9v48UI9vvuuIGS3WxBXdbVoeubkwI03CmJ8V0z+wY9+JNRTr15C/XzyiSDwRx6BBx6Ak0+GO++Ejz4Szec9e4RiO+ss4Ydu3ixesPz8gF1RVibOd+dOoTIzMkQZduyAI44QyqmiQuxn9w4ovBt6nw9fT4cuN8GZk0JJ4PLLRUVUWhp6ffv0hPOB4y6C+s3w7YNw2brE79chh8Cll4Yuv+AC8Sdx663x7Xe4+aru8QtpBuDW4JlnIm9njz0fMED8Tb+XQC4XEM0Uh7z/cv32AKcoF6f+gERghUR6wZ3YxPLxIBZCd5IB9nilM4ClwKnAYcDHmqZ9YRhGddBGhvEM8AzA0KFDWz/mKVUKvSU6wIwkFXpdHbzxhiC55csFMTqhpEQQ8a5dgtQrtgeUGFPEv7w80Ynldotm7DHHCDW46WXRY19YCh2HCWJ96CFBluecIxTJunXwxRdi+6IiobYnTRLbP/KIIMiFC0WzfvFiQdBZWaJZftllgvyzssT6o0bBH/4gKhbZGVVcHPyyqR1LnTuLP4n8fKGQ1XP/xS+guQpevxs6FsMxCMXd20bmEFDTTpD3S6bPdRF/R3trIu449DBhjnJgkTzPA2G0aEuGLSYzMX0CiIXQywG1O7YnZneIgiuBPxpixoi1mqZtAI4CFqSklKlCyhR6gjfH7xceWmmpIDsQTfGVK6BJF3mB9pTDPjOkrr5e9LR/9ZXoPS8qEmS3ezdcdJFoZj70kCDnVasC/isIcrz6avGbYQgS7NNHNPnUpkhRSS8AACAASURBVPqCm+DrJ4VBNvAP0HcC9O3r3Jv/6nTwNcMRo2GYGftfWSlUeLbDyFwQx54xQ6yjNrXDwb4fTQsfWZAo5L1055jfkxg5LDtF5bJ4OtpbFfHGoYcjdHNgkaXzDoDQxZYMW0xmYvoEEMubshA4QtO0vsBW4BLgp7Z1NgOnAV9omtYVOBJYn8qCpgQp89DD3HhdF9bCihUiOuGoo4T/6nKJjq3f/lbYAAUFohldXS1636uqRKvVAzR9ijA6FWRkiObr5s2iAsjKEp0/ICyLsjJBltddJ6yI2lrhBcfisWo6SCHap0jYE2GvgUOUS7SmqaYJ9d6WINW126w8EopDV8MWTcsh3o721kTccehh1ldzucS6r7aOoGyLLbXvNkLohmH4NE27AZiJoJ3nDMNYoWnatebv04AHgX9pmrYcUXXfYRhGuBio/YdkOjYtjxv44luoWCSIU8ad7tgBL7wgFLiKoiLhKX/8sSDdSy4RnvGMGaJJf955MOokePNqoZI75cHg34ttPR4YNEh0tOXkKGU3hL2yfj388pcBtZ8IDB948kSHaLRO0QNl6L8c6JEMoRuKQtc8wcvaIuLN5RJWofsJjBSFNjdatHEPZHcKfJfnEckKa1HLRfHQWwExtWUNw3gfeN+2bJryeRswNrVFawGoF9WpCbRhgyDbzp1FKNfy5cImAdj+FWwE1gJNfwX+Grr9SSfBvfeKKIUlSwThzp8vwt2uvVbEwXo8wsdV0bwPMq82B7pUwyXXC6IIB00TlksqYPjBU2ASuhm2uPFl2LcMBtly4xwoI0XtlksyuX3kwCJoGUJIFewqO671nXK5aLHvq7VQuQw+OBZ+vBw6HCOWLb4ZatbA6A/Cb9eShN7WFHq7hGGIjreXXxaEfMcdwnf+eA/UA1XA1w+Bp4OIUd6wQYTaffNNcJxpSUnA0/VXi4DMk4BLJkHnscLeGDpUdEhmZYmIEokzzhD/r7suennlTc/tBVXfQeMuyHWIrGgJGH5RebhzwG8q9C2vw975wYRuGIGX94Aj9CQVuuqht1XErdDDrS87ftug5dKwDTCgbkOA0Pcth8YogQYHmYfetrFkiRjptmSJ6ADs1EmE3G3YEBhKPHVqQGlL5L4iXsR+/URM665dIiTsF78QBN2pkwglk0pk/jWw4T+gN8GQI+FIJZ+MGlmRCOyE3rC99Qhd9wnF5ckNKPSmvaEPYNAECQcIoXuSIHSrU9TuobdRxD1jURhFb49yaUuWi7TSmisDy5r2gD/K+MZWUehtyHJpkzAMMfDjoYdEp+GQISKCY/du0Rl5333Cn66oEITerx/4HwCtEbL2wXlfQcngOI7nFZ6r3pT62lbe7ILDxNDsuk3QcWhqjxH22H5hGbjzAh56057QBzAoQqgdEHrtRnE+UqmpsEIOzdZXQrlczG1Uy6VNK/R4o1zCKHQrNLMNWi4WoSuJ15p2B+5P2O0k6bbAuSSTEDABtF9C/81vxAi6q64SOSlKSpzX69BBJNgBmP47IA8a9iUQtugThO6tSr0Sk2UpMGOha1sxQMjwg8sNrtxALpfmKAq9PXSKLr0TatfBmQtDf7MslxRFubjag4eeRLbFcPnQY91Xa8FvU+iGIcRJZhhukDiAPPQ2OgoiCubPF2R+7bVixFs4MrdD9ybeEaZ7kyOAaPsGkSwqq2MrE7q0XPKE5WIYwnKxXx+9nSl0X234qJ2Ueuie9hvlovtgwwvOpBxW0Zv50INGirYR2C0XmXhNb4qy3YHjobc/Qtd1kSSoe3cx8jCeySCkyobE4tDdSTTRI+5bGXWYd2jrK3TNA+7cQOiinL0oaL0WzmVTsRhWP526/Rm+COMF7GGLSQ4skh56u7FczM+7ZsPcK2Cvw/g/pwpAdowHWS5t0EOXk5c07QleHg6tEbbYSq3a9kfoL70kkgT98Y+BzGaxwvAmTsq6N+C5tpRCd2VAfisTutop6q8Xdgs4eOgt3Cm6/t+w9I7U7U/3hifqVCr0IMulLRO6A0FLJetvdFjfqVPUJG/VcmnLCr1xd/DysNu1wsCitEIPg7PPFrmXL7ss/m2TUejWhMCuFvDQpR9rEnrdxtZTe1KhZxSJF0GqGjnFmlXGFrZcDF/0Fy/u/cVI6IlMWOLUKdrePHRvTehvFhwsF3WQTlv00O2douqzHOkepz30/YgOHUTObFcCRTe8iefvMHyBl7fFFLpHRLoYPqgvT+0xwkHOQJPbC+q3iJF26m/W5xYmdN0k9FQ14XVv+PtkDf03s98lZbm0Fw9dSRwmr4vPzPvu9C44Wi7mf62NjhSVz6VU6E3KsxxJLLSKh562XFILqTiTVugtMH+kOkgl/1DxubVsF8Mnolzyeoumd42SuiBoQpAWjnKxwrtSpNJ1X3TLxbqfySr09uCh+0ULELDUdySF7tQpahF6C4wUNQxY9biYgjFR2C2XWAm9VTz0tEJ3RsU3sOhX8d94+bIlGuVi+AJqLNVzitotF2hFQjctl1wzP33lN8pvYVIltJRCh+gRCbHCiKDQ1eudKKGrrar2ErYo00lYCl0SejSFbhshrGWQ8pGijbtgyc2w8cXE9xFiuexWfovwXFlioiUUeuvGobc/Qq9dC6ufCK59Y4E9w14inaJaCyl0VTHm9BQE26qEbip0EBWmVS6HyBZXRst56BB9VF+s0CN56OYxkmlxOXrobVihoyuEnqBCD2rZpNhykYSbzIxd8r76asS9j0Whq31Fqa6QDUNR/2lCd4ZsNsZLKilR6HJCYNu2jbug+gfn7WLat/KiuNyQ16f1CF1GuUiFXrVCKZeD5eLOaVlCb02F7spMvMUVLh96W4WjQq8N/h60vpPlojynqR4pKgk3FkKv3wZL7wo9tkra3qrYCD2crZgK7IfR1e2P0F2JEnoKFLorTKfot/fD5+fFtz+nsslzyy2Fhq2J7y8eSMslq6Mg63APoVzuzm4ZDz3Vlku8HvqWt+CtQ2JvITh56G1ZoRt+UYFBqEKPtVPUSaGnjNBleuoYCH3be7DyYZEiI2gfyr1TI7Yg/H2NZZ6DRJGKSXHiRPsl9HhJxUiBQpeWi/0F8O4LTggUL9Rh5GDmjElhCF8kSMtF0yDvENtvKrlLRZrdTiyXGKJcZIvI8InO4PrNsd9HxyiXtuyh64HWbYiHHi1s0cFDT3UcejyTpFuRI7ZnxU7ojbsDlVhYy6WVCD3toYdB0go9iaH/sgPMfuN1L/iTUJaqPw3ihWmt4fUyygUCtouEU3PU00KWS8o7RWNV6Ob9lBWJP8okH+r+IXhgUbuxXGLx0KMo9FSPFI3HcpHlsL9zqhho3icUek6P4P2H7Ku1FHracnFGoh66ahlA/DdP94XvFNWbwxNRLA+83XJxZ7ayQjcJSXaMWi++Q6eo3ZZJWTmkQk+V5eI1O7wcrr9TlIt84aLN2iTR3jpFDT2Ch+5kuUTx0FtKoXurwNcQeV0jBoXetFu0nGUa6rCErpJuqj301lfo7S/bYqoUetwDiyJ46LrX+YFZ9VdY8zcYvzq2ssnKypXZigrdH/CApULP6iI8fKcmY0tbLqmqyNTYYnv61BAP3RdYFiuhq2GL7cZDz8DrLqbcN4jG77+Hbn+Frn6oK4Hvvw9e318M/cxZfjx54nddF8uqOgOG+FzuhW3fhxwubvizA8f7YW2g1eME70li3e0e2KUcO28SHPkLURlVFYl13LlQXA87c2CPQzl1X+C4jcWh1yEZJLnv7OxsevbsSUZGhNnLbGi/hB5vEyYkZWq8losvQAD2ykBvFi+M7g/YF95qWD5ZqAR1lF6ksgVZLq2k0HVfqELP6SYI3clf9OSYitaILzFaNFjN+hR2ilr7tRN6s6mstUCUixXyFiuh+wDNHAbfTiwXLYPy0gco6NSHPt0PR6tsFMvzekN2l+D1m6ugxlTfWSVifIS3Fqq9UHC42K4WKDpC5AFKFt5qqDafgcK+kJEfft36bdDggcJDIaMwsLzGI1p4/kZR5qYMyO4KjTuh4FDIdJh7198E+8xnLrcX5HRN/lwc991TvFcxwjAM9u7dS3l5OX379o15u/ZnuSSq0O2dookodOmXhlgusgmokNHqqYGsb9GackYEy2XpXfDVT+MrazxQFbok9GzzoXaKQ7euX5zXv24LvFoA+75z/l1PseUSaYSe4VUqT9NyiVehyzBWCKQQSFVl1BIwLZfGrMPp2CEXTdOI2S6xbCuZnEtLbWUedAxieLaM0G3kd9nB31wlllmVTTjr0wjzORVIfN+aptGxY0caGx0Sp0VA+yP0hOPQU6XQw1guEHihdT+sejR421jK5tQpum8Z7Ps2vrLGA7VTtKi/IPOSYYHfrDLa+yDivP71W4RnW7sufDkg9Qrd6drrCqG77JZLfWz7N5SWjazk/FG83/0J2SmqudDQgvsXHPt5Ii1LMZnbjxf12bJVMOpyTQtU0p5cJQgiDKG2ZPrfJPetJVBptj9C318KXfcGYo6dLBcIqEtfjdnDXhp87GhlkwThUhS63tyy3qzqMWd3hgt2QJeTzGM7dBglqtCjeeR6lN/jOpY6Qs+hdaQSuqyg9TijXHRfwOeVlZxTGtq2gqC+BMN2XaIRj534NQKkHj9p5ec72ClBmT2jPFtWRRTcwnhrxsesXLU+cJ5ZHWPqvH3ngzn88fF/0aIKvZXyxrdfQk/YQ08ww55spjspdMOm0KXKk55dtAfUMcpF6clvSW9WtVwknKI2krVc5DWLNsAjFZZLuCyREjKNAyRnubQrha4H3+eoA4IiKPRU2y3248VqudjK+NZ7s1j5w7qA7ZJZgqx4fL5w+zQ4Z9wp3PmriSH7SxpGS9o5zmi/hJ6oQtQkKSdguWieQBM96DebQpdzc3oKg49th9+ccFr3BueYVjtF/S2t0H3hCd3RQzfVaN1GWDMt9uNEU+CptFyihaLZPXTdR9xhi3JcApiDV7To4XaphpwyMBYY/uD8K9EUepAatxOoQuhJ8JRhGNx2223079+fAUNO5pXpH4HmYfu2rYwcOZJBgwbRv39/vvjiC/x+PxMnThTrHjeWv/7tpaBz//rrr3nng8+47d5HGHTyRazb1sCoU8dw1933ccr4a3j8yb8zY8YMhg8fzrHHHsvpp5/Ozp07AYN//W8GN9zxCBgwceJEbrrpJkaMGMGhhx7K66+/nvgJtqg/74z2F+WSrIcuBwfFo3p1P2DE7qFLhS574MMd69PToNMJiDkaldAkV6YgOMMwFXoLhjDqDmF9TjPwyHwnktDX/RPW/h0OudQ5esCOVrVcHLz/oGNFsFwSUeiaZo7ubUXLxVsN03vCCf+BXjGknbBaYoEcLDff3Yuly3NFi9Au7fQC8B9puitucAN6vljmyQIywXckeLKD+H3QIHjssdhO4c0332Tp0qUsW7aMPeWrGHbiaYw8+UReeu09zjjjDO6++278fj/19fUsXbqUrVu38t1330HtRvbt2oBqo4wYMYJzxo3i7HFjuOjyG6zl+6qqmDPjGcjrTWVDBvPmzUPTNJ599lkeeeQR/vLH36kXCYDt27fz5ZdfsmrVKs455xwuuuii2E4oBK1vubQ/Qk84Dj0JhR40IbA7VEWGKHRTqWVEUeg1ayC7m4j/dimE7pbDlb2t5KHbFLrTNbZbLo1m+uJYFXWsCj0Vlks0ha43B4aEJ2q5qOGeIK5Layr0hu2ir6Z+S4wbqJaLXaHHC1W1J44vv/ySSy+9FLfbTdeunTllxGAWLl3FsGOP4he/egiv18t5553HoEGDOPTQQ1m/fj033ngjZ506hLEnHe1MkjY76CcXXyw+GDrl5eX85Cc/Yfv27TQ3N5vhgKH7OO+883C5XBx99NGmik8UaYUeHQnnclEHgsSr0NWRhR7Q651/t4jdptANn8ieuPk1+NHtgYfOW202m73BhG61QswRqC3qoStRLtbxnTx0m0Jv2BkoY6zHibR+Kof+O3n/QcdyinIxJWoiYYsgCL01PXSZcybWyl61XAzA0HnsD2ZlkNM9MKJSoqkaajeI98WdC4X9oKkKajdChwHmZChroPCoyDHjkYpkOChYzc3IE8r4fM4c3nv/fS6//HJuu+02rrjiCpYtW8bMmTOZ+szTvPp6Hs89+4zDXoMJPc/qgDW48cYbufXWWznnnHOYPXs2DzzwAE6km5WV5VzG+E8wZN8tjZg8dE3TztQ07QdN09ZqmnZnmHVGaZq2VNO0FZqmzUltMRVY6jGBKBW5vVMseSTYFXq0OHTLcikI/L75DVh6Z+BF1H3ipfA3hKo9NaFQa0a5SET00E2F3rRL/I9VUUcbOJTKkaJRFbraKZqg5aJGuYCo6FozykVO4hBrSzWoJWYAsUa5KGpc9dW1xKNcJEaOHMkrr7yC3+9n9+7dfD73G44bOoRNm7fRpUsnrr76av7v//6PJUuWsGfPHnRd58ILL+TBe25myberQjp2C/JzqKm1379AzpmqqipKS0XF9e9//9uh+C0Zh946iKrQNU1zA1OBMUA5sFDTtHcMw1iprNMBeBo40zCMzZqmdXHeWwpgkU0rWi6qQnccWBTFcgnqdKsRo9hkpjt/Q6hCVy2P/RHlouZy2fYh7JgFBUeIZZblEqdCtwYOtUaUSzweutusNE1y8CcQhw77QaHLQWuxKnQ9EP0BMVguETpFUxTlcv755zN37lzKysrQ8PPI/TfSrUcP/v3B20y57E4yMjLJz8/nP//5D1u3buXKK69E13XQm3j4nuuxE+Yl55/B1bc8xBN/fynQmalUPA888AATJkygtLSU448/ng0bNgTvI+V83jY99OOAtYZhrAfQNO1l4FxgpbLOT4E3DcPYDGAYxq5UF9SCNXAgCcsl3k7RIIUeT6doUWB7K/mQmRDJWy3++xuCCQYcFHqKOkW9NYFWA4iHzEmhu5RKc+u7sP55OHaKWCYtF6lk26LlkkiUi0QinaLQ+oTulS29MM/G3oVicNsJ/zVtJXuUi1mBaZoz2Vh8rka0pGZgUW1trblrjSlTpjBlyhRzOP820DL4+SVn8/Nf3iHSTChYsmSJ+FC9RiTxsjHwicPLWLn4U8jrBcDs2bPFDxVLAJ1zzz2Xc889N7gwzfuYeOl4Jl46HjD417/+5VjWxNA2LZdSQO15KTeXqegHFGuaNlvTtMWapl3htCNN067RNG2RpmmLdu/e7bRKbEhkGjR1hplEFXqkXC4QGrYoyTNoJKKpzGXqUl99sAUAykQEXqFoY6189i6Cpgrn33Z9Aa8VwjuHCS8flJc6goeuNwcqHQgodIlwBF3xDVStCnyPRugptVzi8NATtly8sVsu/iaoT/GEJZblEubZ2PExbHoZfKZwsLfEDL9J1i6cyUYhb/vQ/yQHFjnDEPu0Ep1FakE4DyxCjhQNQZhKS91Xi6BtErrTFbKXzgMMAc4CzgDu1TStX8hGhvGMYRhDDcMY2rlz57gLGyhRAoQuVa5Md5qIQrcsF+VhkyGNEFCXUql5VMvF3IfXRuiOCt387DcVuqqoIuGT0fDDE86/yWgIXy18c0dAnUP4TlHdZ56TETgnO6GHs0gWXgvLfhv4Hi3KJZW5XKKlLdW9oVEuccehx6HQ1zwN7/WP7R7GCqtTNMx7IFuA8j2xBhaZ5GboiFjEKBErQQTZwgOLtFgJXV5Hm6VhGDhSmhbhHFuy49Lq6HW1muUSC6GXA72U7z2BbQ7rfGgYRp1hGHuAz4Gy1BTRAckq9Hg7Re2pUoM8WoWg/GHi0IMUutmEi+ih2ywXtfxhy+gX+5YJwcKdQ9+JULcBqlcpFZXdclE8dHXiXQhYLtZ+wxC0tyqYHGNW6KmwXByic4J+bw60iEJyucQT5aJcN08EQm/YLu5LrPuOBdEUujW9nCR01XJRvoflZgcP3clySZlA14lZoTvmoIlU2UQi1Jb0uRVCb0MKfSFwhKZpfTVNywQuAd6xrfM2cLKmaR5N03KB4UAKEwvb4MqI31fWbQo9LkK32zXq0HJVDSqWi+YOeIC6N7APS6GrHrovjEKvJ/AyRcsH4w3sz/EczN97moNQtr4bOI+QTlHFQ5cELL3/WC0XX0Pwb1aUSyt3isZrucQzY1GQTRbJcjHvibz3qYA3SqeoNRuRktPGHoeuKvawCKfQW8ByiVmhy2Oqk3BE8PcjZpZsDculDRG6YRg+4AZgJoKkXzUMY4Wmaddqmnatuc73wIfAt8AC4FnDMMLkSU1FqROxXGwKPS7LRa0MbB66Wg5LoTeI2F3VizZsCj3Icml2Dlv0KR0y0QjdUtJhCF0eP78vdCiDbe8qCj2Ch26dkyT0GBW6vz6YnCNZLpYFEGF/8SDeTtFEBxbFqtAl0ctKPBH4GgKVKijhr2HeA18Ey8X67iK85aKSt+Kht4jdgknIWsD+i8lDj1WhR6i0WjJscT9YLjENLDIM433gfduyabbvU4ApqStaBETy0HfMEg977wnBy1Ol0O12jUpAqkL35AbHzNs7RX2KWvPVOlsuKrlEq8CsOTGjKHRXBpSeDSv/CI3mrOiR4tCjWi5hFLXfrtAjEbraJ9HaCt1tuz91WJN36GbHodPkJPFEuVgKPQlCX3Iz1KyF0z4R36OFLVqWi6LQseVy0dyghXmuLP7RFD43SbdFICsLs5KJ9H6qnbS+Oqj+QQxwkuW1I5KH7lhxpQot2efgjPaXnAsiK/Tvfg/Lfxe63D4xcEIjRR3CFoOmaZPkVy9e8CCFHsZyAeE3O1kuqiKL6qHHQeidTxbnsG+ZuSxCHLpludSYBGCbDssprtwwwhO6k6WivrypHvqvO3noESwX9fOnp4nBYOGOEdSqisFy8SVhudRvg/rywPdoCt2yXFQPXb3PMSr0kDh0k5ySGFjkmD7XinLRAmGWYaFEufgbrf9vvT+bld87TfcYPcpl6fI1vD/zs9hPIia0QculTSKSh16zOjJpaO4ERopGCFt06hS1FLqqdMNYLiDI3SlsMRHLRZLH93+BHZ+E/q5lBIZqy/2HWC7md9VD99Wa185G6E6KW07QHNR6iaDQw13PRBFL2KJTp6hU4jLstGat+HNCPJ2ivhQodMMbXGF4o3SKWpaLVOjKwCIrIsT0wiPZAa1tuUDABgu/cuC/tOoMnyD0VWtCV9dchPXQzXNf+t1q3p85O/5yR4JquaQJPQLCKXRvrYgocGq2WxNUaIlbLlEVuhK2aPfQrYFFDpaLtzq65RKV0G0hk99NhrlXKAOAZKWUCa6s4P2HWC5y8JbioXtrxHqxELosg3ofInWKBllYKQ5bDOuhO4QtyoFg8rr468OPHHUKW1S9+KB1U+Ch677AdTUMxXJRjrf5dfhohPg9WpQLhi3qxRDTtjnGnCvrpNByCUqfe/yPeWX6hwBs31nByDN+Ej597ogLA+lzTUL/eu5c3vnwC2777QMMGjSIdevWsW7dOs4880yGjLyQk8/8GatWiXERr732Gv3796esrIyRY86ludnLfQ//jVfefI9BgwbxyiuvpOoMzf+2SrNuc+D+pRjtLzkXhPfQa8za2YkUVEXl8sQ+1RgESMiVQUg+9HBhix6F0HVvYBufbaQoiJfPyXLxJWK5NAbK4K0WSn3Afeb1Mpuz9tGedoUuyxDkodeao2zthO5wrSUJxuqh66m2XKIodH+zs+WS3V1YGfK6+OrDPyd2ha7OWmS/Rr4URLmoCt1Xq1SQyvlVLIE9c4VYkM9X2CgXHb57EPYtF8TuyhLn7c4xgwaaxb1wecS6njzT3vCLz4YevL5E8SAYElv+3KD0uRsWMGz0BYw882e89Pr7nHHqidz94GPO6XMrl7KvshKhugWhjzhuMOeceTJnn3sRF10yEYDTTjuNadOmcURXg/kLlzBp0iQ+/fRTJk+ezMyZMyktLWXf9lVkZtYy+a7rWbT0B5565oW4b014yMgdhdB1HzTuMp+RDik8lkD7JPRwCl0SuhMphCRkikOhe80JZzOKYlTo9ZBZTFBecbtCD3q5jdRFufgbApNiaG74/hE46haCIjtCCN3hMZDXyG65yGuYUShII6JCj9FyCVdBJoqYFLpDLpfMDlCHuC66X9xPVaHrftjyhuhw121hi+qsRWp6BbkMAjZIItC9AaWvqjunsNmmPYFnx3o+TcvFCCSrsiwXsSDMgVuuQy8ofW6XjpwyYhgLFy5k2JAyfjHpTrzuDs7pc0ceydhRx2F17oLyDIny1tbW8vXXXzNhwgRxXQyDJp/47cQTT2TixIlcfPHFXDDuBGW7lohykdfY3Ld8nty5YTZKDu2X0NUH2VcvXsgas0PEUTU2Bqafi7dTVHZAZRYTOrDIIWzR3wDuUluUi1ToDpaLPCf75yCFbqvA6suFv9t1lHlMldDNh6boGDHBdNOe4I7AWBS65gn20L01QpnJfeR0D0/oUpH6Y1ToqbZcgjz5GKJcpPLNLBb/fXUB8lRtr11z4KufQF5vB4UeYRq6VFkuuldUKvJ5lMsl5PNXtymwLEihu0xeMQAdBjwgnkMtA3K6iWiR/L5iLk6ZWyWrkxA0xWVQs06cX4f+4p2rWgn5h4pkcwnA0P2irN5aVH9+5Ekj+Pzd53jvqw3O6XP/8TivvvURz019KMhDFxD70HWdDh06sHTpUrPcjdDhGACmTZvG/Pnzee+99xh0/P0s/ew/CZU/hjMkpJ9CPk+evBY54oHhoc+9HGb/OFih2zt6fDXgMZVTvJ2iQYRuNkGtJpRD2KLdcnGMQ68WL456TtZnU6F7Iyj0lY/AnLNDy+FvCDw0kqDkrEdWR6CN0O1RLhC4RmqrQ7Vcsruay1Og0K0+Cld4y2XPPOd8KBWLoco2hs1pYg7ruwzZU1prktBVD11aLarlIjsifbU4hi2Cc6RLqiwXEPdDHQ3s1EKs3RD6uzqnqCG/K1EuIRMvO6lVuQ2kQrmPPOkEXpn+QaAnuQAAIABJREFUEf7mOnbv3sPnXy/iuOOOY9OW7XTpVBg+fe5vrxXpc9ED5dV9FOTnWelzCwsL6du3L6+99hpoGobhZ9kyEdW1bt06hg8fzuTJk+nUsYQtW3dSkJ/vkHpXXgojlE9igmK5SPjqhbB0tYyWbp+EbvfQ6zbB7i9g+0xzgdIUk/DWBIbix2u5NO8THqMnh5CRbOFGitrDFp0slywly7AToaujFu1Ks3GnIJ5GM7GlOrDImqS6Q+A3XfGNZUvFinJxeLjsHjoER7lkdTLXieShKxVrpEmirVzreeEV+pyzRSVmx4LrYP5VzvtTjythn5Db5cYiL3m9fHWBc1AtF3ld/U04JucCZ4Weijh0WW5/Y8BycecEn6usTFRCtyt08cX8L8nGUJbZokHUKJcUd4qef954Bh59OGXHncKp51zJI5Nvo1u3bsz+Yj6DTrmUY489ljfeeINf/epXbN26lVGjRjFo0CAm3vCASJ9rGIHyGn4uOX8sU/7yOMceeyzr1q3jxRdf5J///CdlJ5zFMcefz9tvvw3AbbfdxoABA+jfvz8jTxxO2YAjGT3yOFauWuvcKVqzGhoSSK4WdL2k5VLXYnYLtGfLRSV0SUwyRzcIYlBfOJ+SOtYpY2IkNFcG1G7QfJueYIKyjxRVwxbtnaK+Gig4EqpNdak5WC6RFHrTXvG/biPkdLV56GEUuqwoYrVcZLZHdZkk/8wSsb9Ilosst5YRW6eoJ885qsTXIM5XtaCs36pFk9pXF2jGBqlWu0JXon0g+NxVy8VJoVvRL43OUS6yrHakgtCtOP7GQIsxq7OzXVW3UVnmJTirpqZ8VwnePvpStQuwLQsqWGhZdS/gcm75oaTPBab87ldMmdITmvda0Vc/v/xSfn7hSaKDVXmHlyxZIspXsThwbMVyOXF4GSuXLw6yMz788EMh+Jr3CdsI0RlroW4LNO2mpKSYhbNfh8IjQwvsb3J+R6JC2kim5aKb75Mq5FKM9qnQ7R662pTN7S3+25vu3urkLBep3izVbVPo7lxCRoqqUS4hCr06YFvIc7I+O3SK6j7Y+DJ8c7tZJjNNrnx55bENX4A4MqRC99p8Y494maN66L5gxSzDPj35wkMPR+iqSrUG7EhCjzBGwJPrbLlEmkzD3yi23zM3dH8QXaGrpCyvl78+cA7++gDJBbU8whC600TRVnRKEpaLlXNfUejZnZ37cOpsCj0kTbJU4UqnaIjlgsLdDnHokeLRa9ZAQ3n43wOFCxxTVbMRh/8rFYgRbLnYCq0g2sAiW8dlCPTg6xIzbPuW4sDTcgq9/RK6qry8NYGatWSw+G8nDrvlkqhCtwbdSIIyX6iMfFMJmyFwajiXoXSK+s385746yA5nuTh0ihpekX9l7T/Ed1WhQ7CSlr+pCj0oskMzRzZGiHJx2TpFIfCinT5bRM64smIn9FiiXDx5wTaNRERCN4+1c45yzAgeuhqCCtEVunoMS6E3OXSKylaPTaEHpU5OslMUghV6ZkdbB3AYD91KwmZmV1Qnt7DIzh5/DiFEF4vlYhhmCyaGXEsWSeoEVxYRCN2evyWEaMMQeqTkXNEGS6nWTjyQ10vaVi0c4QLtldBVD90wBPH1mgBj50PpeLHcrvRUyyUhhW63XGwDZTwF4phWLvTcgI2idopCgKBUha6SqvxsV+h6s+gQ8zeJJiqISXvVcoCIagGbh25L0evOjtIpmhGqNmW5SoaYYZmZzopaJXS/0nKwl1M9NxAeurquROOO8NtKAt2lEHpcCl0ldKVT1Mk7l/9103KxTxINoR66+j0VnaL+RvEMZBSKvhDDQaE3KNmtdZ9C6DbLBSfLRVoY4dIBRLFcpGqOOsWdsq1doUfMuGgE1jEMwLaOU96dqHlaoo2YTUKhq5WmnFSkhTpEob0Sumq5+OoAQ5B1p+MCSslJoUvLJe5OUQeFbtgUuiefoLhlu4euKpZ684XL7kygmamQg6YJsrSPFJWEVl8e+M2yXCIodL8tygXEdfKGGfoP4hrZMw+GpNkN56GrsdtKjhR7OSVUywVCK4mGCISuNwIa7J0fIPdIYYvq/LAQGnooB9gEVUq2DlJ/BMvFHuUSROgp6hT1VomIHHtL1dHOsnvoYKlNNQLDIjOVuDTCD/0Po2qt+x0DAQbZPCqh20RT8EbmOq4w60SwXByn2ovS6pDbJRrlorZynObvTTHaL6Hbsxda6tuM4FBJwdCF2k3UcvHuUwg9jELPMBW6JDN3DlZYmGW5mA+OVFCegkAFZB9d6MpwUOjmOVcrYXpOhC7Ve0YEhe7Kimy5OBK6bT23jdDXPQ87P4tiuXhDXw5LoZuEbiemcJaLbg61Ly4Tv+37NnAMiXgUuitD2D52y8VS6EpKALARepgoFzXGPVWWi7dWCAjZcW0dy2lAnaLQ5ese1Clqi3IJGfqvfHQiPzvPWcnAYlG00SwXh3fUMILXsSdfc7JPQqJ7gnZocm60JGUpsFysUNGWQ/sndNmMlepbhuSppCCJMRHLxdBFJ1Q0D92u0KXalF604Q1YIJLQMwqV9eyEHkGhV5nzc+f2Ej34hhFZodvDFiHYcgk39N8+7N3eVLR76MsfgNVTI3eKQqi/qnro6jYS4SwXeZycnuK/vM+R0ucaEQhdyxDPiLc62HLx2ywX2bKJZWCR/J7dxew/icWKcIA6gYmM6IlFoQd56HbLxclDtyl0e7bFEMK0V87y3iZiubiUcpJahQ4x2EhOCl4P/h8O9nz1cn+W5SLLmlbooVA99BCydlDoXpuKVxV6xRJY8MvwL5q3GjDChC2ieOj5wR66VJvWEHpvYB8WoRcEiMCellZGukiohC4Veslgcbym3dE9dDUhFZiEHikO3RMaQuhkuajX2V8vKr+ohG4jZjuh25WmVOj25VL9ypGK1oAmM28NRFDoMmxRJeVMYWX4qsOEK8ocLw7XzRPFcpGhaolGuqgK3W8SuhzNax1LjUiShOcU5WJbB2z2B1jKNeh3lfzCWS5xKHS75WIpdFtLInij0LKrcFTokQjbKTzT4XhKWR577DHq623vRsNWqN8UvMxWWdz3+78ya84853KnCO2T0FUP3a7Qrfk4VUI3m7py0mZVoW95A9Y+AxWLnI8lIwoywoQtWlEuBeKY9tAkqaIMn0Lo281tCgOE7mS5qJAxrBBQ6MVDxP/ajcEvc9Ne8cDLCixcp6h8SJ06RWOxXOweuq9OXC+nTtFIKXJlZeoJY7mE89Dlcay+ApNMDZ/SUgvjoYdV6GaOGvUc7J2iPgeF7gpjufgUhQ6J2y5qp6iq0MOlTbBaZ7YolyA4DCwKUrFqrheI6jfL44EzGYd40UqrQM4pah03wj6AIOoKIvHAcp/PHsoYznKJELYYFIkj4EjoZj4gv1+dnlK1XGDyXTdw+uiTHMqQOrRfQg/nobtjVeimlytDvHZ87Hwsddg/hFouhmK52D10eSxLoZtKUo468xQErxd0jjaFro7alEPdS0xCr9sYqtDduYHWin3oPwTPPBRrp2iI5aIQuqELMvPuC9MpGsEaiFWhRyV0RaFrGYLAQhS6khceQj30jEKRRtbnZLnUBf8PGgxmjqK1E7qMFJIRTYlEugTFWyuEblfoujIARj5rhj3KRYGTh26NvJRKWCVDVUWjLFfLqhC63eKo2wi16znvvPMYMmQIxww+mWf+/aZ1bh9+NJvBgwdTNmgQp50/CdCpra3lyiuvZMCAAQwcOJA33pwOQH6PY63dvj5jNhNveACAiVdeya233sro0aO54447WLBgASNGnc2xo3/GiBNH8sMPPwDg9/v5zW9+w4Djz2LgiAt4ctp/+GTOPM4//3xrvx9//DEXXHRx4HoYBk888QTbtm1j9OjRjB49WpQlP5/7fv84w0//KXPnzmXy5MkMGzaM/iecwzW/ute6DBOvu5PX3/4IgD59+nD//fczePBgBgwYYKX2TRbtd6So4Sco77PHZrkEeeg2Qs/pARjC+pCEvv0j6H9P6LHkII5wYYt+xXLRbWGLcn2ZnEvuY9cXory5pQFrJppCD8oHY55PiflQ128O7RT15CmtFadOUZXQwwz9tzr/XATlApFwZwUyUUoCtCt0e5SLukw9NwiELcbsoduSaqkK3ZUBukNfScjQf1uWy4wiqF4dZsi/jdjtFZw7J9RySYVCD0rA1ShaCJ680L4gf5MY8FVfHiB03UsgqkWZUxS4+aPbWbp9sbg3rozAiEhPLlaqXLk8o8DMuJlhiiZDeMbuTLFP81kbVNKbx068SRzA/sz4GwGD5557jpKSEhoq1jPsxDFceN44dG8jV99wG59/8RV9+/alYv0cMAwefPBBioqKWL58OQCVu8uBHcHXRx7DrGxWr17NrFmzcLvdVFdX8/knM/A0bmHWol3cddddvPHGGzzzzDNs2LCBb76YjsetUVHVQHGBh+vv+DO7d++mc+fOPP/881z588sDxzF0brrpJh599FE+++wzOnXqBEBdXR39j+rL5LsmQXEZRx99NPfddx9UreDyX97Nu+/PYvzoo8U1U1pJnTp1YsmSJTz99NP8+c9/5tlnn43pcYiE9qnQ1RGYFlmbs/BEUuiS9Av7if81qwNRInvmOquncArdUBS6ZuYYN/yB8tg9dEPx0P310PsisY0nnOUSwUMHsa2l+mptCr3CVOgKoRt2yyUr8DlStkUIWFWOlosyOhYEwfsdFHoQKdktF3unqHrvagMEGo9Cd3kIyYwJkTtFpUK3e+ghCj1M34M7O3KnKCRG6EGRLKZCd+cRktNIbzLFCmb/iWZT6LbX3a6+IxfCebHuNd+1UK85NDJEtDSeeOIJysrKOP6Us9mydSdr1m5g3qLljDzpePr27QtASXEHMHRmzZrF9ddfb+2huINDDnHrHorzmTBhAm63WFZVVcWEn/6C/if9hFt+fTsrVqwAYNasWVx77bV4PB5Ao6SkA5oGl19+Of/973/Zt28fc+fOZdwZpweXv7kq5Fq43W4uHD/aWv7ZZ58xfPhwBpxwHp9+Po8Vclo8teMXuOCCCwAYMmQIGzdudLy88aL9KnQQD3osCt0aCm8SU4E5qrRymVB/XUeLcLtdc8QEyipCCN0hbNGVGSDIZlOxqlaKHHqfqTyMfS8PXi8aoeu+YCLM7CheUHe2GT2hkp0RnOpWbyZoUgeIbrmo6jOzSFgpkTx0SXaGLhKGyZmA4uoUdYhDl3aLU8x7JA9dk3PHxhm2mFEk7qGcdcpfrxB5LAo9TNiirHwT6RQNUegyb42hCAvDVOgmoXsKlAgrxXJR7ObHxv5FPP/NlSLZWsMO8Vx06C9arr5akS+mvhyKj4V9S8V55PYU+61cFthZh4FCrVcsEc+lFS6pPHOGzuwvFjBr1izmzp1LLhWMGnMujY0NGIaBplY45rRxYnlQ76z4WVnW2BwclpmXF8jlcu+99zL6lJOZ/tzv2FiZx6jTx5mXS+5Xdv6KTtErr7yS8ePHk52dzYQJE/B4lOfD0IVdarPxsrOzRQViGDQ2NjJp0iQWLVpEr4J9PPDIszQ2yec5uA8iK0twhtvtVvz+5NA+FbpFVCqh2xR6JMslt1S8fNI373OZeJB3zg49VjQPXVoZkoDl+iFhi35R2bhzxAvR5RSzvGGiXKyBL+Z+7Qpdpt515wii0ZuDSdqTG3ydnKJcJJxGrqnkL9PKhkwmnRmoZFS/vWFboPKKqVM0QtiitFtye8dgucSg0CNFubgyRaWvN4n7mN3Z3G+sCt3BcrFHuSRkudgS0enNoWGLhg8wAoSeUYiVFM2enEvCiiaB0Phz+V9R8UGdovbOUV1UnoYeEFX2Tk1Dp6q6muLiYnJzc1m1ag3zFn8HBpwwbCBzvpjLhg3CAq2orAHDYOzYsTz11FPWLiorRQ6jrl068/3qDei6zvQZH5lFCu2wraqqorRUXJN//TswG9HYsWOZNm0aPp+IiKqoEMq7R48e9OjRg9///vdMnDgx+BzMEbAF+bnU1DhVzILQQdgptbV1vP7Wh8GrtNScrCbaJ6FrClH5akx7wSSbSGGL1khRFxQcESDwwiMhpzQQfaKiudL0FU2yUVPiQkChy+NKQle9cdkx5sqAzifDkbcEXqZwHro7M/h3ScoSFqHnCtLQmwPEC2anmctUqdE89DCWi4Q9MZlVRiUO3U7osixBCl0LXiYREofuoNDzeoVaNVZ/hdlfIMlUzibk8oSoqZgUOoiKJKODuIYhHnoylksinaLKfZdjDGSnqOELqHNQCN1JoTtEuYQMLLKnz7UKYV9gK6MeKKcUCyGE7ufMU0/A5/MxcOBA7n3wzxw/pD8AnTsV88zUv3DBBRdQVlbGT37xG0DnnnvuobKy0poD9LPZnwPwxwfv5uyf3sKp511H927dw5bt9ttv57f3TObEH/8ffn+gcr/qqqvo3bs3A0ecS9mJ5/LSa29bv/3sZz+jV69eHH300cp5g7CM/Fzz8wmMGzfO6hRVr0GHDh24+uqrGTBgAOdddjPDBg+0Xc+WjUNv35aL7jVHgCpTfjkpdG+1ePhVVVrQLzCyMK+vIEg5wlKFHPYva1Z7JjhJlPK4cvIBeSzNE+gYc2XAqTJnu4lwHrqstDx5Yp+GabnIl1h2enlMW8AwhCqTBGhVFJmJR7lISJKLxUMHQawhhO4XZfXVRe8UVStjGbKY2wt2fx28nSRLV3YwmRoxKHSnKBcZtiiPm9NNXEdffXCUUVyWiyR02d+RZKdos0Lo1vn6A/chowB6XQRdRsHG/4ZaLiq0CIRun6IuKKEXhJCnYSj9E1Kh20L4jP9v78zjpKjutf89vUzPwDDsm4CCgFsEAREXBK/gArhglBi3aEzcEpNXY6JRk6iJS/QmEo2vidd746uJUZJojEbNNWo0ZDO4BBcQARUFZF+HGWav949fnapTp6t6menZSD2fz3ymu7q6+nR11VNPPb/ltJApS/GHZ5+V7dR8BHWbvFVmzzqO2XPPkic7l4HTQmWvSh566CHj+2+H6pXMO30u806cIMsqR8Ou90EpHnzwwcCwjjzySJYv/ZfMxlS1HzffJj31U6kU8+fPZ/6NF/l32K4Y++tf/8rFF18c/N76sdPMVy89l69ec6u3eNemlWJLud/zlltu4ZZbboFti4U7Uj1h1yoe/L83yWxXEPDMJ0+ezMsvv0wp0D0Vuu2hpwxCD1PoujGXebujuzMmMnLilvX31Y8Js+wffFJbeT8suwuvz7ip0JMVRnpXylfoYdkk+dIWvdxsl1B6DJPnUZaLHodWu9oWCctDt79T4PPDCD1HLxc7xTFMoXt3G1GWS8jregKPimFucNdQTFqRpyqCdodunGXP/2puOzLLxSX0uvUyXn3BDGS97ApuQyPUctFjrJTfbNf7FI1cCh2MwCTy+0/7DYw4zVDwEZYLCfyy9JCS/+Ag3P9RlkGLv2+9gLup0C2lC9kK3h5baO8Vu5c7xm8YNbZCKkXFQz/00EN56623OO+887K/g86ss8cdqHw2WyZYF0WIFXoobA/dVOihhUUW6YModICe+8jBkekvqsCG2ZgL/JNo1cOwZZHkgitDodeu9tUzyMFmKnQbeS0Xl/C1h67L/cssyyVR5gZnK+S7a3LU/VbsLJdEniyXUA+9gKCoRpiH7vUML8Jyqd8k+zPVA7wGR+44vKrcCkuhu42zdMpo4LPyWC6642LzbvnMpO7tYs4epVV+iOWi0zg1mne7CjApqnnDn+REL8ZLbYkgdE/YNPmiwcxe0vUaoZaLssZgl+GbBTcYJGbnoWO8z/0cL+5jqVvzsTJmijLH5D1UIYRvjNP+3SDEUsJaHlaoZH6uw+uvv269bozR+x0icu/1+gGbyib0uJdLNmwP3SR03amw2bJctPLS0KmLPUfK/yjLpX5zkNBNomvcbgRF3RNp+9syObM3npRhDYQReh7LJVnuZg00yonbY4Q/XvAVpPbytYWTNBR6VC8X7ztFNOfSKIuyXCI8dAi2HQAZe1Q3RTso2mwRevmg8Au1R+jllkJvlLHqTJvAZxWQtqiRrPD3r93XBiKCoiGWi/6Nh8yUC371yuxt5YJ5UdJtHZI5FLo5vqz2ufo1wzoJ9HLBemxVWUZ2WzSKn7wLjWm5hJC7rZgDZJfIQ+hmRkwqePHJQj6FrtcJe90ctw5AF6jQ9UUxopK1PVDQ1pVSs5RS7ymlViqlrs2x3mFKqWal1LzSDTEEtkK31bfdNMomffAVeqXkvVLW353F3lJD2xb7FZkg/VMm/hBGXyR+nh0UbWmQtC9vLAahh1kb+fLQE2WuD1/rj3vEPBji5sd6Hq9On3S3lzI99PoSeeghlovTIqRhE55tubTksFw8Dz3CcskMNAjdeE0TeJhC9yyXfB56SGGRRqqHv3/DJicI89DtCS5MQh88U/5veJGiYCrAhiiF7hK6rdDN9rlYhAmEkp3ZzlaZy4z1s8ZoELqXOBCRkx5STp+17ajuh6Gl/wkgGX3Xk6uXi0e64W8NVehR3ULtz+gEyyUvoSulksC9wGzgIOBspdRBEevdATxnv1ZymB56U7WfsqiRzOS3XDL9YOyXYW+3tFcr3vqt/jprnxaVMdwvByaRhgO/LoGYlga5CJhBUYDeBqGrdGEK3U5b1JZLIuOqfJdQ0pXikbrzI5Kq8LNcAoRueui7/cfe9ovIQ4+yXJIGyerGVfrCppWuHRQ1l2lo0tXFYabKrd8k6YNewZhJ6LvxJq62FXoij0LXYw+o1qSl0A0PXd+BZAw7zb5AZ/rLeG2fX/8mvcZKyur6FygKgZRPXezV0/89ilLo2jIJUdgeClHoFvSsPkr5+9Sx/Gf7s7IUuu2hF2i5oCCh2xiEIUezrwDp5urlgiH27OydRn/sWXcfXc9ymQKsdBznA8dxGoAFwNyQ9b4KPA5sLOH4wuEp9KZsDx3koM4KilqWC8Bh98KQGfJYE7ppu6x5Qk5AU6FraEuhfmNQoUPQckmkfKKxSRuiPXQzD91sZWsXHAUUesYnDzPLxcvKKCYoGuKhRwVuWxrcz1BSeg4yjkCvlwKCotpGMPvA122KVuhNu/3vkeWhp3N76HaWSyItJ6Wt0FM9Zf/q/W/HR0z0GCFjb9wBuz6Atc+4Cl1nPCm5s9rwUgRZRSBsOrdUT/87FKrQAxcv3ao2QqHbjbiyFHqU5eIGWlUCyGO55PTQC7RclA7s2gFfc7P5ujfqoGguS4Zwy0XfoXrnpRVctq2gzlbowDBgtfF8jbvMg1JqGPBp4L5cG1JKXaKUek0p9dqmTZtyrZobgbTFEPWdpdB3ZpO+DU+hu4TeVAPrnoPhp4WrEt19sX5ziEI3bmACHnqY5WIoaRP6ebKMQCtbez0vC6Ne1g1T6GGEni8oGpqHblsuhs3U5E6MreMNuvWAOQVdPoWeSPn9yEFOloYt0YTeYqjfSIVeYC8Xb39njMcV7gXTCIqW5VDoOr5RuxqW3A5/OcPtd1LhrzNwukzwXb2CUHz8uPQVCuwfK78bWqnQEwa32MScR6EXarmYRJsrKKr/24Fa72GCbMLHJ12vf4v7/kz/4G9jIldQNLTHu/myMUb32LnrvkeordHtKPSxqwPBTvC/aVsBv3vy9yxdujT689qIQgg97Nvae/ou4JuOk3siQcdx7nccZ7LjOJMHDhxY6BhDRmSUtDfV5FfoYZaLjTKL0Df8WQhieNjNCIZC3xwMivYc5VsH4BK6UVhkY685MOmu4EXAXFd76FG2TTLKcilGoecidBWcGCQwRkuhp3r6hJ6qCBYehXnob34b/nQC3mxOKuG2r3WLb+q3yglVHuWhG/60qdB1YVGutEWPEPT/kDuSsLTFqAA5+IRes1oIu6VeMqdMQtd3e1vfIBRLboFlP7LGrIPGxnEVSFs0FHoiV5ZLDsslzEMPy4Kx3xdQvzkIPdRDdwgP1CLjDOvYaI9Df17FECgfEFgzq31uqOWiX48KnLb4dwGa0P9rAbU1ejIVq/I4tNLW/16/e6rzCX0NMMJ4Phz4xFpnMrBAKbUKmAf8RCl1WklGGAZ9IukiHpvQTYXuONGWiwnbctEFOpVjwtfXhO604KUMQjAgCgQ64oVZG+lKOOCK7BMlKigaabnUB7Nc8il0zwZIZH+2ua55kYiyXJrr3YZRPfz9Ema5mAq9pRne/x/Y/qYbxHS3rfuRg9hZUKDlYih0s7AorB+6tlfM7xSwmNxjxQyKFuKh99QK/WM/37zmw+DFs/eBQrrbIgi9uc6/MNVvgbrNhm9uHOd2ULQ5ynJpgkC3Re9F/SXc/xFq2vaG7QtCwu22iKXQceMXTbVu50Z/m6d95lxpn3vEqdz/0BPe8v997nlpn3vIIcw8SQqMdu2qDrbP/d3TAFT26u1ZLY899piU6QOf//zns9vnTp3KxGPP46gZc7Pb5x49j/GHn8g99z3AiwsX8enTrfa5Z1/qfj9pxfzj+xfwyfpNHDtzplSKOi388aVXOHLmPCYdex6fOetcdu3aBThc+717OGjSdMZPOpJv3HAXf1/0Jk899XuuvvpqJkyYwPvvt6ImIQ8KyUN/FRirlBoFrAXOAs4xV3AcZ5R+rJR6EHjacZzflXCcAeyuT1MBfgAzLMtFH+DNtXIw5bNc9O2aVuh2Qy8baaPRlmm5mP45BE/6MIUeBZPQEymDlEMsF9w2wib5JkMIPSzLJcrTM62IqHVNktWz6KQjCN1W6Jv/LhfNVCWB3PKUYbnoKsLygUY+e5TlYin0RI7Sf3M/eB66sV/1b550PfTmAj308qGyvWqjclDvC+89aegzLlqhm4T+z4vk+479sjuuXv42dBaP/k6eh27FRqLy0JWCK6+EN16VzzQVdaqHofjL/Atnc50IBv25jdWQSLpEngZa4OD94ac/97dX8yF29tAD991Fv732Y/e61zhs5tmccdLRtLSX5i5VAAAgAElEQVQ4XHzZV1i48C/SPnftMmBXdvvctUsAHTRPEBZkzGqfu3Ahqep3eOFvS7Lb5778CKnKoWzdVk3fTA2XX/fjYPvc884w7kKa+T+XnMX8nz7CSy/8kQGD92LzJ+9zy50P8MIzv6an2s4d//Us8+fP5ytfupgnnnmZZW+/ikr3ZPvHi+jTpzennnoqJ598MvPmtU8iYF5CdxynSSn1FSR7JQk84DjOEqXUZe7rOX3zUuOpp+CuG9P86WrEi4TcCn3bYvkf5a9p6H4gWYQecSEwOycmyqS0e9Ax2RZNwLcuhtC1QrayXMIUOsjdSl7LxXhvIg+h65M2mUOhm1kuTbVBy8UjdH2n1OyTTXMDrP6tPG6q8fPGwZ1gwv1d611CzwwKn+SiybRcovLQLYVet9GqWzCCohqe5eLmoTfV+lk8YUVmGomkVLRu+gsBV9IkdJDU149+TWiBUUu9/z12r8ebHAWMSVz0xTpEoduWS1M9XsfJQKVoyM25CstJ14iqFDWyYMzvoycXaa7Ds09c/Pje+3ni6eehuY7Va9ez4oPVbNq8jenTjvbb5/bvBzW7eOHFF1mw4Ffee/v27Q27dZKBCiV0u33uBRdcwIplb6MSSRqbZXx++1zZJ/369YPaWj533rk8/PDDXHjhhfzjH//g5/feCDSFGM/yfV755yKWLv+AqTNPg5YGGpoSHHnUVKp6VVJenuGiL13FSSedxMlHj2z3gCgUWCnqOM6zwLPWslAidxzn820fVjQmToSGJjmQG3ZtpQyob+lFugXJXAI5qBurJSD1j89Lp76981wRlQoWFzXtdEkpgoRNQteVose9HLLdVPjjfAgo9Bypj9piMbvcgWG5pI2UwjCFHjEmz4owMmfCJokG30M3LZdUj2zLRffMaKnzCR1H3mtaLrpHfb2h0HXTsywPPSLLRStYc33HkRxw3enS/E65LBccY+LtPtnvNdFzBGx+xRhTXVA1A/SdJK0jalb5dRDedzImSWmulc92LMvFbhQXUOh2UNSe4MLoyXLXXXIXVPOR+10Ssr96jZaLiUqKUKleAT32gtpPpGWGvrBsfV3ssMbtMjZdFas/q8ntMWS0H3j5r6/zwksLpX1u/Qr+49RLqatrCGmTKydz1nL3oqF09ohKeB0OvZ/Abp977LE88f9uZtWaLfzHyRcEt2tl81z4+c9zytzTjPa5CWhRZF0AXa/daWnh+GMO59FHH5GWw732g7IqaKph0R8f5MVX17DgN0/yf3+8nD/9/gHaG92uUnTECPjPH8pB8/DPRMmdeHIvPvUpeNedmc1ThktvFy/zyJ8HT8QomP1cGvP47mbflGRZ9HqJ1louulK0AA/de2zYI4HmXFZmB/gnfqTlEuahR1gu2kPPUugZUeOOLtlPynu2vy0+c59xsq5ungbBLBdtuWQGGJ9lFRbZCt1xDIVupS3uWCqdIIee4C8LtVysoCjIxSXZI6i2wy6GPUb4FsegY/2xmeg3Sf6H2S7Ndb5Cb94tj+2gaKoIhR45wYVdWGT436E9VEIUes+RbhfJhJ/lordrTv/X4vr4SrGjehd9+/SW9rnLP+CVV/8FuO1zF/7VaJ8r8bETjptptc/dDigGDx7Mu8tX0dICTzzh+/A2pH3uMFAJHvzlY95yv32uBOS3bpXP22uvoSHtcxOYVCntc+UYPWLKRP626E1Wvv8RALW1u1i+fDm7qneyY+cu5syZxV0/+gGL31kOKkmvXr0iWu+WBt2O0AGOmioH8pTx0onvrM/1ZetWmDIFFi3Ct1x2vCNBysHH5NiagUz/oOWSL5DqpfPlIOqAQm+Dh54rbdF8T1jaovd6iEIPU5nmct2wavTFfnWqPUbTQ9fWVtJQ6B6hpFxCf0ee9z9c/jfu8D8vZWa5bBJPPpE27B2r9N/00HHcz9MK3SosWu+mAw453l8WarlohV7h78e6ze5dR578fZ3pkuoFA6e6Y7MIvc84+dywwKg5jaFH6Jbl4v22eRR62AQX3ti1NeI+d8yME7NS1Aqammo50x+vNYUXFNXbMKjF6/OSYNbMo2lqapT2ubfdyxGHTQKlpH3ufT/12+eedxEA377+mmD73IV/B6W4/fbbOfnsK5lx6hcYOnQoUbjmmmu47rrrmHrieYEJnC+66CL2HjGC8dPP4ZAjjueRX/t3jFntcy1r55LzP83skz/Nsccey8AB/Xjwnhs5+/yLGT/9bI6YdjzLli2jeudOTj7na4yfdBTHzDiBH90iLbPPOussfvCDHzBx4sROC4p2Pbgn38H7roFtcNmVgzn5c3D00fDZz8I/52dgaz0V9Zvp1buI9EizQVehhF63IbfyDij0Vlou5oTNWQq9wnqPe8KZzbk0ApMaF+ihJ8rkgD78/ugxmh76sFNg0o/kQuo1BjPyzBNlos5BZrmBbIXeVI0385GeZML8rM2LJEWt2fLQwSdA3ZzL9NDX/RGqDvBamGZ9T40yQ6HrO526DfL97CwSG5rQe432O3qmLEJPlss4tr0VXK5zxk1CJ+F/hyzLxSiwC81D1wrdsFw8QrazXAxC99Y3xham0P0PMu7CtEK3jquWBlAJMuXl/OG3D0LlSLFsygfLxdJpYvbs2cw+yZ0xrGEHVK+gsmePYPvcXaugcQfz5s0LDSyGts9dvlza5zoON//nTwC3fe4P72D+t8/1j4caOS6z2ucm0kYIQfHViz/LV7/+HeGH2rXMmH4Yr57yedixBCr3lUyohm0sev4hSUdWSbkrJcHUqVM7PW2x60EfyLVrAAWZAQwfDgsWwJo18Mz/ZqivreeTDzez4uP+tBRalFdWpELXGR02yQbG2kbLRRO63clOI2kp9Kr95SQJG1uoh54vKJoJf918zfTQ05VwwJVyYmvry1To+j3pKp/8AoTu7vOmGlHomRBC/8d5sPj6oD/tBVx3hyv05nqZYnCIYbeY3z/KQ9dpqNvecO86LAVsQ3+nSoPQE+XZ6/U+WO4gTXi95V3LpWk3Xh8e8OsbbIXuuApdJbIFRK4sF3lgLLMtFzM/O0dhkVbodh66ieYG94Ki1bxu2WuoXxUylqwArVXBWii8MZqb0kIj7W3z0MMOD7bPdaw7Fa9PjdGdMpD6ayz3Ple/t/2Dot2T0PXJV79JVLV7EB9xBDz0EHxqXIahg+sZ0nczzy8cwPTpUNBFUVsujiMkk7cYSZNmLoVupsi1ISgatj2wLJeMBH9PX+8r87yEHmW5GBeUfGNsMTx0+/WWBqOaLuW/p3K0v75puWgybdwpHrqn0I2LR8M2SYeLVOhuXrvZnKt6uaw/4MjgGPMVFvUZB/2PwOtFk69lglZ7laOlhiEzIDvwCbLdmlXBGYyajYyglsZsy8VT6C6xmy0wWuqDFxv9elS3xdAsF9tyMZGjl4tOUTQnQdaE7NlCDS7x6fRIo4Rf2XcLxuOsYqAiWw97CGklENIG+fVFr7Bw4UJvvk+/sMj6Pt7FoSVI2o5F6Bhk3859XNxP64YwiUnPBOPinHNgyhEZUuymqmIbR80YwLvvwoQJcP31sH17ju1m+gsBNFV3AYVuNOeyJ2EwYQdFo7aT9ThfUDTEiojatlaSWYSeCVouOigKLqHrlEtDoWvSatzpXrAHBT+rpUH6pdR87PYs1xk4pkJ3c83NwiLdsrZqbP7vOeIMmPCf0isfYOxl7tgsyyWM0CtHy3Ez4AgZ22mrYdT52etp5b9jib/MnBxDzy6vWx9DdlBUGQq9OYTQVYrsXi5WYVCYKnYcsisoc5X+J/z9bFsuesyeHWOSv7u9XGPJUtVtUOhZU+JlK/SsC5l3kdLfK20sJ1qhEyv0wpGD0AE56Zp2oZwWJkwZwLJl4q1///swahTcdhvs2pX9NjJu6XDdJklbzOuh6y6EhXrobchy8ZbbQVHbQ7e3E6HQE0m8XO0whHnLUdvWFbv5FLoyFHovU6HvzFboDdulrYLtoevKw7r1bpqcS+SpEIVuFhZpQq8cbX3PEMulfCAcdLV/ku59ply8U73yWy5lveGMzdIDCNygYQgB6Qyf7W/7y8yAr87FBz9+YgdFzdL/5rpse8xW6F4qoP84SxUrt+ozK+/cJCgLyvD5bcslcExopWsqdDclMGsflVihh1kupkL3NhlW+m/YQrZCd5qR8hzrAhRquRRHt05os7Dc6J6Ebt4e68l3TZgnXWYAAwfCL34Bb7wB06bBt74FY8bAE0/AqlXwzjvuQa7VYN3GIhV6oVkubQiK2ss1bA89ajth40yWh5OSua6t+gLvtybGNu0f/dnN9dlBURBi9cbuZHvou1bKyaInPdZ3H/qzNGyF3lTjbk976E3+9jIDstNXwwjdRqoCjnkSxt+cvweO3lY+0uk5Ushu+ztQu1YUudl/yPyeTa4tk5XlYjSpC7Nc7ErRRJJyVcOW6iaDtkxVrEvczdJ/93+uoKipfpWlZE3bMmC5GIrfJD1z3cDnarRSoYdZLk4TfrvfiG16HST190oZyzHSPaMsF/MOpHCF7jgOW7Zsobw8JP6SA90zy8W80kUpdI2M37Bn4kSpNP3nP+Gyy+D00/3VDjsM7rttEJNAuuW1NBaettjeQdFcKt9OW8zaTkSWC7jqsYBK0cgxWiSbtBS6l+VipS1C0HIxP0+Tls42qhhmfZahXMFI03T/a/LzPHRDoYf15SnkTgRg0HR3XG6XxID32wqohLSJ2PgSrPqFTFqy35f91wMK3b2d1PZF0g6KulkuYQrdynIZnl7BmrX1bKpWkN4hdzl17ixIaR3crvEVf3oX7N4MiWq5aGx4L/t7N2z1YwEZILUJsYvSsHE11LjbT+0WwmtpgPJm2W6Z4864VQ8b3vW36TRD7WYoa4G00Zm1boN8n4oiSb1hu8RqzM+o3yzfc8MyNwi/GSqWB8+xmo2QdqtdG3dAusmdZ7gZ0lvcAiwFGccdbxOkt8k50VgNG93juAlIbIFELs83iPLycoYPH17U1+ymhK7wOskVoNBtHH645Ks/+CC0tEBjI8yfD/POG8wH8+HDt1cyCkqTh97q0v9CFXorLRfITejFeOheT518HrppuYwJrm9bLprQ9aTYeh/X24Su8+nd/5pYdC8X00PXpGyiEIUe+Dwdeyjit4xCn3Hw/s/kcf2maIXeWA0of3/ZaYtORFBUK3Rt5ag06WQLoz6+AibfKxeQ9S/Cn2bL6wd/B9b8QvbTxr9IHv2BV8MfZkO/w2Drq3BmbXYa5uJrYfkd8viYp2HYScHXn5gJu9fBmEvleFj/PMx4EZ6eDUc+DGufhI0LJZjvff8d8Ng4mDQfDviav/zFy+U7Hf+XvLs3gCXfhyXXw2eN6uKX5kgDuFmvwce/gb+eCXPehj4HyustzbDgIBj3XREfS66GKffDoktgwu1w4DfhD+eK6Jj+O1jwKVn3wBtg0Zdg9eNwRvtPD2GiexI6uAdzY1EK3UQ6DTrVFODcc+HMM8Svffn3Kxh1DFx3YxX7nwhnnw2ZMOfBa0RVYKVoSbJcrM8yp1oLs0dyEXqiPHpMrfLQQyyXgIfuBkUTZXISmDnidlDUU+iu5ZJIyvsLVejmnKLNdXLX1csKiOoxQRGEnqcgqxjoPHxdJh+YHNtS6Im0/9lhhUW5FLr24FM9/e8bVims0n67AtwiIf26noQ616xbkH0MgKQD717nNjpL+ROygJw7YVaYl4YaLOv3umUWC23vme0i6jf6/OHl4BuFaGbDM/1+zSdeaqmb3ZVwUzL192quDd8X7Yzu6aGD/6OGEXoehR6Gvn3hmf8tp0lV8enjJIBW11TFhRdCeTkMGQLPPmu9qdhK0WIOxKoDYOA06Dsht0KH8CIiDXNZlrrP5PaBIbeHblsuUUHRwAQWVdLvIuGSux1s0pZL9Qp5zfx9zeZp3newPHRToesL3a4PAUfuCrK+Q4GWi7e+JsISEPqoC2DqAvmdm2utLBeL0FUqpAo4T9qitpw8y6Yn3ikfluWUMAjdy95w1/dm3Qo5XkxCT4aQmDeheU+/e6XZv33cd2H6U8H36CI5e9Jtu1tmofAu+Mbct3Ub/Dv8XIRu9jMqcyuX9d2Uma5rttloqg3fF+2M7k/omRDLRasP3S2vQJSVQarnIPokhdDn31PFM8/AzTcLoc+dK8FVD8WmLRZDApl+cPxCyWvOlylj9m2xkddyaYNC19ZXLkJvrg9muUz8ARz9G//92g82lWMi49ppg8lK2dTN07z1rSyXxhCFrmcHCvXQQ/LQc6GUCr2sN+zzWZfkdue2XBJpucPY7yt+6wIzbbElQqGD2Bc6FmPvN1twJDShu2mGev3m+uhgbz6FrgndmzCkzp9MO1EmWUVV+wXfo5Rxt2CgpaHtCh3Ey6/b6PNHGKF7k5CX+98r1cvfRxBC6LFCbx30j1qRQ6EXqM4DqBgsKXGAKqtizhz49rfhz3+GqVPh/PNh3jz46U/hvdXDwK1UjR6nSeitzEPVJ51K5T6hWpXl0gYPXb+uVbMdFE2UIcExrXRS0o2w9wH+OvqgN4lFq3QdEA18lqtctdq2FboZFNUeuk5ZDFPo3h1CgSSh90cpFLqGbtEbmba4y/0+aZh8j3Q+hKBCD8tD179h43Y/oKpyKHSVkgtji1boluUSddELEHrP7NfLDIXutXve4b43VxZVGKG31nKxFHrjDjc4m8NyMQl98EzY7/+ITZYs9y2o5prgHZMm9FihFwlVgEJvDaGb20v5QdHeveGFF+DWW+H3v4cvfxkmTN2bVwe/C3vNyjFOTYwFpLJFIR+5pgpU6PYJOXR2dim8t24BWS4gB7d7AQz0Cgf/d9AnURgJJsMI3d3v2j/XSJT5fn2VO2Wf7aF7Ct0o/d/1vtxNmbMNmVCpwklCKbIC1W1FskeI5WKmLe4KJ1O7fa5Njvo9jTuMQKrlodt3f6ZCx1DodZv8CcCzxl+M5dIj+P1yCYYwQndaSegpS6HXucHKXJaLSejlA2Dy3XI+JN0JdFoa5S/Mcukkhd59g6KJtNz+2BF3MBR6/+K3a2bNWFkuqZRUm37967B6NZxyCsw4bX8OPlgKlXbvhgMPhOOPh/POg3798A++thCAPjGjDv6clkuOLJuDvxX9mYV46ACH/lh66gw4KvtuyWt5m4PQ7QAf+Pu9R4hC1+h9EKx5IjvLJSttsUkySCqGRH+H8d+FoSdGv24jV/5+a1CIQg8jSo+EtEK3cpb1GBu2G4RegIfeVIsfFDV6qux3ecT4C7RcUj397RVC6Iny0nnoXmsI91j0CL1AhZ41rrpgsBmClktTbfYdZgeg+yr0RDo8IAptU+gBQg/v5ZLJSGHS88/DccdBVRXstx9MngzLl8MVV8CwYXDHHeCEzVlZLBJ51LJXXFNklksuFJqfPfIcOOgaGHR09Gd7nSJD7J0wy0VnutgK3VSg/acAyv+9Ekn5foGgqKvQG3YEpkDLwqeu9ydvLgSJTGnSFjU8hR6R5dJYHX4xVCqYmhjloYcq9JDmbIm0+PqNO42gqPt6ug+Mvihi/HkUepjl4hF6R1ku7udq717PgFVQUNQidG252ISu0paHHmI/tTO6t0KPmlauLR66ecW2+1hbGD5cqk1tvPUW3HQTXHst1C9PccNMaGxO02oK8Dz0KA8zR5aL5/kWWQhTbPZH6DaMcn3IbbmEKfQwDx3k9x12Cpy60u+3AnLiBdIWtULdVtgEJ4UiafXXaSu8ae4iLJdcgUCdmhjVywVEoXv5/O4x4KUtmjGetBC3trVUQsamEpKzHjUdoxnDCdsvZlDU+37b/fdEwZxWUKOlsXXHZMpS6PXFWC7WftWWiyZ0HTtKWlkucVC0CPSd6E8gYKNNhO7+wOmqVnve48fD44/DD38IGzfLAb5la4qbb4aXXoKamiI3WAoPvdiTIJ/NUwiKsVxCg6IhHjpIG1mlpPd0YFsV/mxHibR/R9CwNbdCLxa58vdbg2QF4PiBQsjOt48i9EIVuiadwTNg/6/5k5kHFHpKLnyNO11rIylxkRP+CeNuyjF+a5YsG4Omwb4XQv/DjKCori7Oo9BbDEJvaZT90pqLs53loi0X3Z7ZC/4WYLkkC7BcmjsnKNp9FfqRD0W/VoqgaL4q0TxQSrx2PpuChZAqS3PDDfLa4MGi4C+8MKJgKWtjeSyXQtIWi7UItN/ZFmWrfwdvPtQwQs+h0KM8dJ2xYSNR7je76jlKppwDl9Db9nsGUGqFbtsQKukTg0Zkm+NUYQpdk06mPxw633i/ZbnoVNzm3b6a7z85z/iticltlPWFI9z5NPVvpzOjigmK7nxP9kufQ3KPJ9cY9d1izcfBtNhiPfR8lkus0EuI8sFyoFQd2Ir3lobQPbgnVf+BKd5/H55+Wvz3L30J9t0XvvENuPtumDULj/CjthEdFC0gbbFY3zHTD47/u+RJtxbFWC6FZrlANKGnKuSEqjrQnSnGILSSKvRM6dMWQQg9UWbsE+P0zGW56MKiKIXuNEX7ubblEriAF0gPXk/6AgispzsBiK4NyEvoRlB022L533dCYeMyYWe57Fgix4hGLkLP8tAtyyVlWS4tjbLPY4VeIlQMkRamUZ5fLpSa0N2TSiXS7LuvkPicORJQvfNOuOceaGiA/v3huedg//1lHaWk54w0wNOZMhEndUGWSysc/AGHF/+esM/WB35YHn6Y5TJwOmxfkp0GWYhCB9j7M/hd9ACcEiv08pC2rm3ZnknoGTfTpFouQp5qz1EA1uKmGUYpdMhB6HZQtE/4aznHb1Ww5kL5EPm+ujagkDz0xdfBXrOF0BMZfyaoYmBmuTiO3L3te4H/emhQNMpDd8fVHGG5aAETpy2WEK0hcxASUalADnqbEJLlohSccIL81dfD+vWw114wY4akO2rsu6/0cJ9QlmI/YHt1GaEGSCGWS1uybFoLfauqS88LtVyGnyJ/NjwPPU9wbu8zs7dZVkKFXrGX5EOXCp5C3yr7zCPIXm7GSXNuhd6wI7gd8zXvMwpQ6AmjvQAUHkTPZ7kEPs+Nfejp9/IFRatXwtLbYcsiGU+fg1tnd+k2E027Jc22qTq/Qm+0ulx624rw0FUaWmr9mFGs0LsAVEJKkUum0I0qzxBkMrCPm6jx61/DLbfAUUdBczPcdZdMzHHVnBR3ngtvLylj7QIYMECqViv0ubfPmX6g0EaylR56KaDTD3OpzDDLJQrJPAq9rK8E+/qEBPxKqdCPeIDsiRDaAFOhJzN+RkaqwlXrNbmDorvXyWM7ZlSsQrctl0IVeqoIywVkcpOCCL3cTx3c8JJ8h9ZagEq5WTO1fmxFB4YhnNC9PvTWsZPM4E27CNmFRbFC72I49G7osXf+9QpBEXnoQ4fCvff6z885R57v7/5MiVQZZ58trx1wAPz859LHnb4Ton1FfcLkq/hsD3izD+Ug9LDCoijks1ym3GdNzhDiy5cCrb37i4LpoacqfevIm5S6JkdQNA27P5HHdtV0IQo9Kyhq3Mm0h0IHf9Yolcr9GXo/9Ngbaj+WO70+rfDPvXG66aF62r+qfAp9pxvTiLBcvLRFI224pSFW6F0Oe3+mdNvKl0OeA6mUFCmxPAWvwZQjynjhBdiyBb72NZgyBaZPlzTJwYOlyGnKFEiY50hrs1xKAY/Q3RS8MNIuRqHnI/Se1kU4oNBLaLmUGpoQG7aJyjYnvvYqYXMo9DpXoevp+jQShSh0q/S/NUFRlQgGc/NBE3q+lFj93ff7svQr3/o69G1Fhou3vQoJiu5cKrGycuOOJorQw4SAZ7loJW5lucQKfQ+Gl0PeltJ/eW86k2amO0fDCSfA/ffLJB2PPALbtsF3viMB1wULpOVvKgWqMz10m9BDg6KtIPR0BKFnrd9OCr3U0PugpcEPikJhhK4neoHsyV7Mi7jdOM1bx2rOla4CFOAQ2bgtDMnywisjNaHnCoiCf2Eb/mm5IFevaBuhp9yK3J2rg+oc/O9aCKFry6W5JlhMpS2XTlToBV2ClVKzlFLvKaVWKqWuDXn9XKXUW+7f35VSbdjrexi8nihtKf3PLvLp0weuuQaWLhXFvnmzZM089xyMHCn++pgx8P07sgm9uRleey1kusZSI9UTUH4Ze3tbLja6jUI3TnwzKJqsIG//dXN5pgQKXSUMEisiq3nIcTDgiMLW7VWgQh91Phz2U2mtO+ZSOG1t2y7MyQpRzzuXBv1ziFboqRB7LVkuF9/G6uB+1ZaL5613QUJXSiWBe4HZwEHA2Uop6/LGh8AxjuOMB24G7i/1QLstzNa3bd1GjhOgXz+46iqZhOOEE+Dqq2HUKPjWDULkqz5O89xzklVz0UXivX//+60fUmHjVnIClsxycckt7CQL/fxuptAhPCgKuRU6BDsZ2q/p18Ngpy2CMXFLEYQ+7XEYc3H+9UDaNejZq3KhaiyMvcwdiyr8ziwKqR6w7V9C1H3HB18rxnLRv0nDtuB+tS2XLuqhTwFWOo7zAYBSagEwF1iqV3Ac5+/G+q8Axc1suiejlM25CijD1+mQGq+/nqDp3RSrPk4z6xLo0QNqa2HsWOnzPnlycP2SI13ll7SHKvSQtMUoJNtiuXQThZ7IGEFRg9BzVYpCtjq33xNJ6CHFS+k+wEeFZ7kUi0Ta7cHTwXWNyQoJICfSYuOYiMpyKQ/p0qmFRf2W4H61LZcu6qEPA1Ybz9cAuSpOvgj8IewFpdQlwCUAe+9doiySro5ECQi9DReFQw8FVpYxbXqap56CRx+FT30KrrwSjjwSTj9dGozV1ko+/PjxElhNlupcNhVOaB661QUwF1pruahEp3S+KxiBboXlRhqgYbnkCopCxGTppkKP2Ge6AMtp9j331ij0YlE5xs/O6SjoC+ewU7MDyFEKvZc1kxIYCn1LMDbhWS5dW6GHdagKdV+VUscihB7SSxUcx7kf146ZPHlyezu4XQOlsFza2vkwkSaZLnDlCGAAABSISURBVOOU46WHu8Zzz0lmjK3QR4yASy+Fyy+Hnj3Fpqls7d2uSeih81GWMMvFhjfxdOsbrXUI9PyqOigaptDzWS5hE70UotDBJ3R9nHmE3k4KHeCQW4IdJTsC+sK57xeyX2uN5bJzGQw61thGOpi22BU9dESRjzCeDweyLq1KqfHA/wBzHcfZYr/+b4tSBEXb2vkwURb6+UOHytR611wjszB9+KEo+AMOEDtm2DAh9KoqmDhR2hUANDXB7bfDiSdKQDYnAoSew3JpF0LXvby7sH+u4eUyZ4IKPZ/l4in0EMulEA/d3IYyLRdoV0uk/2EwtD29vhD03FvuDMImM9F3I1mEHhKv0XdNTTUw8lxjeZn0cLHz0zsQhcjGV4GxSqlRwFrgLOAccwWl1N7Ab4HPOY6zvOSj7M5oQx66hzYr9HBCB6k6veMO//nIkXDWWbB4MfzXf0k2TSYjqZCnniqVrA8/LK8rJcVPzzwj702FHU35CD3TX8ZWyOxSxRK6pzi7sH+ukeohfcjtLJdCFXqY5VKMQje31RGWS2fgkNvg4BvC0zFthd7SKDnrYS1A9G9S1hdGnOYvD0zKnSku7bNEyEvojuM0KaW+AjwHJIEHHMdZopS6zH39PuAGoD/wEyW3tk2O4+TpuflvghLmobea0NO9CidBFxMmyETYGpdfLkVM3/gGjB4tbQp27pSMmfJySKfFl//GN6TRmP/ZJqGHEERZXzhpKfQcmX9Qxeahd0eFbuahp4rw0MOCogUrdIvQdQC5PS2XzkAiBYmoWIJF6I0RZf/g/yYjzw221tXHZ+P2TrFboMDCIsdxngWetZbdZzy+CLiotEPbQ1DSLJdWbuOoX7ZuflUDAwfCwoXw6qviuWs1rhSsWAEffSQ2zA9+ANOmiZrv3RsOqK3iqH4yFZ+K8rF7jSlsEJkBsj/DyCsMet935QwXjZRhuYQp9Fyl/5BboSfSuY8du9/QnqrQcyGL0N2JUsIIvWp/ydIZ+6Xgck3oDds7xW6BuFK0/ZEogeXSVoXeb1LrP9vAwIFSiWriC0Z86brr4Fe/gieflJx4gBtPr+KoM6CuPsUNV8Ps2dKmoKFBMmqKyqYZcTqc9E64XxyGbqnQy4urFC1EoUdViXrbsBV6BwRFuxrsGYuiGnOBFEbNXZW9XO+/mg9zT0rejogJvb2huoDl0kEYN07+brkFVq0S0h5VXwVvg0okufNOmZZPY9IkuO8+t8FYIUikiuuF3a0UulbllkLPVymaS6HrYy5fyqZKun/uHVSs0A2FXkQjNn1+Vq/s+ICvi5jQ2xu2+mkNQkr/uzpGjnQfrBSFU16RYsMG+Ne/YOtW8d+/+1045hj405+E/F95RXz6sjJJk9wvJAW4KCS6o0KPsFwig6K5CouMKtJcUKng9ss6IMulq8HOcslluUTBm9BlF/TYJ/e67YSY0NsbSklAssigZAClKE7qLOgTIpFi4MBgzvtpp0lx08yZUthkQimxbS67TNIrexqctHKl+PMD8zkv3Uqhaw+9WMtFK/Qwy6UYhW5s/9/RcgE/Hx9aSejGPrQ7f3YQ/o0uwZ2IGS/Afl9p/fu7ieUSCn1ChFgGgwbBH/4gWTPXXAMffwyPPQa/+50UNt15p7QoGDQIfvYzaUD2/e/DgQdKtevDD0vK5W9/G/HZHqF3I4WezPhT75X1zR8UzfSDiqHBbAsNlSisSjaRClqCvcZA/8Pb1tmwO8KclLotCh3c1gYdj1ihdwTaOjdnWR9AtTlTpVOQg9BBbJW33vKfj3BL2ObOhQsvhGXL4KGHJD3yIjeP6vTT4b334HOf89/32c9Ky4LNm6WV8LXXwj59rbzqroyUYbkMnAYznpfim62vucsjFPqB18DoL0ZvV6ULU+jm9tO94MRXCh/7noLywVC3QR63mdA7R6HHhN4d0GM4zHkrOAdid4FH6MXfvk+ZIn/nniukvmOHVKwec4xYNH/+s2TK/M//wK23SoZNKgWJhLx25w/HsmPFXfTvO5fjR8Hu3ZIz3yW7ACQNy0UpaUern0M0oacrc+flJ1LFWy7/rigf4k8WovPQi7FKzd8o9tBj5ESfgzt7BK2D4aG3FslkMD0SxFPXKZQ33SQpk3V10k3yr3+VtgRzTlIkk1fQ3CwTbn/wgfw/7zy48UaCMzt1NnQgVGe1eMvzWC75oNIFpC2mumd8ptSoGOpPT9e4U8i8mEwfb7rHik67m44JPUb7Io/lUipkMvIHcOyx4sMvXw4XXAB33w2vvw5nny0Te3zve/DJJ9L24N135WLxxz/Cyy+LJ3/SSe061HCYQVET+SpF8yHTX4gqF1Sy3X+fboGKobD+RXncFNGYKxc0offcp9NuA+NfMUb7Qk9G0ZY8/FZgzpyggtdwHLj+eqlqVUpI/ckn5S5g+HA4+WSxeL79bXj6aWlpcOSRkm45bhwcdZRs55NPJGj7ta/J+9oMMygaWN5GhX7cy/mzfBKxQgeE0Bu3Q9Pu6E6LuaD3YScFRCEm9BjtjURSPNwuogCVgttuk14148ZJhs3TT0vmzJgx8tqtt8Ivf5n93spKWLRIHs+eLe0OXn5Z8um/+125GFx1FfQqohbFgxkUNZHPQ8+HHgVcbeyg6L8r9GQWdetbSeiuQu/ReXM9dCUXMcaeinRVl8ppVkqyYg46SGyaM86Qx2VlouZff12IfelSsW0efRT+9jfx56dNg4MPlqDsHXeIcj/lFEm5vOkmuUDcfbe0Gv7b3/z8+g8+gK9/XTpYNjSEDCoZYbm0ldALQUzoAm1N7V4fPZ9oLpiWSyeha8imGHs20lVdRqEXgvHj5U9j7Fj5/9hjcPHF4rlfeSXstRf07SvNyW66Cd5+W9Ilr7zSf28yKets3w4tLfJ3662SgnniiXJnUFWFzHFZOSabDCrHyF/VAe33hVUqznIBn9Dr1kmWS9j0c7mQ6SdB1E7MRus+Z1mM7otUVYd76O2BadMkL97Exca8yIcfLm0M/vUvUebbtkl3ys2bpa/8V78Kb74p3vuNN8pfeTncey984Qvj2H38ChY8Ir79vHnyGhWD4dQVvPaatEuYMaMdvtiAI6Glvh023M2gCXz3utZZLhVD4ZQV0HNU6cdWILr/WRaj66PqAJnJ5d8ASknTMQ1zyj+QNgazZolFs3gx3HMPfPGLotq3bhUlD3DFFVJANX26rHvjjaLu77kHvvQlaX720kui8u2g7HvvSYFWj0I7uE64rbVfd89CZqAo7OoVsHttYfEHG5X7ln5cRUA5TudM7Tl58mTntdde65TPjtHBcFoA1UUrejoXzc2i2BcvhooKOP98Wfbf/y3B2l27ZL25c4XQf//74PsHDBCy37xZ3v/mm+L5T50qPn5FRXD9+nq5EPTqBYcc0oa5YvdUPLGXxBRq10i1ri7w6kJQSr0eNYFQrNBjtD/+ndqwFolkUvrY2JgxQ8j3o4+kwnXcOCH0Bx+E1avFl584Eb78ZbFylJKUzPJyuSj84heSdTNvnvTLeeUVKah68UW/1cLee0u+/sSJHfqVuzbKh8K2NyRIPOCozh5N0YgJPUaMLopMJthCOJHw+9lovPGGTO49ahQ0Ngqp9+ol+fJXXSWefv/+4u/ffbco+kcflYyeK66Q5ePGCakffbR0sNy8WQqu9t9fJgzXNlJZmdg5/fvLdjSamoLzydbXy0Wod+9ueFNWMQS2Ic3JOmkaubYgJvQYMboxMhkhXf1Y49JLhfzXrJFulRUVsG6dWCw6T37qVJlw5M034fHHpaOlRiIhdwQa++0nHS6feEJIeuJEyeV/4w2xi8rL4cwzpSjr/PNhwwYYMgR+8xu5UGg0Nkr74/3372KtFzR0psvgYzt3HK1E7KHHiBGD5mbJua+uFsIfO1aef/SRZOt873vy+OqrRY2//LJYN2PHwnHHCYE/8IBsZ/RouOQSuUCsXStB3DVrYMsWab2wbZv49xdeKAS/aJH05rn9dpme8G9/kxjCWWdJANlGfb3YTmMKnIq2KLz5HVhyC8z8U5cl9VweekzoMWLEyIvmZrFWMpnodV55RRT59deLLbNunWThLF0K++wjds4BB4iyv+ceKbYCycjZuFGycioqpK2CUqLgv/51yfJJpSRDqLkZFiyQdU46SZqyHXKI3GXoWMH48fCZz0jLhqKx/kV4+yYJiIb1mO8CiAk9RowYnQLHERVeZs3N0twsij2dlgDv0qXSP6eyUqyguXP9IO7w4ULuGzbI9qZOlb+775Y7Co1EQmyh5ctFxc+aJdvfskXet3at3AlcfLEUhe3cKfUCJ54oF5odO2ScFRWyvvb/6+vlgqInNG9qks/t27dj9qGNmNBjxIjR7eA4otwHDQoPrm7bJoS/dKkEdqdNk2BtTQ386Efwk5/Icz1V4V57iX//ijV3RyIh79fZP/36ST3AkCFy9/DGGxLgPeYYKSxbtkxI/XOfkzYQv/2tZAwNGiQXhdGjZXsjRsjFaPBguRjU1srdhv6MQSHzeheCmNBjxIgRw8WKFXLXUFUlgd+77xYff8YMIff166Wy9+OP5e/ww8Wz//vfhcAnTJDe+/feK9uZPFnuArZtk22uXi0XI41USsh7wwa5MwH45jclZtAaxHnoMWLEiOFC9+bRuPPO1m3nyislPfMAq83Orl1y0Vizxv/75BNR7PvvL2r9wANb95n5EBN6jBgxYrQC+0Q0VayslLTOzijY6oqZoDFixIgRoxWICT1GjBgx9hAUROhKqVlKqfeUUiuVUteGvK6UUj92X39LKTUpbDsxYsSIEaP9kJfQlVJJ4F5gNnAQcLZSyu7gPhsY6/5dAvy0xOOMESNGjBh5UIhCnwKsdBznA8dxGoAFwFxrnbnAzx3BK0AfpVSeqcZjxIgRI0YpUQihDwNWG8/XuMuKXQel1CVKqdeUUq9t2rSp2LHGiBEjRowcKITQwxpg2tVIhayD4zj3O44z2XGcyQN1+VaMGDFixCgJCiH0NcAI4/lw4JNWrBMjRowYMdoRhRD6q8BYpdQopVQZcBbwlLXOU8D5brbLEcAOx3HWlXisMWLEiBEjB/JWijqO06SU+grwHJAEHnAcZ4lS6jL39fuAZ4E5wEqgFriw/YYcI0aMGDHCUFDpv+M4zyKkbS67z3jsAJeXdmgxYsSIEaMYxJWiMWLEiLGHICb0GDFixNhDEBN6jBgxYuwhiAk9RowYMfYQxIQeI0aMGHsIYkKPESNGjD0EMaHHiBEjxh6CmNBjxIgRYw9BTOgxYsSIsYcgJvQYMWLE2EMQE3qMGDFi7CGICT1GjBgx9hAo6avVCR+s1Cbgo1a+fQCwuYTDKSW66tjicRWHrjou6Lpji8dVHFo7rn0cxwmdIajTCL0tUEq95jjO5M4eRxi66tjicRWHrjou6Lpji8dVHNpjXLHlEiNGjBh7CGJCjxEjRow9BN2V0O/v7AHkQFcdWzyu4tBVxwVdd2zxuIpDycfVLT30GDFixIiRje6q0GPEiBEjhoWY0GPEiBFjD0G3I3Sl1Cyl1HtKqZVKqWs7cRwjlFIvKaXeVUotUUpd4S6/SSm1Vim12P2b0wljW6WUetv9/NfcZf2UUs8rpVa4//t2wrj2N/bLYqXUTqXUlZ2xz5RSDyilNiql3jGWRe4jpdR17jH3nlLqxA4e1w+UUsuUUm8ppZ5QSvVxl49USu029tt90Vtul3FF/m4dtb9yjO1XxrhWKaUWu8s7ZJ/l4If2PcYcx+k2f0ASeB/YFygD3gQO6qSxDAUmuY97AcuBg4CbgG908n5aBQywlv0ncK37+Frgji7wW64H9umMfQZMByYB7+TbR+7v+iaQAUa5x2CyA8d1ApByH99hjGukuV4n7K/Q360j91fU2KzX7wRu6Mh9loMf2vUY624KfQqw0nGcDxzHaQAWAHM7YyCO46xzHOcN93E18C4wrDPGUiDmAg+5jx8CTuvEsQDMBN53HKe11cJtguM4C4Gt1uKofTQXWOA4Tr3jOB8CK5FjsUPG5TjOHx3HaXKfvgIMb4/PLnZcOdBh+yvf2JRSCjgTeLS9Pj9iTFH80K7HWHcj9GHAauP5GroAiSqlRgITgX+6i77i3h4/0BnWBuAAf1RKva6UusRdNthxnHUgBxswqBPGZeIsgidZZ+8ziN5HXem4+wLwB+P5KKXUv5RSf1ZKTeuE8YT9bl1pf00DNjiOs8JY1qH7zOKHdj3Guhuhq5BlnZp3qZSqBB4HrnQcZyfwU2A0MAFYh9zudTSmOo4zCZgNXK6Umt4JY4iEUqoMOBX4jbuoK+yzXOgSx51S6ltAE/BLd9E6YG/HcSYCVwGPKKWqOnBIUb9bl9hfLs4mKBw6dJ+F8EPkqiHLit5n3Y3Q1wAjjOfDgU86aSwopdLIj/VLx3F+C+A4zgbHcZodx2kB/pt2vNWMguM4n7j/NwJPuGPYoJQa6o57KLCxo8dlYDbwhuM4G6Br7DMXUfuo0487pdQFwMnAuY5rurq351vcx68jvut+HTWmHL9bp+8vAKVUCjgd+JVe1pH7LIwfaOdjrLsR+qvAWKXUKFflnQU81RkDcb25nwHvOo4z31g+1Fjt08A79nvbeVw9lVK99GMkoPYOsp8ucFe7AHiyI8dlIaCaOnufGYjaR08BZymlMkqpUcBYYFFHDUopNQv4JnCq4zi1xvKBSqmk+3hfd1wfdOC4on63Tt1fBo4DljmOs0Yv6Kh9FsUPtPcx1t7R3naIHs9BIsbvA9/qxHEcjdwSvQUsdv/mAL8A3naXPwUM7eBx7YtEy98Eluh9BPQHXgRWuP/7ddJ+6wFsAXobyzp8nyEXlHVAI6KOvphrHwHfco+594DZHTyulYi/qo+z+9x1z3B/4zeBN4BTOnhckb9bR+2vqLG5yx8ELrPW7ZB9loMf2vUYi0v/Y8SIEWMPQXezXGLEiBEjRgRiQo8RI0aMPQQxoceIESPGHoKY0GPEiBFjD0FM6DFixIixhyAm9BgxYsTYQxATeowYMWLsIfj/ntFQeVSHDTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Duplicate Model\n",
    "# model= clone_model(baseModel)\n",
    "model_with_last_20_layers = load_model('Base_Model_2.h5')\n",
    "\n",
    "# # loop over the layers in the model and show which ones are trainable\n",
    "# # or not\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in model_with_last_20_layers.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 20\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in model_with_last_20_layers.layers:\n",
    "    layer.trainable=False\n",
    "for layer in model_with_last_20_layers.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "for layer in model_with_last_20_layers.layers[fine_tune_at:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "\n",
    "# # loop over the layers in the model and show which ones are trainable\n",
    "# # or not\n",
    "# print(\"\\r\\r\\r\\r\")\n",
    "# for layer in model_with_last_20_layers.layers:\n",
    "#     print(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# compile model\n",
    "#opt = SGD(lr=1.0e-6, momentum=0.9)\n",
    "opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "model_with_last_20_layers.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# learning schedule callback\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                          patience=5, min_lr=0.001)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "# callbacks_list = [ModelCheckpoint(filepath='model.h5', save_best_only=True)]\n",
    "callbacks_list = [tensorboard]\n",
    "# fit model\n",
    "history_awith_last_20_layers = model_with_last_20_layers.fit_generator(train_it, steps_per_epoch=len(train_it), \n",
    "                                                                      validation_data=test_it, \n",
    "                                                                      validation_steps=len(test_it), \n",
    "                                                                      epochs=epochs, verbose=1, \n",
    "                                                                      callbacks=callbacks_list)\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = model_with_last_20_layers.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print(train_it.class_indices)\n",
    "#print(model.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history_awith_last_20_layers)\n",
    "#print_metrics(model, test_datagen, test_path)\n",
    "    \n",
    "    \n",
    "# entry point, run the test harness\n",
    "# dataset_home = '../data/processed/iris_data/LG2200/gender/'\n",
    "#run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_last_20_layers.save('Base_Model_fine_tuned_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n",
      "Found 4630 images belonging to 2 classes.\n",
      "> 74.039\n"
     ]
    }
   ],
   "source": [
    "test_path = '../data/raw/iris_data/LG4000/gender/'\n",
    "\n",
    "# Duplicate Model\n",
    "# model= clone_model(baseModel)\n",
    "model = load_model('Base_Model_fine_tuned_2.h5')\n",
    "\n",
    "\n",
    "# entry point, run the test harness\n",
    "file = '../data/processed/iris_data/LG2200/gender/train/Male/02463d1896.tiff'\n",
    "width, height = imagesize.get(file)\n",
    "print(width, height)\n",
    "\n",
    "\n",
    "# prueba = load_all_images(train_path+'Male', height, width, 'tiff')\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalise_features)\n",
    "train_datagen.fit(load_all_images(test_path+'Male', height, width, 'tiff'))\n",
    "train_datagen.fit(load_all_images(test_path+'Female', height, width, 'tiff'))\n",
    "\n",
    "# prepare iterators\n",
    "test_it = train_datagen.flow_from_directory(test_path,\n",
    "    class_mode='binary', batch_size=batch_size, target_size=(240, 320)) \n",
    "\n",
    "\n",
    "# evaluate model\n",
    "test_it.reset()\n",
    "_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "#print(model.summary())\n",
    "print('> %.3f' % (acc * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.15",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
